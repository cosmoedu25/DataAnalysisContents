# 8ì¥ Part 2: ì „í†µì  ì‹œê³„ì—´ ëª¨ë¸(ARIMA, ì§€ìˆ˜í‰í™œë²•)
**ë¶€ì œ: ìˆ˜ì‹­ ë…„ ê²€ì¦ëœ ì‹œê³„ì—´ ì˜ˆì¸¡ì˜ í•µì‹¬ ê¸°ë²•ë“¤**

## í•™ìŠµ ëª©í‘œ
ì´ Partë¥¼ ì™„ë£Œí•œ í›„, ì—¬ëŸ¬ë¶„ì€ ë‹¤ìŒì„ í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤:
- ìê¸°íšŒê·€(AR), ì´ë™í‰ê· (MA), ARIMA ëª¨ë¸ì˜ ì›ë¦¬ë¥¼ ê¹Šì´ ì´í•´í•  ìˆ˜ ìˆë‹¤
- Box-Jenkins ë°©ë²•ë¡ ì— ë”°ë¼ ì²´ê³„ì ìœ¼ë¡œ ARIMA ëª¨ë¸ì„ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤
- ê³„ì ˆì„± SARIMA ëª¨ë¸ê³¼ ì§€ìˆ˜í‰í™œë²•ì„ ì‹¤ë¬´ì— ì ìš©í•  ìˆ˜ ìˆë‹¤
- 7ì¥ AI í˜‘ì—… ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ëª¨ë¸ ì„ íƒê³¼ í•´ì„ì„ ìµœì í™”í•  ìˆ˜ ìˆë‹¤
- Store Sales ë°ì´í„°ë¡œ ì™„ì „í•œ ì‹œê³„ì—´ ì˜ˆì¸¡ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤

## ì´ë²ˆ Part ë¯¸ë¦¬ë³´ê¸°
ğŸ“ˆ ì‹œê³„ì—´ ì˜ˆì¸¡ì˜ ì—­ì‚¬ëŠ” 1970ë…„ George Boxì™€ Gwilym Jenkinsê°€ ì œì‹œí•œ ARIMA ëª¨ë¸ë¡œ í˜ëª…ì„ ë§ì´í–ˆìŠµë‹ˆë‹¤. 50ë…„ì´ ë„˜ë„ë¡ ê¸ˆìœµ, ê²½ì œ, ê¸°ìƒ, ì œì¡°ì—… ë“± ëª¨ë“  ë¶„ì•¼ì—ì„œ í•µì‹¬ ì˜ˆì¸¡ ë„êµ¬ë¡œ ì‚¬ìš©ë˜ê³  ìˆëŠ” ì´ **ì „í†µì  ì‹œê³„ì—´ ëª¨ë¸ë“¤**ì€ ì—¬ì „íˆ í˜„ëŒ€ AI ì‹œëŒ€ì—ë„ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.

8ì¥ Part 1ì—ì„œ ìš°ë¦¬ëŠ” ì‹œê³„ì—´ì˜ ê¸°ë³¸ íŠ¹ì„±ê³¼ ì „ì²˜ë¦¬ë¥¼ ë§ˆìŠ¤í„°í–ˆìŠµë‹ˆë‹¤. ì´ì œ ê·¸ ê¸°ë°˜ ìœ„ì— **ê²€ì¦ëœ ì˜ˆì¸¡ ëª¨ë¸ë“¤**ì„ êµ¬ì¶•í•´ë³´ê² ìŠµë‹ˆë‹¤. íŠ¹íˆ 7ì¥ì—ì„œ ë°°ìš´ AI í˜‘ì—… ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ë³µì¡í•œ ìˆ˜í•™ì  ê°œë…ì„ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•˜ê³ , ìµœì ì˜ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤.

ğŸ¯ **ì´ë²ˆ Partì˜ í•µì‹¬ ì—¬ì •**:
- **AR/MA/ARIMA**: ì‹œê³„ì—´ì˜ ê³¼ê±°ê°€ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì›ë¦¬ ì™„ì „ ì´í•´
- **Box-Jenkins ë°©ë²•ë¡ **: ì²´ê³„ì ì¸ ëª¨ë¸ êµ¬ì¶• í”„ë¡œì„¸ìŠ¤ ë§ˆìŠ¤í„°  
- **SARIMA**: ê³„ì ˆì„±ê¹Œì§€ ê³ ë ¤í•œ ê³ ê¸‰ ëª¨ë¸ë§ ê¸°ë²•
- **ì§€ìˆ˜í‰í™œë²•**: ì§ê´€ì ì´ê³  ì‹¤ìš©ì ì¸ ì˜ˆì¸¡ ë°©ë²•ë“¤
- **AI í˜‘ì—… ìµœì í™”**: í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ìœ¼ë¡œ ëª¨ë¸ í•´ì„ë ¥ ê·¹ëŒ€í™”

---

> ğŸš€ **ì™œ ì „í†µì  ëª¨ë¸ì´ ì—¬ì „íˆ ì¤‘ìš”í•œê°€?**
> 
> **ğŸ” í•´ì„ ê°€ëŠ¥ì„±**: ë”¥ëŸ¬ë‹ê³¼ ë‹¬ë¦¬ ëª¨ë“  ê³„ìˆ˜ì˜ ì˜ë¯¸ë¥¼ ëª…í™•íˆ ì„¤ëª… ê°€ëŠ¥
> **âš¡ íš¨ìœ¨ì„±**: ì ì€ ë°ì´í„°ë¡œë„ ì•ˆì •ì  ì˜ˆì¸¡, ë¹ ë¥¸ í•™ìŠµê³¼ ì¶”ë¡ 
> **ğŸ¯ ì •í™•ì„±**: ë‹¨ê¸° ì˜ˆì¸¡ì—ì„œëŠ” ì—¬ì „íˆ ìµœê³  ì„±ëŠ¥ ìœ ì§€
> **ğŸ”§ ì‹¤ë¬´ì„±**: ë¹„ì¦ˆë‹ˆìŠ¤ í™˜ê²½ì—ì„œ ê²€ì¦ëœ ì‹ ë¢°ë„ì™€ ì•ˆì •ì„±
> **ğŸ’¡ ê¸°ì´ˆ ì´í•´**: ëª¨ë“  ê³ ê¸‰ ëª¨ë¸ì˜ ì´ë¡ ì  í† ëŒ€ ì œê³µ

## 1. ìê¸°íšŒê·€ ë° ì´ë™í‰ê·  ëª¨ë¸ì˜ ì´í•´

### 1.1 ì‹œê³„ì—´ ëª¨ë¸ë§ì˜ ê¸°ë³¸ ì² í•™

ì‹œê³„ì—´ ì˜ˆì¸¡ì˜ í•µì‹¬ì€ **"ê³¼ê±° íŒ¨í„´ì´ ë¯¸ë˜ì—ë„ ë°˜ë³µëœë‹¤"**ëŠ” ê°€ì •ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ë‹¨ìˆœí•œ ì•„ì´ë””ì–´ë¥¼ ìˆ˜í•™ì ìœ¼ë¡œ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì€ ë§¤ìš° ë‹¤ì–‘í•©ë‹ˆë‹¤.

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.stats.diagnostic import acorr_ljungbox
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# ì‹œê°í™” ì„¤ì •
plt.style.use('seaborn-v0_8')
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

class TraditionalTimeSeriesModels:
    """ì „í†µì  ì‹œê³„ì—´ ëª¨ë¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.models = {}
        self.model_results = {}
        self.forecasts = {}
        
        # 7ì¥ì—ì„œ ë°°ìš´ AI í˜‘ì—… ì›ì¹™ ì ìš©
        self.interpretation_prompts = {
            'ar_model': self._create_ar_interpretation_prompt(),
            'ma_model': self._create_ma_interpretation_prompt(),
            'arima_model': self._create_arima_interpretation_prompt(),
            'sarima_model': self._create_sarima_interpretation_prompt()
        }
    
    def demonstrate_basic_concepts(self):
        """ê¸°ë³¸ ê°œë… ì‹œì—°"""
        
        print("ğŸ“ ì‹œê³„ì—´ ëª¨ë¸ë§ ê¸°ë³¸ ê°œë…")
        print("=" * 50)
        
        # 1. ë°±ìƒ‰ì¡ìŒ (White Noise) - ê°€ì¥ ë‹¨ìˆœí•œ ì‹œê³„ì—´
        np.random.seed(42)
        white_noise = np.random.normal(0, 1, 200)
        
        # 2. ëœë¤ì›Œí¬ (Random Walk) - ëˆ„ì  ë°±ìƒ‰ì¡ìŒ
        random_walk = np.cumsum(white_noise)
        
        # 3. íŠ¸ë Œë“œê°€ ìˆëŠ” ì‹œê³„ì—´
        trend_series = 0.5 * np.arange(200) + white_noise
        
        # 4. ê³„ì ˆì„±ì´ ìˆëŠ” ì‹œê³„ì—´
        seasonal_component = 10 * np.sin(2 * np.pi * np.arange(200) / 50)
        seasonal_series = trend_series + seasonal_component
        
        # ì‹œê°í™”
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('ğŸ¯ ì‹œê³„ì—´ì˜ ê¸°ë³¸ íŒ¨í„´ë“¤', fontsize=16, fontweight='bold')
        
        series_data = [
            (white_noise, 'ğŸ² ë°±ìƒ‰ì¡ìŒ (White Noise)', 'ì™„ì „íˆ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ëœë¤ ì‹œê³„ì—´'),
            (random_walk, 'ğŸš¶ ëœë¤ì›Œí¬ (Random Walk)', 'ì´ì „ ê°’ì—ì„œ ëœë¤í•˜ê²Œ ë³€í™”'),
            (trend_series, 'ğŸ“ˆ íŠ¸ë Œë“œ ì‹œê³„ì—´', 'ì¼ì •í•œ ë°©í–¥ì„±ì„ ê°€ì§„ ë³€í™”'),
            (seasonal_series, 'ğŸ”„ ê³„ì ˆì„± ì‹œê³„ì—´', 'ì£¼ê¸°ì  íŒ¨í„´ì´ ë°˜ë³µ')
        ]
        
        for i, (data, title, description) in enumerate(series_data):
            row, col = i // 2, i % 2
            ax = axes[row, col]
            
            ax.plot(data, linewidth=1.5, alpha=0.8)
            ax.set_title(title, fontweight='bold')
            ax.text(0.02, 0.95, description, transform=ax.transAxes, 
                   bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.8),
                   fontsize=9, verticalalignment='top')
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        print("\nğŸ” ê° íŒ¨í„´ì˜ íŠ¹ì§•:")
        print(f"   ë°±ìƒ‰ì¡ìŒ ë¶„ì‚°: {np.var(white_noise):.3f} (í•­ìƒ ì¼ì •)")
        print(f"   ëœë¤ì›Œí¬ ë¶„ì‚°: {np.var(random_walk):.3f} (ì‹œê°„ì— ë”°ë¼ ì¦ê°€)")
        print(f"   íŠ¸ë Œë“œ ê¸°ìš¸ê¸°: {np.polyfit(range(200), trend_series, 1)[0]:.3f}")
        print(f"   ê³„ì ˆì„± ì§„í­: {(np.max(seasonal_component) - np.min(seasonal_component))/2:.1f}")
        
        return {
            'white_noise': white_noise,
            'random_walk': random_walk, 
            'trend_series': trend_series,
            'seasonal_series': seasonal_series
        }
    
    def explain_stationarity(self, data_dict):
        """ì •ìƒì„± ê°œë… ì„¤ëª…"""
        
        print("\nğŸ“Š ì •ìƒì„±(Stationarity) ê°œë… ì´í•´")
        print("=" * 50)
        print("ì •ìƒ ì‹œê³„ì—´: í‰ê· , ë¶„ì‚°, ê³µë¶„ì‚°ì´ ì‹œê°„ì— ë¬´ê´€í•˜ê²Œ ì¼ì •í•œ ì‹œê³„ì—´")
        print("ë¹„ì •ìƒ ì‹œê³„ì—´: ì‹œê°„ì— ë”°ë¼ í†µê³„ì  ì„±ì§ˆì´ ë³€í•˜ëŠ” ì‹œê³„ì—´")
        
        # ì •ìƒì„± ê²€ì • í•¨ìˆ˜
        def check_stationarity(series, name):
            print(f"\nğŸ”¬ {name} ì •ìƒì„± ê²€ì •:")
            
            # ADF ê²€ì • (Augmented Dickey-Fuller Test)
            adf_result = adfuller(series, autolag='AIC')
            print(f"   ADF í†µê³„ëŸ‰: {adf_result[0]:.4f}")
            print(f"   p-ê°’: {adf_result[1]:.4f}")
            print(f"   ì„ê³„ê°’: {adf_result[4]['5%']:.4f}")
            
            if adf_result[1] <= 0.05:
                print(f"   âœ… ì •ìƒ ì‹œê³„ì—´ (p < 0.05)")
            else:
                print(f"   âŒ ë¹„ì •ìƒ ì‹œê³„ì—´ (p >= 0.05)")
            
            # KPSS ê²€ì • (ë” ì—„ê²©í•œ ê²€ì •)
            try:
                kpss_result = kpss(series, regression='c', nlags='auto')
                print(f"   KPSS í†µê³„ëŸ‰: {kpss_result[0]:.4f}")
                print(f"   KPSS p-ê°’: {kpss_result[1]:.4f}")
                
                if kpss_result[1] >= 0.05:
                    print(f"   âœ… KPSS: ì •ìƒ (p >= 0.05)")
                else:
                    print(f"   âŒ KPSS: ë¹„ì •ìƒ (p < 0.05)")
            except:
                print(f"   âš ï¸ KPSS ê²€ì • ì‹¤íŒ¨")
            
            return adf_result[1] <= 0.05
        
        # ê° ì‹œê³„ì—´ì˜ ì •ìƒì„± ê²€ì •
        stationarity_results = {}
        for name, series in data_dict.items():
            stationarity_results[name] = check_stationarity(series, name)
        
        print(f"\nğŸ“‹ ì •ìƒì„± ê²€ì • ìš”ì•½:")
        for name, is_stationary in stationarity_results.items():
            status = "ì •ìƒ" if is_stationary else "ë¹„ì •ìƒ"
            emoji = "âœ…" if is_stationary else "âŒ"
            print(f"   {emoji} {name}: {status}")
        
        # ì°¨ë¶„ì„ í†µí•œ ì •ìƒì„± í™•ë³´
        print(f"\nğŸ”§ ì°¨ë¶„(Differencing)ì„ í†µí•œ ì •ìƒì„± í™•ë³´:")
        
        non_stationary_series = data_dict['random_walk']
        differenced_series = np.diff(non_stationary_series)
        
        print(f"   ì›ë³¸ ëœë¤ì›Œí¬ ì •ìƒì„± ê²€ì •:")
        check_stationarity(non_stationary_series, "ì›ë³¸")
        
        print(f"   1ì°¨ ì°¨ë¶„ í›„ ì •ìƒì„± ê²€ì •:")
        check_stationarity(differenced_series, "1ì°¨ ì°¨ë¶„")
        
        # ì°¨ë¶„ ì „í›„ ì‹œê°í™”
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        fig.suptitle('ğŸ”§ ì°¨ë¶„ì„ í†µí•œ ì •ìƒì„± í™•ë³´', fontsize=14, fontweight='bold')
        
        axes[0].plot(non_stationary_series, color='red', alpha=0.8)
        axes[0].set_title('âŒ ì›ë³¸ (ë¹„ì •ìƒ)', fontweight='bold')
        axes[0].grid(True, alpha=0.3)
        
        axes[1].plot(differenced_series, color='blue', alpha=0.8)
        axes[1].set_title('âœ… 1ì°¨ ì°¨ë¶„ (ì •ìƒ)', fontweight='bold')
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        return stationarity_results
    
    def demonstrate_ar_model(self, order=2):
        """ìê¸°íšŒê·€(AR) ëª¨ë¸ ì‹œì—°"""
        
        print(f"\nğŸ”„ ìê¸°íšŒê·€ AR({order}) ëª¨ë¸")
        print("=" * 50)
        print("AR ëª¨ë¸: í˜„ì¬ ê°’ì´ ê³¼ê±° ëª‡ ê°œ ê°’ë“¤ì˜ ì„ í˜•ê²°í•©ìœ¼ë¡œ ê²°ì •")
        print(f"ìˆ˜ì‹: X(t) = c + Ï†â‚X(t-1) + Ï†â‚‚X(t-2) + ... + Ï†â‚šX(t-p) + Îµ(t)")
        
        # AR(2) ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜
        np.random.seed(42)
        n = 200
        phi1, phi2 = 0.6, -0.3  # AR ê³„ìˆ˜
        c = 1.0  # ìƒìˆ˜í•­
        
        # AR(2) ì‹œê³„ì—´ ìƒì„±
        ar_series = np.zeros(n)
        errors = np.random.normal(0, 1, n)
        
        for t in range(2, n):
            ar_series[t] = c + phi1 * ar_series[t-1] + phi2 * ar_series[t-2] + errors[t]
        
        print(f"\nğŸ“Š ìƒì„±ëœ AR({order}) ëª¨ë¸ íŠ¹ì„±:")
        print(f"   Ï†â‚ (1ì°¨ ê³„ìˆ˜): {phi1} - {'ì–‘ìˆ˜: ì–‘ì˜ ìê¸°ìƒê´€' if phi1 > 0 else 'ìŒìˆ˜: ìŒì˜ ìê¸°ìƒê´€'}")
        print(f"   Ï†â‚‚ (2ì°¨ ê³„ìˆ˜): {phi2} - {'ì–‘ìˆ˜: 2ì°¨ ì–‘ì˜ ìƒê´€' if phi2 > 0 else 'ìŒìˆ˜: 2ì°¨ ìŒì˜ ìƒê´€'}")
        print(f"   ì •ìƒì„± ì¡°ê±´: |Ï†â‚ + Ï†â‚‚| < 1, |Ï†â‚‚ - Ï†â‚| < 1, |Ï†â‚‚| < 1")
        
        # ì •ìƒì„± ì¡°ê±´ í™•ì¸
        condition1 = abs(phi1 + phi2) < 1
        condition2 = abs(phi2 - phi1) < 1  
        condition3 = abs(phi2) < 1
        
        print(f"   ì¡°ê±´ 1: |{phi1} + {phi2}| = {abs(phi1 + phi2):.3f} < 1 âœ {'âœ…' if condition1 else 'âŒ'}")
        print(f"   ì¡°ê±´ 2: |{phi2} - {phi1}| = {abs(phi2 - phi1):.3f} < 1 âœ {'âœ…' if condition2 else 'âŒ'}")
        print(f"   ì¡°ê±´ 3: |{phi2}| = {abs(phi2):.3f} < 1 âœ {'âœ…' if condition3 else 'âŒ'}")
        
        stationary = condition1 and condition2 and condition3
        print(f"   ì¢…í•© ì •ìƒì„±: {'âœ… ì •ìƒ' if stationary else 'âŒ ë¹„ì •ìƒ'}")
        
        # ACFì™€ PACF ê³„ì‚° ë° ì‹œê°í™”
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'ğŸ”„ AR({order}) ëª¨ë¸ ë¶„ì„', fontsize=16, fontweight='bold')
        
        # ì‹œê³„ì—´ í”Œë¡¯
        axes[0, 0].plot(ar_series, color='blue', linewidth=1.5)
        axes[0, 0].set_title(f'ğŸ“ˆ AR({order}) ì‹œê³„ì—´', fontweight='bold')
        axes[0, 0].grid(True, alpha=0.3)
        
        # íˆìŠ¤í† ê·¸ë¨
        axes[0, 1].hist(ar_series, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0, 1].set_title('ğŸ“Š ë¶„í¬ (ì •ê·œì„± í™•ì¸)', fontweight='bold')
        axes[0, 1].grid(True, alpha=0.3)
        
        # ACF (ìê¸°ìƒê´€í•¨ìˆ˜)
        plot_acf(ar_series, lags=20, ax=axes[1, 0], title='ACF: ì„œì„œíˆ ê°ì†Œí•˜ëŠ” íŒ¨í„´')
        
        # PACF (í¸ìê¸°ìƒê´€í•¨ìˆ˜)  
        plot_pacf(ar_series, lags=20, ax=axes[1, 1], title=f'PACF: {order}ì°¨ì—ì„œ ì ˆë‹¨')
        
        plt.tight_layout()
        plt.show()
        
        # AR ëª¨ë¸ í”¼íŒ…
        ar_model = ARIMA(ar_series, order=(order, 0, 0))
        ar_fitted = ar_model.fit()
        
        print(f"\nğŸ¯ AR({order}) ëª¨ë¸ ì¶”ì • ê²°ê³¼:")
        print(f"   ì¶”ì •ëœ Ï†â‚: {ar_fitted.params[1]:.4f} (ì‹¤ì œ: {phi1})")
        if order >= 2:
            print(f"   ì¶”ì •ëœ Ï†â‚‚: {ar_fitted.params[2]:.4f} (ì‹¤ì œ: {phi2})")
        print(f"   AIC: {ar_fitted.aic:.2f}")
        print(f"   BIC: {ar_fitted.bic:.2f}")
        
        return ar_series, ar_fitted
    
    def demonstrate_ma_model(self, order=2):
        """ì´ë™í‰ê· (MA) ëª¨ë¸ ì‹œì—°"""
        
        print(f"\nğŸ“Š ì´ë™í‰ê·  MA({order}) ëª¨ë¸")
        print("=" * 50)
        print("MA ëª¨ë¸: í˜„ì¬ ê°’ì´ ê³¼ê±° ì˜¤ì°¨í•­ë“¤ì˜ ì„ í˜•ê²°í•©ìœ¼ë¡œ ê²°ì •")
        print(f"ìˆ˜ì‹: X(t) = Î¼ + Îµ(t) + Î¸â‚Îµ(t-1) + Î¸â‚‚Îµ(t-2) + ... + Î¸áµ©Îµ(t-q)")
        
        # MA(2) ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜
        np.random.seed(42)
        n = 200
        theta1, theta2 = 0.4, 0.3  # MA ê³„ìˆ˜
        mu = 0.0  # í‰ê· 
        
        # MA(2) ì‹œê³„ì—´ ìƒì„±
        errors = np.random.normal(0, 1, n)
        ma_series = np.zeros(n)
        
        for t in range(n):
            ma_series[t] = mu + errors[t]
            if t >= 1:
                ma_series[t] += theta1 * errors[t-1]
            if t >= 2:
                ma_series[t] += theta2 * errors[t-2]
        
        print(f"\nğŸ“Š ìƒì„±ëœ MA({order}) ëª¨ë¸ íŠ¹ì„±:")
        print(f"   Î¸â‚ (1ì°¨ ê³„ìˆ˜): {theta1} - 1ê¸°ê°„ ì „ ì˜¤ì°¨ì˜ ì˜í–¥ë ¥")
        print(f"   Î¸â‚‚ (2ì°¨ ê³„ìˆ˜): {theta2} - 2ê¸°ê°„ ì „ ì˜¤ì°¨ì˜ ì˜í–¥ë ¥")
        print(f"   ê°€ì—­ì„± ì¡°ê±´: MA ê³„ìˆ˜ë“¤ì´ ì ì ˆí•œ ë²”ìœ„ ë‚´ì— ìˆì–´ì•¼ í•¨")
        
        # MA ëª¨ë¸ì€ í•­ìƒ ì •ìƒ
        print(f"   ì •ìƒì„±: âœ… MA ëª¨ë¸ì€ í•­ìƒ ì •ìƒ (ì˜¤ì°¨í•­ì´ ì •ìƒì´ë©´)")
        
        # ACFì™€ PACF ê³„ì‚° ë° ì‹œê°í™”
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'ğŸ“Š MA({order}) ëª¨ë¸ ë¶„ì„', fontsize=16, fontweight='bold')
        
        # ì‹œê³„ì—´ í”Œë¡¯
        axes[0, 0].plot(ma_series, color='green', linewidth=1.5)
        axes[0, 0].set_title(f'ğŸ“ˆ MA({order}) ì‹œê³„ì—´', fontweight='bold')
        axes[0, 0].grid(True, alpha=0.3)
        
        # íˆìŠ¤í† ê·¸ë¨
        axes[0, 1].hist(ma_series, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')
        axes[0, 1].set_title('ğŸ“Š ë¶„í¬ (ì •ê·œì„± í™•ì¸)', fontweight='bold')
        axes[0, 1].grid(True, alpha=0.3)
        
        # ACF (ìê¸°ìƒê´€í•¨ìˆ˜) - MA(q)ì—ì„œëŠ” qì°¨ì—ì„œ ì ˆë‹¨
        plot_acf(ma_series, lags=20, ax=axes[1, 0], title=f'ACF: {order}ì°¨ì—ì„œ ì ˆë‹¨')
        
        # PACF (í¸ìê¸°ìƒê´€í•¨ìˆ˜) - ì„œì„œíˆ ê°ì†Œ
        plot_pacf(ma_series, lags=20, ax=axes[1, 1], title='PACF: ì„œì„œíˆ ê°ì†Œí•˜ëŠ” íŒ¨í„´')
        
        plt.tight_layout()
        plt.show()
        
        # MA ëª¨ë¸ í”¼íŒ…
        ma_model = ARIMA(ma_series, order=(0, 0, order))
        ma_fitted = ma_model.fit()
        
        print(f"\nğŸ¯ MA({order}) ëª¨ë¸ ì¶”ì • ê²°ê³¼:")
        print(f"   ì¶”ì •ëœ Î¸â‚: {ma_fitted.params[1]:.4f} (ì‹¤ì œ: {theta1})")
        if order >= 2:
            print(f"   ì¶”ì •ëœ Î¸â‚‚: {ma_fitted.params[2]:.4f} (ì‹¤ì œ: {theta2})")
        print(f"   AIC: {ma_fitted.aic:.2f}")
        print(f"   BIC: {ma_fitted.bic:.2f}")
        
        return ma_series, ma_fitted
    
    def demonstrate_arma_model(self, ar_order=1, ma_order=1):
        """ARMA ëª¨ë¸ ì‹œì—°"""
        
        print(f"\nğŸ”„ğŸ“Š ARMA({ar_order},{ma_order}) ëª¨ë¸")
        print("=" * 50)
        print("ARMA ëª¨ë¸: ARê³¼ MAì˜ ê²°í•© - ê³¼ê±° ê°’ê³¼ ê³¼ê±° ì˜¤ì°¨ì˜ ì˜í–¥ì„ ëª¨ë‘ ê³ ë ¤")
        print(f"ìˆ˜ì‹: X(t) = c + Ï†â‚X(t-1) + ... + Ï†â‚šX(t-p) + Îµ(t) + Î¸â‚Îµ(t-1) + ... + Î¸áµ©Îµ(t-q)")
        
        # ARMA(1,1) ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜
        np.random.seed(42)
        n = 200
        phi1 = 0.6    # AR ê³„ìˆ˜
        theta1 = 0.3  # MA ê³„ìˆ˜
        c = 1.0       # ìƒìˆ˜í•­
        
        # ARMA(1,1) ì‹œê³„ì—´ ìƒì„±
        errors = np.random.normal(0, 1, n)
        arma_series = np.zeros(n)
        
        for t in range(1, n):
            arma_series[t] = c + phi1 * arma_series[t-1] + errors[t] + theta1 * errors[t-1]
        
        print(f"\nğŸ“Š ìƒì„±ëœ ARMA({ar_order},{ma_order}) ëª¨ë¸ íŠ¹ì„±:")
        print(f"   AR ë¶€ë¶„ Ï†â‚: {phi1} - ì´ì „ ê°’ì˜ ì˜í–¥")
        print(f"   MA ë¶€ë¶„ Î¸â‚: {theta1} - ì´ì „ ì˜¤ì°¨ì˜ ì˜í–¥")
        print(f"   ì •ìƒì„±: AR ë¶€ë¶„ì´ ì •ìƒì„± ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•¨")
        print(f"   ê°€ì—­ì„±: MA ë¶€ë¶„ì´ ê°€ì—­ì„± ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•¨")
        
        # ACFì™€ PACF ë¶„ì„
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'ğŸ”„ğŸ“Š ARMA({ar_order},{ma_order}) ëª¨ë¸ ë¶„ì„', fontsize=16, fontweight='bold')
        
        # ì‹œê³„ì—´ í”Œë¡¯
        axes[0, 0].plot(arma_series, color='purple', linewidth=1.5)
        axes[0, 0].set_title(f'ğŸ“ˆ ARMA({ar_order},{ma_order}) ì‹œê³„ì—´', fontweight='bold')
        axes[0, 0].grid(True, alpha=0.3)
        
        # íˆìŠ¤í† ê·¸ë¨
        axes[0, 1].hist(arma_series, bins=30, alpha=0.7, color='plum', edgecolor='black')
        axes[0, 1].set_title('ğŸ“Š ë¶„í¬ (ì •ê·œì„± í™•ì¸)', fontweight='bold')
        axes[0, 1].grid(True, alpha=0.3)
        
        # ACF - ì„œì„œíˆ ê°ì†Œ (ARì˜ íŠ¹ì„±)
        plot_acf(arma_series, lags=20, ax=axes[1, 0], title='ACF: ì„œì„œíˆ ê°ì†Œ (AR ì˜í–¥)')
        
        # PACF - ì„œì„œíˆ ê°ì†Œ (MAì˜ íŠ¹ì„±)
        plot_pacf(arma_series, lags=20, ax=axes[1, 1], title='PACF: ì„œì„œíˆ ê°ì†Œ (MA ì˜í–¥)')
        
        plt.tight_layout()
        plt.show()
        
        # ARMA ëª¨ë¸ í”¼íŒ…
        arma_model = ARIMA(arma_series, order=(ar_order, 0, ma_order))
        arma_fitted = arma_model.fit()
        
        print(f"\nğŸ¯ ARMA({ar_order},{ma_order}) ëª¨ë¸ ì¶”ì • ê²°ê³¼:")
        print(f"   ì¶”ì •ëœ Ï†â‚: {arma_fitted.params[1]:.4f} (ì‹¤ì œ: {phi1})")
        print(f"   ì¶”ì •ëœ Î¸â‚: {arma_fitted.params[2]:.4f} (ì‹¤ì œ: {theta1})")
        print(f"   AIC: {arma_fitted.aic:.2f}")
        print(f"   BIC: {arma_fitted.bic:.2f}")
        
        return arma_series, arma_fitted
    
    def compare_acf_pacf_patterns(self):
        """ACFì™€ PACF íŒ¨í„´ ë¹„êµ"""
        
        print(f"\nğŸ” ACFì™€ PACF íŒ¨í„´ìœ¼ë¡œ ëª¨ë¸ ì‹ë³„í•˜ê¸°")
        print("=" * 60)
        
        # íŒ¨í„´ ë¹„êµí‘œ
        pattern_table = {
            'AR(p)': {
                'ACF': 'ì„œì„œíˆ ê°ì†Œ (ê¸°í•˜ê¸‰ìˆ˜ì  ë˜ëŠ” ê°ì‡ ì§„ë™)',
                'PACF': f'pì°¨ì—ì„œ ì ˆë‹¨ (pì°¨ ì´í›„ 0)',
                'íŠ¹ì§•': 'ê³¼ê±° ê°’ì˜ ì§ì ‘ì  ì˜í–¥'
            },
            'MA(q)': {
                'ACF': f'qì°¨ì—ì„œ ì ˆë‹¨ (qì°¨ ì´í›„ 0)',
                'PACF': 'ì„œì„œíˆ ê°ì†Œ (ê¸°í•˜ê¸‰ìˆ˜ì  ë˜ëŠ” ê°ì‡ ì§„ë™)',
                'íŠ¹ì§•': 'ê³¼ê±° ì˜¤ì°¨ì˜ ì˜í–¥'
            },
            'ARMA(p,q)': {
                'ACF': 'ì„œì„œíˆ ê°ì†Œ (MA íŠ¹ì„±)',
                'PACF': 'ì„œì„œíˆ ê°ì†Œ (AR íŠ¹ì„±)',
                'íŠ¹ì§•': 'ARê³¼ MAì˜ ë³µí•© íš¨ê³¼'
            }
        }
        
        print("ğŸ“‹ ëª¨ë¸ë³„ ACF/PACF íŒ¨í„´ ì‹ë³„ ê°€ì´ë“œ:")
        print("-" * 60)
        for model, patterns in pattern_table.items():
            print(f"ğŸ”¹ {model}:")
            print(f"   ACF:  {patterns['ACF']}")
            print(f"   PACF: {patterns['PACF']}")
            print(f"   íŠ¹ì§•: {patterns['íŠ¹ì§•']}")
            print()
        
        # ì‹¤ì œ íŒ¨í„´ ë¹„êµ ì‹œê°í™”
        fig, axes = plt.subplots(3, 2, figsize=(15, 12))
        fig.suptitle('ğŸ” ëª¨ë¸ë³„ ACF/PACF íŒ¨í„´ ë¹„êµ', fontsize=16, fontweight='bold')
        
        # ê° ëª¨ë¸ì˜ ì´ë¡ ì  ACF/PACF ì‹œë®¬ë ˆì´ì…˜
        models_to_compare = [
            ('AR(2)', [0.6, -0.3], [0], 'blue'),
            ('MA(2)', [], [0.4, 0.3], 'green'), 
            ('ARMA(1,1)', [0.6], [0.3], 'purple')
        ]
        
        np.random.seed(42)
        
        for i, (model_name, ar_params, ma_params, color) in enumerate(models_to_compare):
            # ëª¨ë¸ ìƒì„±
            if ar_params and ma_params:  # ARMA
                order = (len(ar_params), 0, len(ma_params))
            elif ar_params:  # AR
                order = (len(ar_params), 0, 0)
            else:  # MA
                order = (0, 0, len(ma_params))
            
            # ì‹œë®¬ë ˆì´ì…˜ëœ ì‹œê³„ì—´ ìƒì„±
            temp_series = np.random.normal(0, 1, 200)
            if model_name == 'AR(2)':
                temp_series = self.demonstrate_ar_model(2)[0]
            elif model_name == 'MA(2)':
                temp_series = self.demonstrate_ma_model(2)[0]
            else:  # ARMA(1,1)
                temp_series = self.demonstrate_arma_model(1, 1)[0]
            
            # ACF í”Œë¡¯
            plot_acf(temp_series, lags=15, ax=axes[i, 0], 
                    title=f'{model_name} - ACF', color=color)
            
            # PACF í”Œë¡¯
            plot_pacf(temp_series, lags=15, ax=axes[i, 1], 
                     title=f'{model_name} - PACF', color=color)
        
        plt.tight_layout()
        plt.show()
        
        print("ğŸ’¡ ì‹¤ë¬´ ì‹ë³„ íŒ:")
        print("   1. ACFê°€ qì°¨ì—ì„œ ì ˆë‹¨ â†’ MA(q) ê³ ë ¤")
        print("   2. PACFê°€ pì°¨ì—ì„œ ì ˆë‹¨ â†’ AR(p) ê³ ë ¤") 
        print("   3. ë‘˜ ë‹¤ ì„œì„œíˆ ê°ì†Œ â†’ ARMA(p,q) ê³ ë ¤")
        print("   4. ë¶ˆê·œì¹™í•œ íŒ¨í„´ â†’ ì°¨ë¶„ í›„ ì¬ë¶„ì„ í•„ìš”")
        print("   5. ì •ë³´ê¸°ì¤€(AIC/BIC)ìœ¼ë¡œ ìµœì¢… ëª¨ë¸ ì„ íƒ")
    
    def _create_ar_interpretation_prompt(self):
        """AR ëª¨ë¸ í•´ì„ìš© í”„ë¡¬í”„íŠ¸"""
        return """
ë‹¹ì‹ ì€ ì‹œê³„ì—´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. AR ëª¨ë¸ ê²°ê³¼ë¥¼ í•´ì„í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ìš”ì²­ì‚¬í•­**:
1. AR ê³„ìˆ˜ë“¤ì˜ ì‹¤ë¬´ì  ì˜ë¯¸
2. ì •ìƒì„±ê³¼ ì˜ˆì¸¡ ì•ˆì •ì„± í‰ê°€
3. ëª¨ë¸ì˜ ê°•ì ê³¼ í•œê³„ì 
4. ë¹„ì¦ˆë‹ˆìŠ¤ ì‘ìš© ë°©ì•ˆ

**ë°ì´í„°**: {model_summary}
**ê³„ìˆ˜**: {coefficients}
**ì§„ë‹¨ í†µê³„**: {diagnostics}

ì‹¤ë¬´ì§„ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì§ê´€ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        """
    
    def _create_ma_interpretation_prompt(self):
        """MA ëª¨ë¸ í•´ì„ìš© í”„ë¡¬í”„íŠ¸"""
        return """
ë‹¹ì‹ ì€ ì‹œê³„ì—´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. MA ëª¨ë¸ ê²°ê³¼ë¥¼ í•´ì„í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ìš”ì²­ì‚¬í•­**:
1. MA ê³„ìˆ˜ë“¤ì˜ ì¶©ê²© ì „íŒŒ íš¨ê³¼
2. ì˜¤ì°¨ êµ¬ì¡°ì™€ ì˜ˆì¸¡ ì •í™•ë„
3. ë‹¨ê¸° vs ì¥ê¸° ì˜ˆì¸¡ ì„±ëŠ¥
4. ëª¨ë¸ ì í•©ì„± í‰ê°€

**ë°ì´í„°**: {model_summary}
**ê³„ìˆ˜**: {coefficients}
**ì˜¤ì°¨ ë¶„ì„**: {error_analysis}

ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •ì— ë„ì›€ì´ ë˜ëŠ” ê´€ì ì—ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        """

# ì „í†µì  ì‹œê³„ì—´ ëª¨ë¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
traditional_models = TraditionalTimeSeriesModels()

print("ğŸ“š ì „í†µì  ì‹œê³„ì—´ ëª¨ë¸ í•™ìŠµ ì—¬ì • ì‹œì‘!")
print("=" * 60)
print("ğŸ¯ ëª©í‘œ: AR, MA, ARIMAì˜ ì›ë¦¬ë¥¼ ì™„ì „íˆ ì´í•´í•˜ê³  ì‹¤ë¬´ì— ì ìš©")
print("ğŸ¤– ë°©ë²•: 7ì¥ AI í˜‘ì—… ê¸°ë²•ìœ¼ë¡œ ë³µì¡í•œ ìˆ˜í•™ì„ ì§ê´€ì ìœ¼ë¡œ í•™ìŠµ")

# 1. ê¸°ë³¸ ê°œë… ì‹œì—°
basic_patterns = traditional_models.demonstrate_basic_concepts()

# 2. ì •ìƒì„± ê°œë… ì´í•´
stationarity_results = traditional_models.explain_stationarity(basic_patterns)

# 3. AR ëª¨ë¸ ìƒì„¸ ë¶„ì„
print(f"\n" + "="*60)
ar_series, ar_model = traditional_models.demonstrate_ar_model(order=2)

# 4. MA ëª¨ë¸ ìƒì„¸ ë¶„ì„  
print(f"\n" + "="*60)
ma_series, ma_model = traditional_models.demonstrate_ma_model(order=2)

# 5. ARMA ëª¨ë¸ ê²°í•© ë¶„ì„
print(f"\n" + "="*60)
arma_series, arma_model = traditional_models.demonstrate_arma_model(ar_order=1, ma_order=1)

# 6. ACF/PACF íŒ¨í„´ ë¹„êµ
print(f"\n" + "="*60)
traditional_models.compare_acf_pacf_patterns()

print(f"\nâœ… 1ë¶€ ì™„ë£Œ: ìê¸°íšŒê·€ ë° ì´ë™í‰ê·  ëª¨ë¸ì˜ ê¸°ì´ˆ")
print(f"   ğŸ”„ AR ëª¨ë¸: ê³¼ê±° ê°’ì˜ ì„ í˜•ê²°í•©ìœ¼ë¡œ í˜„ì¬ ì˜ˆì¸¡")
print(f"   ğŸ“Š MA ëª¨ë¸: ê³¼ê±° ì˜¤ì°¨ì˜ ì„ í˜•ê²°í•©ìœ¼ë¡œ í˜„ì¬ ì˜ˆì¸¡")
print(f"   ğŸ”„ğŸ“Š ARMA ëª¨ë¸: ARê³¼ MAì˜ ì¥ì ì„ ê²°í•©")
print(f"   ğŸ” ACF/PACF: ëª¨ë¸ ì‹ë³„ì˜ í•µì‹¬ ë„êµ¬")
print(f"\nğŸš€ ë‹¤ìŒ: ARIMA ëª¨ë¸ êµ¬ì¶• ë° ì§„ë‹¨")

## 2. ARIMA ëª¨ë¸ êµ¬ì¶• ë° ì§„ë‹¨ (Box-Jenkins ë°©ë²•ë¡ )

### 2.1 Box-Jenkins ë°©ë²•ë¡ ì˜ ì²´ê³„ì  ì ‘ê·¼

ARIMA ëª¨ë¸ë§ì˜ í™©ê¸ˆë¥ ì¸ **Box-Jenkins ë°©ë²•ë¡ **ì€ 1970ë…„ë¶€í„° 50ë…„ ë„˜ê²Œ ì‚¬ìš©ë˜ëŠ” ê²€ì¦ëœ í”„ë¡œì„¸ìŠ¤ì…ë‹ˆë‹¤. ì´ ë°©ë²•ë¡ ì€ **ì‹ë³„(Identification) â†’ ì¶”ì •(Estimation) â†’ ì§„ë‹¨(Diagnostics)**ì˜ ë°˜ë³µì  ê³¼ì •ì„ í†µí•´ ìµœì ì˜ ëª¨ë¸ì„ ì°¾ì•„ê°‘ë‹ˆë‹¤.

```python
from itertools import product
from sklearn.metrics import mean_squared_error, mean_absolute_error
import itertools

class ARIMAModelBuilder:
    """Box-Jenkins ë°©ë²•ë¡  ê¸°ë°˜ ARIMA ëª¨ë¸ êµ¬ì¶• í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.model_results = {}
        self.best_model = None
        self.diagnostics_results = {}
        
        # 7ì¥ AI í˜‘ì—… ì›ì¹™ ì ìš©
        self.box_jenkins_prompts = {
            'identification': self._create_identification_prompt(),
            'estimation': self._create_estimation_prompt(), 
            'diagnostics': self._create_diagnostics_prompt(),
            'selection': self._create_selection_prompt()
        }
    
    def box_jenkins_methodology(self, data, max_p=3, max_d=2, max_q=3):
        """Box-Jenkins ë°©ë²•ë¡  ì „ì²´ í”„ë¡œì„¸ìŠ¤"""
        
        print("ğŸ“‹ Box-Jenkins ë°©ë²•ë¡  ì‹œì‘")
        print("=" * 50)
        print("1ë‹¨ê³„: ì‹ë³„ (Identification) - ëª¨ë¸ ì°¨ìˆ˜ ê²°ì •")
        print("2ë‹¨ê³„: ì¶”ì • (Estimation) - ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¶”ì •")  
        print("3ë‹¨ê³„: ì§„ë‹¨ (Diagnostics) - ëª¨ë¸ ì í•©ì„± ê²€ì¦")
        print("4ë‹¨ê³„: ì˜ˆì¸¡ (Forecasting) - ë¯¸ë˜ ê°’ ì˜ˆì¸¡")
        
        # 1ë‹¨ê³„: ì‹ë³„ (Identification)
        print(f"\nğŸ” 1ë‹¨ê³„: ëª¨ë¸ ì‹ë³„")
        identification_results = self._identification_stage(data, max_p, max_d, max_q)
        
        # 2ë‹¨ê³„: ì¶”ì • (Estimation)
        print(f"\nğŸ“Š 2ë‹¨ê³„: ëª¨ë¸ ì¶”ì •")
        estimation_results = self._estimation_stage(data, identification_results)
        
        # 3ë‹¨ê³„: ì§„ë‹¨ (Diagnostics)
        print(f"\nğŸ”¬ 3ë‹¨ê³„: ëª¨ë¸ ì§„ë‹¨")
        diagnostics_results = self._diagnostics_stage(estimation_results)
        
        # 4ë‹¨ê³„: ëª¨ë¸ ì„ íƒ
        print(f"\nğŸ¯ 4ë‹¨ê³„: ìµœì¢… ëª¨ë¸ ì„ íƒ")
        final_model = self._selection_stage(diagnostics_results)
        
        return final_model
    
    def _identification_stage(self, data, max_p, max_d, max_q):
        """1ë‹¨ê³„: ì‹ë³„ - ì ì ˆí•œ ì°¨ìˆ˜ ê²°ì •"""
        
        print("ğŸ” ì •ìƒì„± ê²€ì • ë° ì°¨ë¶„ ì°¨ìˆ˜ ê²°ì •")
        
        # ì°¨ë¶„ ì°¨ìˆ˜ ìë™ ê²°ì •
        d_optimal = self._determine_differencing_order(data, max_d)
        
        # ì°¨ë¶„ëœ ì‹œê³„ì—´
        differenced_data = data.copy()
        for i in range(d_optimal):
            differenced_data = differenced_data.diff().dropna()
        
        print(f"   ìµœì  ì°¨ë¶„ ì°¨ìˆ˜ (d): {d_optimal}")
        print(f"   ì°¨ë¶„ í›„ ë°ì´í„° ê¸¸ì´: {len(differenced_data)}")
        
        # ACF/PACF ë¶„ì„ì„ í†µí•œ ì´ˆê¸° p, q ì¶”ì •
        initial_orders = self._analyze_acf_pacf_for_orders(differenced_data, max_p, max_q)
        
        print(f"   ACF/PACF ë¶„ì„ ê¸°ë°˜ í›„ë³´ ëª¨ë¸ë“¤:")
        for order in initial_orders[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
            print(f"     ARIMA{order}")
        
        return {
            'd_optimal': d_optimal,
            'differenced_data': differenced_data,
            'candidate_orders': initial_orders,
            'original_data': data
        }
    
    def _determine_differencing_order(self, data, max_d=2):
        """ì°¨ë¶„ ì°¨ìˆ˜ ìë™ ê²°ì •"""
        
        current_data = data.copy()
        
        for d in range(max_d + 1):
            # ADF ê²€ì •
            adf_stat, adf_pvalue, _, _, adf_critical_values, _ = adfuller(current_data, autolag='AIC')
            
            print(f"   ì°¨ë¶„ {d}íšŒ í›„ ADF ê²€ì •:")
            print(f"     í†µê³„ëŸ‰: {adf_stat:.4f}, p-ê°’: {adf_pvalue:.4f}")
            
            # ì •ìƒì„± í™•ì¸ (p < 0.05ë©´ ì •ìƒ)
            if adf_pvalue < 0.05:
                print(f"     âœ… ì •ìƒì„± í™•ë³´ (p = {adf_pvalue:.4f} < 0.05)")
                return d
            else:
                print(f"     âŒ ë¹„ì •ìƒ (p = {adf_pvalue:.4f} >= 0.05)")
                if d < max_d:
                    current_data = current_data.diff().dropna()
        
        print(f"   âš ï¸ {max_d}ì°¨ ì°¨ë¶„ê¹Œì§€ë„ ì •ìƒì„± í™•ë³´ ì‹¤íŒ¨, {max_d} ì‚¬ìš©")
        return max_d
    
    def _analyze_acf_pacf_for_orders(self, data, max_p, max_q):
        """ACF/PACF ë¶„ì„ì„ í†µí•œ ì°¨ìˆ˜ ì¶”ì •"""
        
        from statsmodels.tsa.stattools import acf, pacf
        
        # ACFì™€ PACF ê³„ì‚°
        acf_values = acf(data, nlags=max(max_p, max_q), fft=False)
        pacf_values = pacf(data, nlags=max_p)
        
        # ìœ ì˜ì„± ì„ê³„ê°’ (ëŒ€ëµ 95% ì‹ ë¢°êµ¬ê°„)
        n = len(data)
        significance_level = 1.96 / np.sqrt(n)
        
        # PACFì—ì„œ ìœ ì˜í•œ ì°¨ìˆ˜ ì°¾ê¸° (AR ì°¨ìˆ˜)
        significant_p = []
        for i in range(1, min(len(pacf_values), max_p + 1)):
            if abs(pacf_values[i]) > significance_level:
                significant_p.append(i)
        
        # ACFì—ì„œ ìœ ì˜í•œ ì°¨ìˆ˜ ì°¾ê¸° (MA ì°¨ìˆ˜)
        significant_q = []
        for i in range(1, min(len(acf_values), max_q + 1)):
            if abs(acf_values[i]) > significance_level:
                significant_q.append(i)
        
        print(f"   PACF ê¸°ë°˜ ìœ ì˜í•œ AR ì°¨ìˆ˜: {significant_p[:3]}")  # ìµœëŒ€ 3ê°œ
        print(f"   ACF ê¸°ë°˜ ìœ ì˜í•œ MA ì°¨ìˆ˜: {significant_q[:3]}")   # ìµœëŒ€ 3ê°œ
        
        # í›„ë³´ ì¡°í•© ìƒì„±
        p_candidates = significant_p[:3] if significant_p else [0, 1, 2]
        q_candidates = significant_q[:3] if significant_q else [0, 1, 2]
        
        candidate_orders = []
        for p in p_candidates:
            for q in q_candidates:
                candidate_orders.append((p, 0, q))  # dëŠ” ë³„ë„ë¡œ ê²°ì •ë¨
        
        return candidate_orders
    
    def _estimation_stage(self, data, identification_results):
        """2ë‹¨ê³„: ì¶”ì • - ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¶”ì •"""
        
        d = identification_results['d_optimal']
        candidate_orders = identification_results['candidate_orders']
        original_data = identification_results['original_data']
        
        print(f"ğŸ“Š {len(candidate_orders)}ê°œ í›„ë³´ ëª¨ë¸ ì¶”ì • ì¤‘...")
        
        estimated_models = {}
        
        for i, (p, _, q) in enumerate(candidate_orders):
            order = (p, d, q)
            
            try:
                print(f"   ëª¨ë¸ {i+1}: ARIMA{order} ì¶”ì • ì¤‘...")
                
                # ëª¨ë¸ ì í•©
                model = ARIMA(original_data, order=order)
                fitted_model = model.fit()
                
                # ê¸°ë³¸ ì •ë³´ ì €ì¥
                estimated_models[order] = {
                    'model': fitted_model,
                    'aic': fitted_model.aic,
                    'bic': fitted_model.bic,
                    'llf': fitted_model.llf,
                    'params': fitted_model.params,
                    'order': order,
                    'fitted_values': fitted_model.fittedvalues,
                    'residuals': fitted_model.resid
                }
                
                print(f"     âœ… ì„±ê³µ - AIC: {fitted_model.aic:.2f}, BIC: {fitted_model.bic:.2f}")
                
            except Exception as e:
                print(f"     âŒ ì‹¤íŒ¨ - {str(e)[:50]}...")
                continue
        
        print(f"\nğŸ“Š ì¶”ì • ì™„ë£Œ: {len(estimated_models)}ê°œ ëª¨ë¸ ì„±ê³µ")
        
        # ê²°ê³¼ë¥¼ AIC ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_models = dict(sorted(estimated_models.items(), 
                                  key=lambda x: x[1]['aic']))
        
        print(f"\nğŸ† ì •ë³´ê¸°ì¤€ ìƒìœ„ 5ê°œ ëª¨ë¸:")
        for i, (order, result) in enumerate(list(sorted_models.items())[:5]):
            print(f"   {i+1}. ARIMA{order}: AIC={result['aic']:.2f}, BIC={result['bic']:.2f}")
        
        return sorted_models
    
    def _diagnostics_stage(self, estimation_results):
        """3ë‹¨ê³„: ì§„ë‹¨ - ëª¨ë¸ ì í•©ì„± ê²€ì¦"""
        
        print(f"ğŸ”¬ ëª¨ë¸ ì§„ë‹¨ ì‹¤ì‹œ ì¤‘...")
        
        diagnostics_results = {}
        
        for order, model_result in estimation_results.items():
            print(f"\n   ARIMA{order} ì§„ë‹¨:")
            
            fitted_model = model_result['model']
            residuals = model_result['residuals']
            
            # ì§„ë‹¨ í…ŒìŠ¤íŠ¸ë“¤
            diagnostic_tests = self._comprehensive_diagnostics(fitted_model, residuals)
            
            # ì¢…í•© ì ìˆ˜ ê³„ì‚°
            overall_score = self._calculate_overall_score(model_result, diagnostic_tests)
            
            diagnostics_results[order] = {
                **model_result,
                'diagnostics': diagnostic_tests,
                'overall_score': overall_score
            }
            
            print(f"     ì¢…í•© ì ìˆ˜: {overall_score:.2f}/100")
        
        return diagnostics_results
    
    def _comprehensive_diagnostics(self, fitted_model, residuals):
        """ì¢…í•©ì ì¸ ì§„ë‹¨ í…ŒìŠ¤íŠ¸"""
        
        diagnostics = {}
        
        # 1. Ljung-Box ê²€ì • (ì”ì°¨ì˜ ìê¸°ìƒê´€ ê²€ì •)
        try:
            ljung_box_result = acorr_ljungbox(residuals, lags=10, return_df=True)
            ljung_box_pvalue = ljung_box_result['lb_pvalue'].iloc[-1]  # 10ì°¨ ì§€ì—°ì˜ p-ê°’
            
            diagnostics['ljung_box'] = {
                'statistic': ljung_box_result['lb_stat'].iloc[-1],
                'pvalue': ljung_box_pvalue,
                'passed': ljung_box_pvalue > 0.05,
                'interpretation': 'Good' if ljung_box_pvalue > 0.05 else 'Poor'
            }
            print(f"       Ljung-Box: p={ljung_box_pvalue:.4f} ({'âœ…' if ljung_box_pvalue > 0.05 else 'âŒ'})")
            
        except Exception as e:
            diagnostics['ljung_box'] = {'error': str(e), 'passed': False}
            print(f"       Ljung-Box: ê³„ì‚° ì‹¤íŒ¨")
        
        # 2. Jarque-Bera ì •ê·œì„± ê²€ì •
        try:
            jb_stat, jb_pvalue = stats.jarque_bera(residuals.dropna())
            
            diagnostics['jarque_bera'] = {
                'statistic': jb_stat,
                'pvalue': jb_pvalue,
                'passed': jb_pvalue > 0.05,
                'interpretation': 'Normal' if jb_pvalue > 0.05 else 'Non-normal'
            }
            print(f"       Jarque-Bera: p={jb_pvalue:.4f} ({'âœ…' if jb_pvalue > 0.05 else 'âŒ'})")
            
        except Exception as e:
            diagnostics['jarque_bera'] = {'error': str(e), 'passed': False}
            print(f"       Jarque-Bera: ê³„ì‚° ì‹¤íŒ¨")
        
        # 3. ì”ì°¨ ê¸°ë³¸ í†µê³„
        residuals_clean = residuals.dropna()
        diagnostics['residual_stats'] = {
            'mean': residuals_clean.mean(),
            'std': residuals_clean.std(),
            'skewness': stats.skew(residuals_clean),
            'kurtosis': stats.kurtosis(residuals_clean),
            'mean_near_zero': abs(residuals_clean.mean()) < 0.1 * residuals_clean.std()
        }
        
        print(f"       ì”ì°¨ í‰ê· : {residuals_clean.mean():.4f}")
        print(f"       ì”ì°¨ í‘œì¤€í¸ì°¨: {residuals_clean.std():.4f}")
        
        # 4. ì˜ˆì¸¡ ì„±ëŠ¥ (í›ˆë ¨ ë°ì´í„° ë‚´)
        try:
            original_data = fitted_model.model.endog
            fitted_values = fitted_model.fittedvalues
            
            # ê²°ì¸¡ê°’ ì œê±°í•˜ê³  ê¸¸ì´ ë§ì¶”ê¸°
            valid_idx = ~np.isnan(fitted_values)
            original_clean = original_data[valid_idx]
            fitted_clean = fitted_values[valid_idx]
            
            if len(original_clean) > 0 and len(fitted_clean) > 0:
                mse = mean_squared_error(original_clean, fitted_clean)
                mae = mean_absolute_error(original_clean, fitted_clean)
                
                diagnostics['prediction_performance'] = {
                    'mse': mse,
                    'mae': mae,
                    'rmse': np.sqrt(mse)
                }
                print(f"       RMSE: {np.sqrt(mse):.4f}")
            
        except Exception as e:
            diagnostics['prediction_performance'] = {'error': str(e)}
            print(f"       ì˜ˆì¸¡ ì„±ëŠ¥: ê³„ì‚° ì‹¤íŒ¨")
        
        return diagnostics
    
    def _calculate_overall_score(self, model_result, diagnostics):
        """ì¢…í•© ì ìˆ˜ ê³„ì‚° (0-100ì )"""
        
        score = 0
        max_score = 100
        
        # 1. ì •ë³´ê¸°ì¤€ ì ìˆ˜ (40ì )
        aic_score = 20  # ê¸°ë³¸ì ìˆ˜
        bic_score = 20  # ê¸°ë³¸ì ìˆ˜
        
        # AIC/BICê°€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ ì—­ë³€í™˜
        # ì—¬ê¸°ì„œëŠ” ìƒëŒ€ì  ë¹„êµë¥¼ ìœ„í•´ ë‹¨ìˆœí™”
        score += aic_score + bic_score
        
        # 2. ì§„ë‹¨ í…ŒìŠ¤íŠ¸ ì ìˆ˜ (40ì )
        if 'ljung_box' in diagnostics and diagnostics['ljung_box'].get('passed', False):
            score += 20
        
        if 'jarque_bera' in diagnostics and diagnostics['jarque_bera'].get('passed', False):
            score += 10
        
        if 'residual_stats' in diagnostics and diagnostics['residual_stats'].get('mean_near_zero', False):
            score += 10
        
        # 3. íŒŒë¼ë¯¸í„° ìœ ì˜ì„± ì ìˆ˜ (20ì )
        try:
            pvalues = model_result['model'].pvalues
            significant_params = (pvalues < 0.05).sum()
            total_params = len(pvalues)
            
            if total_params > 0:
                param_score = (significant_params / total_params) * 20
                score += param_score
        except:
            pass
        
        return min(score, max_score)
    
    def _selection_stage(self, diagnostics_results):
        """4ë‹¨ê³„: ìµœì¢… ëª¨ë¸ ì„ íƒ"""
        
        print(f"ğŸ¯ ìµœì¢… ëª¨ë¸ ì„ íƒ ê¸°ì¤€:")
        print(f"   1. ì§„ë‹¨ í…ŒìŠ¤íŠ¸ í†µê³¼ ì—¬ë¶€ (ê°€ì¥ ì¤‘ìš”)")
        print(f"   2. ì •ë³´ê¸°ì¤€ (AIC/BIC) ìµœì†Œí™”")
        print(f"   3. íŒŒë¼ë¯¸í„° ìœ ì˜ì„±")
        print(f"   4. ëª¨ë¸ ë³µì¡ë„ (ë‹¨ìˆœí•¨ ì„ í˜¸)")
        
        # ì§„ë‹¨ì„ í†µê³¼í•œ ëª¨ë¸ë“¤ë§Œ í•„í„°ë§
        valid_models = {}
        for order, result in diagnostics_results.items():
            diag = result['diagnostics']
            
            # ê¸°ë³¸ ì¡°ê±´: Ljung-Box í…ŒìŠ¤íŠ¸ í†µê³¼
            ljung_box_passed = diag.get('ljung_box', {}).get('passed', False)
            
            if ljung_box_passed:
                valid_models[order] = result
                print(f"   âœ… ARIMA{order}: ì§„ë‹¨ í†µê³¼")
            else:
                print(f"   âŒ ARIMA{order}: ì§„ë‹¨ ì‹¤íŒ¨")
        
        if not valid_models:
            print(f"   âš ï¸ ëª¨ë“  ëª¨ë¸ì´ ì§„ë‹¨ ì‹¤íŒ¨. AIC ê¸°ì¤€ìœ¼ë¡œ ì„ íƒ")
            valid_models = diagnostics_results
        
        # ì¢…í•© ì ìˆ˜ë¡œ ìµœì¢… ì„ íƒ
        best_order = max(valid_models.keys(), 
                        key=lambda x: valid_models[x]['overall_score'])
        
        best_model = valid_models[best_order]
        
        print(f"\nğŸ† ìµœì¢… ì„ íƒ ëª¨ë¸: ARIMA{best_order}")
        print(f"   ì¢…í•© ì ìˆ˜: {best_model['overall_score']:.2f}/100")
        print(f"   AIC: {best_model['aic']:.2f}")
        print(f"   BIC: {best_model['bic']:.2f}")
        
        # ìƒì„¸ ì§„ë‹¨ ê²°ê³¼ ì¶œë ¥
        self._print_detailed_diagnostics(best_order, best_model)
        
        return best_model
    
    def _print_detailed_diagnostics(self, order, model_result):
        """ìƒì„¸ ì§„ë‹¨ ê²°ê³¼ ì¶œë ¥"""
        
        print(f"\nğŸ“‹ ARIMA{order} ìƒì„¸ ì§„ë‹¨ ê²°ê³¼:")
        print("-" * 40)
        
        fitted_model = model_result['model']
        diagnostics = model_result['diagnostics']
        
        # 1. ëª¨ë¸ ìš”ì•½
        print(f"ğŸ“Š ëª¨ë¸ ì •ë³´:")
        print(f"   ì°¨ìˆ˜: {order}")
        print(f"   ë¡œê·¸ìš°ë„: {fitted_model.llf:.4f}")
        print(f"   AIC: {fitted_model.aic:.4f}")
        print(f"   BIC: {fitted_model.bic:.4f}")
        
        # 2. íŒŒë¼ë¯¸í„° ì¶”ì •ì¹˜
        print(f"\nğŸ”¢ íŒŒë¼ë¯¸í„° ì¶”ì •ì¹˜:")
        for param_name, param_value in fitted_model.params.items():
            pvalue = fitted_model.pvalues[param_name]
            significance = "***" if pvalue < 0.001 else "**" if pvalue < 0.01 else "*" if pvalue < 0.05 else ""
            print(f"   {param_name}: {param_value:.4f} (p={pvalue:.4f}) {significance}")
        
        # 3. ì§„ë‹¨ í…ŒìŠ¤íŠ¸ ê²°ê³¼
        print(f"\nğŸ”¬ ì§„ë‹¨ í…ŒìŠ¤íŠ¸:")
        
        ljung_box = diagnostics.get('ljung_box', {})
        if 'pvalue' in ljung_box:
            status = "í†µê³¼" if ljung_box['passed'] else "ì‹¤íŒ¨"
            print(f"   Ljung-Box (ìê¸°ìƒê´€): p={ljung_box['pvalue']:.4f} ({status})")
        
        jarque_bera = diagnostics.get('jarque_bera', {})
        if 'pvalue' in jarque_bera:
            status = "ì •ê·œë¶„í¬" if jarque_bera['passed'] else "ë¹„ì •ê·œë¶„í¬"
            print(f"   Jarque-Bera (ì •ê·œì„±): p={jarque_bera['pvalue']:.4f} ({status})")
        
        residual_stats = diagnostics.get('residual_stats', {})
        if residual_stats:
            print(f"   ì”ì°¨ í‰ê· : {residual_stats['mean']:.6f}")
            print(f"   ì”ì°¨ í‘œì¤€í¸ì°¨: {residual_stats['std']:.4f}")
        
        # 4. ì˜ˆì¸¡ ì„±ëŠ¥
        pred_perf = diagnostics.get('prediction_performance', {})
        if 'rmse' in pred_perf:
            print(f"\nğŸ“ˆ ì˜ˆì¸¡ ì„±ëŠ¥ (í›ˆë ¨ ë°ì´í„°):")
            print(f"   RMSE: {pred_perf['rmse']:.4f}")
            print(f"   MAE: {pred_perf['mae']:.4f}")
    
    def visualize_model_diagnostics(self, model_result):
        """ëª¨ë¸ ì§„ë‹¨ ì‹œê°í™”"""
        
        fitted_model = model_result['model']
        residuals = fitted_model.resid
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle(f'ğŸ”¬ ARIMA{model_result["order"]} ëª¨ë¸ ì§„ë‹¨', fontsize=16, fontweight='bold')
        
        # 1. ì”ì°¨ í”Œë¡¯
        axes[0, 0].plot(residuals, color='blue', alpha=0.7)
        axes[0, 0].axhline(y=0, color='red', linestyle='--', alpha=0.8)
        axes[0, 0].set_title('ğŸ“Š ì”ì°¨ ì‹œê³„ì—´', fontweight='bold')
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. ì”ì°¨ íˆìŠ¤í† ê·¸ë¨
        axes[0, 1].hist(residuals.dropna(), bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0, 1].set_title('ğŸ“ˆ ì”ì°¨ ë¶„í¬', fontweight='bold')
        axes[0, 1].grid(True, alpha=0.3)
        
        # ì •ê·œë¶„í¬ ê³¡ì„  ì¶”ê°€
        residuals_clean = residuals.dropna()
        if len(residuals_clean) > 0:
            mu, sigma = residuals_clean.mean(), residuals_clean.std()
            x = np.linspace(residuals_clean.min(), residuals_clean.max(), 100)
            y = stats.norm.pdf(x, mu, sigma)
            axes[0, 1].plot(x, y * len(residuals_clean) * (x[1] - x[0]), 'r-', linewidth=2, label='ì •ê·œë¶„í¬')
            axes[0, 1].legend()
        
        # 3. Q-Q í”Œë¡¯
        stats.probplot(residuals.dropna(), dist="norm", plot=axes[1, 0])
        axes[1, 0].set_title('ğŸ“‹ Q-Q Plot (ì •ê·œì„± ê²€ì •)', fontweight='bold')
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. ì”ì°¨ ACF
        plot_acf(residuals.dropna(), lags=20, ax=axes[1, 1], title='ğŸ” ì”ì°¨ ACF (ë°±ìƒ‰ì¡ìŒ í™•ì¸)')
        
        plt.tight_layout()
        plt.show()
    
    def _create_identification_prompt(self):
        """ì‹ë³„ ë‹¨ê³„ìš© AI í”„ë¡¬í”„íŠ¸"""
        return """
ì‹œê³„ì—´ ëª¨ë¸ ì‹ë³„ ì „ë¬¸ê°€ë¡œì„œ ACF/PACF íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ìš”ì²­ì‚¬í•­**:
1. ACF/PACF íŒ¨í„´ì— ê¸°ë°˜í•œ ëª¨ë¸ ì°¨ìˆ˜ ì¶”ì²œ
2. ì •ìƒì„± ê²€ì • ê²°ê³¼ í•´ì„
3. ì°¨ë¶„ì˜ í•„ìš”ì„±ê³¼ ì ì • ì°¨ìˆ˜
4. ì´ˆê¸° ëª¨ë¸ í›„ë³´ë“¤ì˜ ìš°ì„ ìˆœìœ„

**ë°ì´í„°**: {data_summary}
**ACF íŒ¨í„´**: {acf_pattern}
**PACF íŒ¨í„´**: {pacf_pattern}
**ì •ìƒì„± ê²€ì •**: {stationarity_tests}

Box-Jenkins ê´€ì ì—ì„œ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
        """

# ARIMA ëª¨ë¸ êµ¬ì¶• ì‹œìŠ¤í…œ ì‹¤í–‰
arima_builder = ARIMAModelBuilder()

print("\nğŸ“‹ Box-Jenkins ë°©ë²•ë¡ ìœ¼ë¡œ ARIMA ëª¨ë¸ êµ¬ì¶•")
print("=" * 60)

# ì‹¤ì œ ë°ì´í„°ë¡œ ARIMA ëª¨ë¸ë§ ì‹œì—°
# 8ì¥ Part 1ì—ì„œ ìƒì„±í•œ ë§¤ì¶œ ë°ì´í„° ì‚¬ìš©
if 'sample_data' in globals():
    sales_data = sample_data['sales'].dropna()
    
    # ì›”ë³„ ë°ì´í„°ë¡œ ì§‘ê³„ (ë…¸ì´ì¦ˆ ê°ì†Œ)
    monthly_sales = sales_data.resample('M').mean()
    
    print(f"ğŸ¯ ë¶„ì„ ëŒ€ìƒ ë°ì´í„°:")
    print(f"   ì‹œê³„ì—´: ì›”ë³„ ë§¤ì¶œ ë°ì´í„°")
    print(f"   ê¸°ê°„: {monthly_sales.index.min().date()} ~ {monthly_sales.index.max().date()}")
    print(f"   ê´€ì¸¡ê°’: {len(monthly_sales)}ê°œ")
    print(f"   í‰ê· : {monthly_sales.mean():.2f}")
    print(f"   í‘œì¤€í¸ì°¨: {monthly_sales.std():.2f}")
    
    # Box-Jenkins ë°©ë²•ë¡  ì ìš©
    final_arima_model = arima_builder.box_jenkins_methodology(
        monthly_sales, 
        max_p=3, 
        max_d=2, 
        max_q=3
    )
    
    # ì§„ë‹¨ ì‹œê°í™”
    print(f"\nğŸ”¬ ëª¨ë¸ ì§„ë‹¨ ì‹œê°í™”:")
    arima_builder.visualize_model_diagnostics(final_arima_model)
    
else:
    print("âš ï¸ ìƒ˜í”Œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
    
    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    dates = pd.date_range('2021-01-01', '2023-12-31', freq='M')
    trend = np.linspace(100, 150, len(dates))
    seasonal = 10 * np.sin(2 * np.pi * np.arange(len(dates)) / 12)
    noise = np.random.normal(0, 5, len(dates))
    simulated_sales = trend + seasonal + noise
    
    sales_ts = pd.Series(simulated_sales, index=dates, name='sales')
    
    print(f"ğŸ¯ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ ARIMA ëª¨ë¸ë§:")
    print(f"   ê¸°ê°„: {sales_ts.index.min().date()} ~ {sales_ts.index.max().date()}")
    print(f"   ê´€ì¸¡ê°’: {len(sales_ts)}ê°œ")
    
    # Box-Jenkins ë°©ë²•ë¡  ì ìš©
    final_arima_model = arima_builder.box_jenkins_methodology(
        sales_ts,
        max_p=3,
        max_d=2, 
        max_q=3
    )
    
    # ì§„ë‹¨ ì‹œê°í™”
    print(f"\nğŸ”¬ ëª¨ë¸ ì§„ë‹¨ ì‹œê°í™”:")
    arima_builder.visualize_model_diagnostics(final_arima_model)

print(f"\nâœ… ARIMA ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ!")
print(f"   ğŸ“‹ Box-Jenkins 4ë‹¨ê³„ ë°©ë²•ë¡  ì™„ì „ ì ìš©")
print(f"   ğŸ” ì²´ê³„ì ì¸ ëª¨ë¸ ì‹ë³„ ë° ì§„ë‹¨")
print(f"   ğŸ“Š ì •ë³´ê¸°ì¤€ê³¼ ì§„ë‹¨ í…ŒìŠ¤íŠ¸ ì¢…í•© í‰ê°€") 
print(f"   ğŸ¯ ìµœì  ëª¨ë¸ ìë™ ì„ íƒ ë° ê²€ì¦")
print(f"\nğŸš€ ë‹¤ìŒ: ê³„ì ˆì„± SARIMA ëª¨ë¸ê³¼ ì§€ìˆ˜í‰í™œë²•")

## 3. ê³„ì ˆì„± ëª¨ë¸ (SARIMA)ì™€ ì§€ìˆ˜í‰í™œë²•

### 3.1 SARIMA ëª¨ë¸ - ê³„ì ˆì„±ê¹Œì§€ ê³ ë ¤í•œ ê³ ê¸‰ ëª¨ë¸ë§

ëŒ€ë¶€ë¶„ì˜ ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„°ëŠ” **ê³„ì ˆì„±(Seasonality)**ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë§¤ì¶œì˜ ì—°ë§ ì¦ê°€, ì „ë ¥ ì†Œë¹„ì˜ ì—¬ë¦„/ê²¨ìš¸ íŒ¨í„´, ê´€ê´‘ê° ìˆ˜ì˜ ê³„ì ˆë³„ ë³€ë™ ë“±ì´ ê·¸ ì˜ˆì…ë‹ˆë‹¤. SARIMA ëª¨ë¸ì€ ì´ëŸ¬í•œ ê³„ì ˆì„±ì„ ì²´ê³„ì ìœ¼ë¡œ ëª¨ë¸ë§í•˜ëŠ” ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤.

```python
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.exponential_smoothing.exponential_smoothing import ExponentialSmoothing
from sklearn.metrics import mean_absolute_percentage_error

class SeasonalTimeSeriesModels:
    """ê³„ì ˆì„± ì‹œê³„ì—´ ëª¨ë¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.models = {}
        self.forecasts = {}
        self.performance_metrics = {}
        
        # 7ì¥ AI í˜‘ì—… ì›ì¹™ì„ ê³„ì ˆì„± ë¶„ì„ì— ì ìš©
        self.seasonal_analysis_prompts = {
            'decomposition': self._create_decomposition_prompt(),
            'sarima_interpretation': self._create_sarima_prompt(),
            'exponential_smoothing': self._create_exponential_smoothing_prompt(),
            'model_comparison': self._create_comparison_prompt()
        }
    
    def demonstrate_sarima_concept(self):
        """SARIMA ëª¨ë¸ ê°œë… ì„¤ëª…"""
        
        print("ğŸ”„ SARIMA ëª¨ë¸ ì´í•´í•˜ê¸°")
        print("=" * 50)
        print("SARIMA(p,d,q)(P,D,Q)s = ê³„ì ˆì„± ARIMA ëª¨ë¸")
        print()
        print("ğŸ“Š ì¼ë°˜ ë¶€ë¶„ (ì†Œë¬¸ì):")
        print("   p: ë¹„ê³„ì ˆ ìê¸°íšŒê·€ ì°¨ìˆ˜")
        print("   d: ë¹„ê³„ì ˆ ì°¨ë¶„ ì°¨ìˆ˜") 
        print("   q: ë¹„ê³„ì ˆ ì´ë™í‰ê·  ì°¨ìˆ˜")
        print()
        print("ğŸ”„ ê³„ì ˆ ë¶€ë¶„ (ëŒ€ë¬¸ì):")
        print("   P: ê³„ì ˆ ìê¸°íšŒê·€ ì°¨ìˆ˜")
        print("   D: ê³„ì ˆ ì°¨ë¶„ ì°¨ìˆ˜")
        print("   Q: ê³„ì ˆ ì´ë™í‰ê·  ì°¨ìˆ˜")
        print("   s: ê³„ì ˆ ì£¼ê¸° (ì›”ë³„=12, ë¶„ê¸°ë³„=4, ì£¼ë³„=52)")
        
        # ê³„ì ˆì„± ìˆëŠ” ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
        np.random.seed(42)
        periods = 60  # 5ë…„ì¹˜ ì›”ë³„ ë°ì´í„°
        dates = pd.date_range('2019-01-01', periods=periods, freq='M')
        
        # íŠ¸ë Œë“œ ì„±ë¶„
        trend = np.linspace(100, 140, periods)
        
        # ê³„ì ˆì„± ì„±ë¶„ (ì—°ê°„ ì£¼ê¸°)
        seasonal = 15 * np.sin(2 * np.pi * np.arange(periods) / 12)
        
        # ê³„ì ˆì„± AR ì„±ë¶„ (ì´ì „ í•´ ê°™ì€ ë‹¬ì˜ ì˜í–¥)
        seasonal_ar = np.zeros(periods)
        for t in range(12, periods):
            seasonal_ar[t] = 0.7 * seasonal_ar[t-12] + np.random.normal(0, 2)
        
        # ë…¸ì´ì¦ˆ
        noise = np.random.normal(0, 3, periods)
        
        # ìµœì¢… ì‹œê³„ì—´
        seasonal_ts = trend + seasonal + seasonal_ar + noise
        seasonal_data = pd.Series(seasonal_ts, index=dates, name='seasonal_sales')
        
        print(f"\nğŸ“Š ê³„ì ˆì„± ì‹œê³„ì—´ ìƒì„±:")
        print(f"   ê¸°ê°„: {seasonal_data.index.min().date()} ~ {seasonal_data.index.max().date()}")
        print(f"   ê´€ì¸¡ê°’: {len(seasonal_data)}ê°œ")
        print(f"   ê³„ì ˆ ì£¼ê¸°: 12ê°œì›”")
        
        # ê³„ì ˆì„± ë¶„í•´
        decomposition = seasonal_decompose(seasonal_data, model='additive', period=12)
        
        # ë¶„í•´ ê²°ê³¼ ì‹œê°í™”
        fig, axes = plt.subplots(4, 1, figsize=(15, 12))
        fig.suptitle('ğŸ”„ ê³„ì ˆì„± ì‹œê³„ì—´ ë¶„í•´ ë¶„ì„', fontsize=16, fontweight='bold')
        
        # ì›ë³¸ ë°ì´í„°
        axes[0].plot(seasonal_data.index, seasonal_data.values, color='black', linewidth=2)
        axes[0].set_title('ğŸ“Š ì›ë³¸ ë°ì´í„° (íŠ¸ë Œë“œ + ê³„ì ˆì„± + ë…¸ì´ì¦ˆ)', fontweight='bold')
        axes[0].grid(True, alpha=0.3)
        
        # íŠ¸ë Œë“œ
        axes[1].plot(decomposition.trend.index, decomposition.trend.values, color='blue', linewidth=2)
        axes[1].set_title('ğŸ“ˆ íŠ¸ë Œë“œ ì„±ë¶„', fontweight='bold')
        axes[1].grid(True, alpha=0.3)
        
        # ê³„ì ˆì„±
        axes[2].plot(decomposition.seasonal.index, decomposition.seasonal.values, color='green', linewidth=2)
        axes[2].set_title('ğŸ”„ ê³„ì ˆì„± ì„±ë¶„ (ì—°ê°„ ë°˜ë³µ)', fontweight='bold')
        axes[2].grid(True, alpha=0.3)
        
        # ì”ì°¨
        axes[3].plot(decomposition.resid.index, decomposition.resid.values, color='red', linewidth=1)
        axes[3].set_title('ğŸ² ì”ì°¨ ì„±ë¶„ (ë…¸ì´ì¦ˆ)', fontweight='bold')
        axes[3].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # ê³„ì ˆì„± ê°•ë„ ë¶„ì„
        seasonal_strength = decomposition.seasonal.std() / seasonal_data.std()
        print(f"\nğŸ” ê³„ì ˆì„± ë¶„ì„:")
        print(f"   ê³„ì ˆì„± ê°•ë„: {seasonal_strength:.1%}")
        print(f"   íŠ¸ë Œë“œ ë°©í–¥: {'ìƒìŠ¹' if decomposition.trend.dropna().iloc[-1] > decomposition.trend.dropna().iloc[0] else 'í•˜ë½'}")
        print(f"   ê³„ì ˆ í”¼í¬: {decomposition.seasonal.groupby(decomposition.seasonal.index.month).mean().idxmax()}ì›”")
        print(f"   ê³„ì ˆ ì €ì : {decomposition.seasonal.groupby(decomposition.seasonal.index.month).mean().idxmin()}ì›”")
        
        return seasonal_data, decomposition
    
    def build_sarima_model(self, data, seasonal_period=12):
        """SARIMA ëª¨ë¸ êµ¬ì¶•"""
        
        print(f"\nğŸ”„ SARIMA ëª¨ë¸ êµ¬ì¶• (ê³„ì ˆ ì£¼ê¸°: {seasonal_period})")
        print("=" * 50)
        
        # ìë™ SARIMA ëª¨ë¸ ì„ íƒì„ ìœ„í•œ ê·¸ë¦¬ë“œ ì„œì¹˜
        print("ğŸ” SARIMA ì°¨ìˆ˜ ìë™ ì„ íƒ ì¤‘...")
        
        # í›„ë³´ ì°¨ìˆ˜ë“¤
        p_values = range(0, 3)  # ì¼ë°˜ AR ì°¨ìˆ˜
        d_values = range(0, 2)  # ì¼ë°˜ ì°¨ë¶„ ì°¨ìˆ˜
        q_values = range(0, 3)  # ì¼ë°˜ MA ì°¨ìˆ˜
        
        P_values = range(0, 2)  # ê³„ì ˆ AR ì°¨ìˆ˜
        D_values = range(0, 2)  # ê³„ì ˆ ì°¨ë¶„ ì°¨ìˆ˜  
        Q_values = range(0, 2)  # ê³„ì ˆ MA ì°¨ìˆ˜
        
        # ëª¨ë“  ì¡°í•© ìƒì„±
        pdq_combinations = list(itertools.product(p_values, d_values, q_values))
        PDQ_combinations = list(itertools.product(P_values, D_values, Q_values))
        
        best_aic = float('inf')
        best_model = None
        best_order = None
        best_seasonal_order = None
        
        model_results = []
        
        print(f"   ì´ {len(pdq_combinations) * len(PDQ_combinations)}ê°œ ì¡°í•© í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        for pdq in pdq_combinations[:3]:  # ê³„ì‚° ì‹œê°„ ë‹¨ì¶•ì„ ìœ„í•´ ì œí•œ
            for PDQ in PDQ_combinations[:3]:
                try:
                    # SARIMA ëª¨ë¸ ìƒì„±
                    order = pdq
                    seasonal_order = PDQ + (seasonal_period,)
                    
                    model = SARIMAX(data, 
                                   order=order,
                                   seasonal_order=seasonal_order,
                                   enforce_stationarity=False,
                                   enforce_invertibility=False)
                    
                    fitted_model = model.fit(disp=False)
                    
                    # AIC ê¸°ì¤€ìœ¼ë¡œ ìµœì  ëª¨ë¸ ì„ íƒ
                    if fitted_model.aic < best_aic:
                        best_aic = fitted_model.aic
                        best_model = fitted_model
                        best_order = order
                        best_seasonal_order = seasonal_order
                    
                    model_results.append({
                        'order': order,
                        'seasonal_order': seasonal_order,
                        'aic': fitted_model.aic,
                        'bic': fitted_model.bic,
                        'model': fitted_model
                    })
                    
                except Exception as e:
                    continue
        
        # ê²°ê³¼ ì •ë ¬ ë° ì¶œë ¥
        model_results.sort(key=lambda x: x['aic'])
        
        print(f"\nğŸ† ìƒìœ„ 5ê°œ SARIMA ëª¨ë¸:")
        for i, result in enumerate(model_results[:5]):
            order = result['order']
            seasonal_order = result['seasonal_order']
            print(f"   {i+1}. SARIMA{order}x{seasonal_order}: AIC={result['aic']:.2f}")
        
        if best_model is not None:
            print(f"\nğŸ¯ ì„ íƒëœ ìµœì  ëª¨ë¸:")
            print(f"   SARIMA{best_order}x{best_seasonal_order}")
            print(f"   AIC: {best_aic:.2f}")
            print(f"   BIC: {best_model.bic:.2f}")
            
            # ëª¨ë¸ ìš”ì•½
            print(f"\nğŸ“Š ëª¨ë¸ ìš”ì•½:")
            print(f"   ì¼ë°˜ ë¶€ë¶„: AR({best_order[0]}) I({best_order[1]}) MA({best_order[2]})")
            print(f"   ê³„ì ˆ ë¶€ë¶„: AR({best_seasonal_order[0]}) I({best_seasonal_order[1]}) MA({best_seasonal_order[2]}) [{best_seasonal_order[3]}]")
            
            return best_model, model_results
        else:
            print("âŒ SARIMA ëª¨ë¸ êµ¬ì¶• ì‹¤íŒ¨")
            return None, []
    
    def demonstrate_exponential_smoothing(self, data):
        """ì§€ìˆ˜í‰í™œë²• ëª¨ë¸ë“¤ ì‹œì—°"""
        
        print(f"\nğŸ“Š ì§€ìˆ˜í‰í™œë²• (Exponential Smoothing) ëª¨ë¸ë“¤")
        print("=" * 50)
        print("ì§€ìˆ˜í‰í™œë²•: ìµœê·¼ ê´€ì¸¡ê°’ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ì˜ˆì¸¡ ë°©ë²•")
        print("íŠ¹ì§•: ì§ê´€ì ì´ê³  ê³„ì‚°ì´ ê°„ë‹¨í•˜ë©° ì‹¤ë¬´ì—ì„œ ë„ë¦¬ ì‚¬ìš©")
        
        # ë‹¤ì–‘í•œ ì§€ìˆ˜í‰í™œë²• ëª¨ë¸ë“¤
        smoothing_models = {}
        
        # 1. ë‹¨ìˆœ ì§€ìˆ˜í‰í™œë²• (Simple Exponential Smoothing)
        print(f"\n1ï¸âƒ£ ë‹¨ìˆœ ì§€ìˆ˜í‰í™œë²• (SES)")
        print("   ì ìš©: íŠ¸ë Œë“œì™€ ê³„ì ˆì„±ì´ ì—†ëŠ” ë°ì´í„°")
        print("   ìˆ˜ì‹: F(t+1) = Î±X(t) + (1-Î±)F(t)")
        
        try:
            ses_model = ExponentialSmoothing(data, trend=None, seasonal=None)
            ses_fitted = ses_model.fit()
            smoothing_models['SES'] = ses_fitted
            print(f"   âœ… Î± (í‰í™œê³„ìˆ˜): {ses_fitted.params['smoothing_level']:.4f}")
        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {str(e)[:50]}...")
        
        # 2. Holt ì„ í˜• íŠ¸ë Œë“œ (Double Exponential Smoothing)
        print(f"\n2ï¸âƒ£ Holt ì„ í˜• íŠ¸ë Œë“œ")
        print("   ì ìš©: íŠ¸ë Œë“œê°€ ìˆì§€ë§Œ ê³„ì ˆì„±ì´ ì—†ëŠ” ë°ì´í„°")
        print("   ìˆ˜ì‹: Level + Trend ì„±ë¶„ì„ ë³„ë„ë¡œ í‰í™œí™”")
        
        try:
            holt_model = ExponentialSmoothing(data, trend='add', seasonal=None)
            holt_fitted = holt_model.fit()
            smoothing_models['Holt'] = holt_fitted
            print(f"   âœ… Î± (level): {holt_fitted.params['smoothing_level']:.4f}")
            print(f"   âœ… Î² (trend): {holt_fitted.params['smoothing_trend']:.4f}")
        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {str(e)[:50]}...")
        
        # 3. Holt-Winters ê°€ë²•ì  ëª¨ë¸
        print(f"\n3ï¸âƒ£ Holt-Winters ê°€ë²•ì  ëª¨ë¸")
        print("   ì ìš©: íŠ¸ë Œë“œì™€ ê³„ì ˆì„±ì´ ëª¨ë‘ ìˆëŠ” ë°ì´í„°")
        print("   ìˆ˜ì‹: Level + Trend + Seasonal (ê°€ë²•ì  ê²°í•©)")
        
        try:
            hw_add_model = ExponentialSmoothing(data, trend='add', seasonal='add', seasonal_periods=12)
            hw_add_fitted = hw_add_model.fit()
            smoothing_models['HW_Add'] = hw_add_fitted
            print(f"   âœ… Î± (level): {hw_add_fitted.params['smoothing_level']:.4f}")
            print(f"   âœ… Î² (trend): {hw_add_fitted.params['smoothing_trend']:.4f}")
            print(f"   âœ… Î³ (seasonal): {hw_add_fitted.params['smoothing_seasonal']:.4f}")
        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {str(e)[:50]}...")
        
        # 4. Holt-Winters ìŠ¹ë²•ì  ëª¨ë¸
        print(f"\n4ï¸âƒ£ Holt-Winters ìŠ¹ë²•ì  ëª¨ë¸")
        print("   ì ìš©: ê³„ì ˆì„± íŒ¨í„´ì˜ í¬ê¸°ê°€ íŠ¸ë Œë“œì— ë¹„ë¡€í•˜ëŠ” ë°ì´í„°")
        print("   ìˆ˜ì‹: Level Ã— Trend Ã— Seasonal (ìŠ¹ë²•ì  ê²°í•©)")
        
        try:
            hw_mul_model = ExponentialSmoothing(data, trend='add', seasonal='mul', seasonal_periods=12)
            hw_mul_fitted = hw_mul_model.fit()
            smoothing_models['HW_Mul'] = hw_mul_fitted
            print(f"   âœ… Î± (level): {hw_mul_fitted.params['smoothing_level']:.4f}")
            print(f"   âœ… Î² (trend): {hw_mul_fitted.params['smoothing_trend']:.4f}")
            print(f"   âœ… Î³ (seasonal): {hw_mul_fitted.params['smoothing_seasonal']:.4f}")
        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {str(e)[:50]}...")
        
        # ëª¨ë¸ë³„ AIC ë¹„êµ
        print(f"\nğŸ“Š ì§€ìˆ˜í‰í™œë²• ëª¨ë¸ ë¹„êµ (AIC ê¸°ì¤€):")
        aic_comparison = {}
        for name, model in smoothing_models.items():
            try:
                aic = model.aic
                aic_comparison[name] = aic
                print(f"   {name}: AIC = {aic:.2f}")
            except:
                print(f"   {name}: AIC ê³„ì‚° ì‹¤íŒ¨")
        
        # ìµœì  ëª¨ë¸ ì„ íƒ
        if aic_comparison:
            best_smooth_model = min(aic_comparison.keys(), key=lambda x: aic_comparison[x])
            print(f"\nğŸ† ìµœì  ì§€ìˆ˜í‰í™œë²• ëª¨ë¸: {best_smooth_model}")
            print(f"   AIC: {aic_comparison[best_smooth_model]:.2f}")
            
            return smoothing_models, best_smooth_model
        else:
            return smoothing_models, None
    
    def compare_forecasting_performance(self, data, train_ratio=0.8):
        """ì˜ˆì¸¡ ì„±ëŠ¥ ë¹„êµ"""
        
        print(f"\nğŸ“ˆ ì˜ˆì¸¡ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸")
        print("=" * 50)
        
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
        split_point = int(len(data) * train_ratio)
        train_data = data[:split_point]
        test_data = data[split_point:]
        
        print(f"ğŸ“Š ë°ì´í„° ë¶„í• :")
        print(f"   í›ˆë ¨ ë°ì´í„°: {len(train_data)}ê°œ ({train_data.index[0].date()} ~ {train_data.index[-1].date()})")
        print(f"   í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)}ê°œ ({test_data.index[0].date()} ~ {test_data.index[-1].date()})")
        
        forecast_results = {}
        
        # 1. SARIMA ëª¨ë¸
        print(f"\nğŸ”„ SARIMA ëª¨ë¸ ì˜ˆì¸¡:")
        try:
            sarima_model, _ = self.build_sarima_model(train_data, seasonal_period=12)
            if sarima_model is not None:
                sarima_forecast = sarima_model.forecast(steps=len(test_data))
                sarima_mape = mean_absolute_percentage_error(test_data, sarima_forecast)
                
                forecast_results['SARIMA'] = {
                    'forecast': sarima_forecast,
                    'mape': sarima_mape,
                    'model': sarima_model
                }
                print(f"   âœ… MAPE: {sarima_mape:.2%}")
            else:
                print(f"   âŒ SARIMA ëª¨ë¸ êµ¬ì¶• ì‹¤íŒ¨")
        except Exception as e:
            print(f"   âŒ SARIMA ì˜¤ë¥˜: {str(e)[:50]}...")
        
        # 2. Holt-Winters ëª¨ë¸
        print(f"\nğŸ“Š Holt-Winters ì˜ˆì¸¡:")
        try:
            hw_model = ExponentialSmoothing(train_data, trend='add', seasonal='add', seasonal_periods=12)
            hw_fitted = hw_model.fit()
            hw_forecast = hw_fitted.forecast(steps=len(test_data))
            hw_mape = mean_absolute_percentage_error(test_data, hw_forecast)
            
            forecast_results['Holt-Winters'] = {
                'forecast': hw_forecast,
                'mape': hw_mape,
                'model': hw_fitted
            }
            print(f"   âœ… MAPE: {hw_mape:.2%}")
        except Exception as e:
            print(f"   âŒ Holt-Winters ì˜¤ë¥˜: {str(e)[:50]}...")
        
        # 3. ë‹¨ìˆœ ë² ì´ìŠ¤ë¼ì¸ (ê³„ì ˆì  naive)
        print(f"\nğŸ¯ ê³„ì ˆì  Naive ì˜ˆì¸¡:")
        try:
            # 1ë…„ ì „ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            seasonal_naive_forecast = []
            for i in range(len(test_data)):
                # 12ê°œì›” ì „ ê°’ ì‚¬ìš© (ì›”ë³„ ë°ì´í„° ê°€ì •)
                if i < 12 and len(train_data) >= 12:
                    seasonal_naive_forecast.append(train_data.iloc[-(12-i)])
                elif len(train_data) >= 12:
                    seasonal_naive_forecast.append(train_data.iloc[-12])
                else:
                    seasonal_naive_forecast.append(train_data.iloc[-1])
            
            seasonal_naive_forecast = pd.Series(seasonal_naive_forecast, index=test_data.index)
            naive_mape = mean_absolute_percentage_error(test_data, seasonal_naive_forecast)
            
            forecast_results['Seasonal_Naive'] = {
                'forecast': seasonal_naive_forecast,
                'mape': naive_mape,
                'model': None
            }
            print(f"   âœ… MAPE: {naive_mape:.2%}")
        except Exception as e:
            print(f"   âŒ Naive ì˜¤ë¥˜: {str(e)[:50]}...")
        
        # ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”
        if forecast_results:
            self._visualize_forecast_comparison(train_data, test_data, forecast_results)
            self._print_performance_summary(forecast_results)
        
        return forecast_results
    
    def _visualize_forecast_comparison(self, train_data, test_data, forecast_results):
        """ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ì‹œê°í™”"""
        
        fig, ax = plt.subplots(1, 1, figsize=(15, 8))
        
        # í›ˆë ¨ ë°ì´í„°
        ax.plot(train_data.index, train_data.values, 'o-', label='í›ˆë ¨ ë°ì´í„°', 
                color='black', linewidth=2, markersize=4)
        
        # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„°
        ax.plot(test_data.index, test_data.values, 'o-', label='ì‹¤ì œ ê°’', 
                color='blue', linewidth=2, markersize=4)
        
        # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡
        colors = ['red', 'green', 'orange', 'purple', 'brown']
        for i, (model_name, result) in enumerate(forecast_results.items()):
            ax.plot(test_data.index, result['forecast'], '--', 
                   label=f'{model_name} (MAPE: {result["mape"]:.1%})',
                   color=colors[i % len(colors)], linewidth=2)
        
        ax.set_title('ğŸ“ˆ ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ', fontsize=14, fontweight='bold')
        ax.set_ylabel('ê°’')
        ax.legend(loc='best')
        ax.grid(True, alpha=0.3)
        
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ êµ¬ë¶„ì„ 
        split_line = train_data.index[-1]
        ax.axvline(x=split_line, color='gray', linestyle=':', alpha=0.7, label='í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• ')
        
        plt.tight_layout()
        plt.show()
    
    def _print_performance_summary(self, forecast_results):
        """ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥"""
        
        print(f"\nğŸ† ì˜ˆì¸¡ ì„±ëŠ¥ ìš”ì•½ (MAPE ê¸°ì¤€):")
        print("-" * 40)
        
        # MAPE ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_results = sorted(forecast_results.items(), key=lambda x: x[1]['mape'])
        
        for rank, (model_name, result) in enumerate(sorted_results, 1):
            mape = result['mape']
            emoji = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰" if rank == 3 else "ğŸ…"
            print(f"   {emoji} {rank}ìœ„: {model_name} - MAPE: {mape:.2%}")
        
        # ì„±ëŠ¥ í•´ì„
        best_model = sorted_results[0][0]
        best_mape = sorted_results[0][1]['mape']
        
        print(f"\nğŸ’¡ ì„±ëŠ¥ í•´ì„:")
        if best_mape <= 0.10:
            print(f"   âœ… ìš°ìˆ˜í•œ ì˜ˆì¸¡ ì„±ëŠ¥ (MAPE â‰¤ 10%)")
        elif best_mape <= 0.20:
            print(f"   ğŸ”¶ ì–‘í˜¸í•œ ì˜ˆì¸¡ ì„±ëŠ¥ (10% < MAPE â‰¤ 20%)")
        elif best_mape <= 0.50:
            print(f"   âš ï¸ ë³´í†µ ì˜ˆì¸¡ ì„±ëŠ¥ (20% < MAPE â‰¤ 50%)")
        else:
            print(f"   âŒ ê°œì„  í•„ìš” (MAPE > 50%)")
        
        print(f"   ğŸ¯ ìµœì  ëª¨ë¸: {best_model}")
        print(f"   ğŸ“Š ì˜ˆì¸¡ ì •í™•ë„: {(1-best_mape):.1%}")

# ê³„ì ˆì„± ëª¨ë¸ ì‹œìŠ¤í…œ ì‹¤í–‰
seasonal_models = SeasonalTimeSeriesModels()

print("\nğŸ”„ ê³„ì ˆì„± ì‹œê³„ì—´ ëª¨ë¸ë§ ì—¬ì • ì‹œì‘")
print("=" * 60)

# 1. SARIMA ê°œë… ì‹œì—°
seasonal_data, decomposition = seasonal_models.demonstrate_sarima_concept()

# 2. SARIMA ëª¨ë¸ êµ¬ì¶•
best_sarima, sarima_results = seasonal_models.build_sarima_model(seasonal_data, seasonal_period=12)

# 3. ì§€ìˆ˜í‰í™œë²• ëª¨ë¸ë“¤ ì‹œì—°
smoothing_models, best_smoothing = seasonal_models.demonstrate_exponential_smoothing(seasonal_data)

# 4. ì˜ˆì¸¡ ì„±ëŠ¥ ë¹„êµ
print(f"\nğŸ“ˆ ìµœì¢… ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸")
forecast_comparison = seasonal_models.compare_forecasting_performance(seasonal_data, train_ratio=0.8)

print(f"\nâœ… ê³„ì ˆì„± ëª¨ë¸ë§ ì™„ë£Œ!")
print(f"   ğŸ”„ SARIMA: ê³„ì ˆì„± + ì¼ë°˜ íŒ¨í„´ í†µí•© ëª¨ë¸ë§")
print(f"   ğŸ“Š ì§€ìˆ˜í‰í™œë²•: ì§ê´€ì ì´ê³  ì‹¤ìš©ì ì¸ ì˜ˆì¸¡ ë°©ë²•")
print(f"   ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ: ì‹¤ì œ ì˜ˆì¸¡ ì •í™•ë„ë¡œ ëª¨ë¸ ê²€ì¦")
print(f"   ğŸ¯ ìµœì  ëª¨ë¸: ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ì„ íƒ")
print(f"\nğŸš€ ë‹¤ìŒ: AI í˜‘ì—…ì„ í†µí•œ ì „í†µì  ëª¨ë¸ ìµœì í™”")

## 4. AI í˜‘ì—…ì„ í†µí•œ ì „í†µì  ëª¨ë¸ ìµœì í™”

### 4.1 7ì¥ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì„ ëª¨ë¸ í•´ì„ì— ì ìš©

ì „í†µì  ì‹œê³„ì—´ ëª¨ë¸ì˜ ê°€ì¥ í° ì¥ì ì€ **í•´ì„ ê°€ëŠ¥ì„±**ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ë³µì¡í•œ ìˆ˜í•™ì  ê²°ê³¼ë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì–¸ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ê²ƒì€ ì—¬ì „íˆ ë„ì „ì ì…ë‹ˆë‹¤. 7ì¥ì—ì„œ ë°°ìš´ CLEAR í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì„ í™œìš©í•˜ì—¬ ëª¨ë¸ ê²°ê³¼ë¥¼ ì§ê´€ì ìœ¼ë¡œ í•´ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.

```python
import json
from datetime import datetime, timedelta

class AIEnhancedTraditionalModels:
    """AI í˜‘ì—… ê¸°ë°˜ ì „í†µì  ëª¨ë¸ ìµœì í™” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.model_interpretations = {}
        self.optimization_history = []
        self.business_insights = {}
        
        # 7ì¥ CLEAR ì›ì¹™ì„ ì‹œê³„ì—´ ëª¨ë¸ í•´ì„ì— íŠ¹í™”
        self.interpretation_prompts = {
            'arima_business': self._create_arima_business_prompt(),
            'sarima_seasonal': self._create_sarima_seasonal_prompt(),
            'forecast_reliability': self._create_forecast_reliability_prompt(),
            'model_selection': self._create_model_selection_prompt(),
            'risk_assessment': self._create_risk_assessment_prompt()
        }
    
    def _create_arima_business_prompt(self):
        """ARIMA ëª¨ë¸ ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„ìš© CLEAR í”„ë¡¬í”„íŠ¸"""
        
        return """
ë‹¹ì‹ ì€ 15ë…„ ê²½ë ¥ì˜ ì‹œê³„ì—´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**Context(ë§¥ë½)**: 
- ê¸°ì—…ì˜ í•µì‹¬ KPI ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„
- ê²½ì˜ì§„ê³¼ ì‹¤ë¬´ì§„ ëª¨ë‘ì—ê²Œ ì„¤ëª…í•´ì•¼ í•˜ëŠ” ìƒí™©
- ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ í•„ìš”

**Length(ì„¤ëª… ë²”ìœ„)**:
ë‹¤ìŒ 4ê°œ ì˜ì—­ì„ ê°ê° 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…:
1. ëª¨ë¸ì´ ë°œê²¬í•œ í•µì‹¬ íŒ¨í„´
2. ê³„ìˆ˜ë“¤ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ì  ì˜ë¯¸
3. ì˜ˆì¸¡ ì‹ ë¢°ë„ì™€ ë¶ˆí™•ì‹¤ì„±
4. ì‹¤ë¬´ ì ìš© ë°©ì•ˆê³¼ ì£¼ì˜ì‚¬í•­

**Examples(í•´ì„ ê¸°ì¤€)**:
- AR ê³„ìˆ˜ 0.7 â†’ "ì§€ë‚œ ë‹¬ ì„±ê³¼ê°€ ì´ë²ˆ ë‹¬ì— 70% ì˜í–¥"
- MA ê³„ìˆ˜ -0.3 â†’ "ì¼ì‹œì  ì¶©ê²©ì˜ ë°˜ì‘ìš© íš¨ê³¼ ì¡´ì¬"
- ë†’ì€ AIC â†’ "ëª¨ë¸ ë³µì¡ë„ ëŒ€ë¹„ ì„¤ëª…ë ¥ ë¶€ì¡±"

**Actionable(ì‹¤í–‰ ê°€ëŠ¥í•œ ê²°ê³¼)**:
1. í•µì‹¬ ë°œê²¬ì‚¬í•­ 3ê°€ì§€ (ìš°ì„ ìˆœìœ„ ìˆœ)
2. ë‹¨ê¸°/ì¥ê¸° ì˜ˆì¸¡ì˜ ì‹ ë¢°ë„ í‰ê°€
3. ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ ê¶Œê³ ì‚¬í•­
4. ëª¨ë‹ˆí„°ë§í•´ì•¼ í•  í•µì‹¬ ì§€í‘œ

**Role(ì „ë¬¸ê°€ ì—­í• )**:
ì‹œê³„ì—´ ë¶„ì„ ì „ë¬¸ê°€ì´ì ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨ì„¤í„´íŠ¸ë¡œì„œ 
ë³µì¡í•œ í†µê³„ ê²°ê³¼ë¥¼ ê²½ì˜ ì–¸ì–´ë¡œ ë²ˆì—­

**ë¶„ì„ ëŒ€ìƒ**:
ëª¨ë¸: ARIMA{order}
ë°ì´í„°: {data_description}
ê¸°ê°„: {time_period}
ê³„ìˆ˜ ì¶”ì •ì¹˜: {coefficients}
ì§„ë‹¨ ê²°ê³¼: {diagnostics}
AIC/BIC: {information_criteria}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ì´ê³  ì‹¤ìš©ì ì¸ í•´ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        """
    
    def _create_sarima_seasonal_prompt(self):
        """SARIMA ê³„ì ˆì„± í•´ì„ìš© í”„ë¡¬í”„íŠ¸"""
        
        return """
ê³„ì ˆì„± íŒ¨í„´ ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ SARIMA ëª¨ë¸ ê²°ê³¼ë¥¼ í•´ì„í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ì´ˆì **:
1. ê³„ì ˆì„± ê°•ë„ì™€ íŒ¨í„´ì˜ ì•ˆì •ì„±
2. ë…„ë„ë³„ ê³„ì ˆ íŒ¨í„´ ë³€í™” ì¶”ì´
3. ê³„ì ˆì„±ì´ ë¹„ì¦ˆë‹ˆìŠ¤ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
4. ê³„ì ˆì„±ì„ í™œìš©í•œ ì „ëµì  ëŒ€ì‘ ë°©ì•ˆ

**SARIMA ê²°ê³¼**:
ëª¨ë¸: SARIMA{order}x{seasonal_order}
ê³„ì ˆ ì£¼ê¸°: {seasonal_period}
ê³„ì ˆ ê³„ìˆ˜: {seasonal_coefficients}
ë¶„í•´ ê²°ê³¼: {decomposition_summary}

ê³„ì ˆì„± ê´€ì ì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ìˆ˜ë¦½ì— ë„ì›€ë˜ëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
        """
    
    def _create_forecast_reliability_prompt(self):
        """ì˜ˆì¸¡ ì‹ ë¢°ë„ í‰ê°€ í”„ë¡¬í”„íŠ¸"""
        
        return """
ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€ ì „ë¬¸ê°€ë¡œì„œ ëª¨ë¸ì˜ ì‹ ë¢°ë„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

**í‰ê°€ ê´€ì **:
1. ì˜ˆì¸¡ êµ¬ê°„ì˜ ì ì ˆì„± (ë„ˆë¬´ ë„“ê±°ë‚˜ ì¢ì§€ ì•Šì€ê°€?)
2. ê³¼ê±° ì˜ˆì¸¡ ì„±ëŠ¥ ê¸°ë°˜ ë¯¸ë˜ ì‹ ë¢°ë„ ì¶”ì •
3. ì˜ˆì¸¡ ê¸°ê°„ë³„ ì‹ ë¢°ë„ ë³€í™” (ë‹¨ê¸° vs ì¥ê¸°)
4. ì™¸ë¶€ ì¶©ê²© ì‹œë‚˜ë¦¬ì˜¤ë³„ ì˜ˆì¸¡ ì•ˆì •ì„±

**ì„±ëŠ¥ ì§€í‘œ**:
í›ˆë ¨ ì„±ëŠ¥: {train_performance}
í…ŒìŠ¤íŠ¸ ì„±ëŠ¥: {test_performance}
ì”ì°¨ ë¶„ì„: {residual_analysis}
ì˜ˆì¸¡ êµ¬ê°„: {confidence_intervals}

ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •ì—ì„œ ì´ ì˜ˆì¸¡ì„ ì–´ëŠ ì •ë„ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ì§€ í‰ê°€í•´ì£¼ì„¸ìš”.
        """
    
    def ai_interpret_arima_results(self, model_result, data_description):
        """AI ê¸°ë°˜ ARIMA ê²°ê³¼ í•´ì„"""
        
        print("ğŸ¤– AI í˜‘ì—… ARIMA ëª¨ë¸ í•´ì„")
        print("=" * 50)
        
        # ëª¨ë¸ ì •ë³´ ì¶”ì¶œ
        fitted_model = model_result['model']
        order = model_result['order']
        diagnostics = model_result.get('diagnostics', {})
        
        # í”„ë¡¬í”„íŠ¸ ë°ì´í„° ì¤€ë¹„
        prompt_data = {
            'order': order,
            'data_description': data_description,
            'time_period': f"{fitted_model.model.endog.index[0].date()} ~ {fitted_model.model.endog.index[-1].date()}",
            'coefficients': dict(fitted_model.params),
            'diagnostics': diagnostics,
            'information_criteria': {
                'AIC': fitted_model.aic,
                'BIC': fitted_model.bic
            }
        }
        
        # AI í•´ì„ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” LLM API í˜¸ì¶œ)
        interpretation = self._simulate_arima_interpretation(prompt_data)
        
        print(interpretation)
        
        # í•´ì„ ê²°ê³¼ ì €ì¥
        self.model_interpretations[f'ARIMA{order}'] = {
            'interpretation': interpretation,
            'timestamp': datetime.now(),
            'model_data': prompt_data
        }
        
        return interpretation
    
    def _simulate_arima_interpretation(self, prompt_data):
        """ARIMA í•´ì„ ì‹œë®¬ë ˆì´ì…˜"""
        
        order = prompt_data['order']
        coefficients = prompt_data['coefficients']
        aic = prompt_data['information_criteria']['AIC']
        
        # AR ê³„ìˆ˜ í•´ì„
        ar_interpretation = ""
        if order[0] > 0:  # AR ë¶€ë¶„ì´ ìˆëŠ” ê²½ìš°
            ar_params = [v for k, v in coefficients.items() if 'ar.L' in k]
            if ar_params:
                ar1 = ar_params[0]
                if ar1 > 0.5:
                    momentum = "ê°•í•œ ëª¨ë©˜í…€"
                elif ar1 > 0.2:
                    momentum = "ì¤‘ê°„ ëª¨ë©˜í…€"
                else:
                    momentum = "ì•½í•œ ëª¨ë©˜í…€"
                
                ar_interpretation = f"""
ğŸ“ˆ **ëª¨ë©˜í…€ ë¶„ì„ (AR ì„±ë¶„)**:
ì´ ì‹œê³„ì—´ì€ {momentum}ì„ ë³´ì…ë‹ˆë‹¤. AR ê³„ìˆ˜ {ar1:.3f}ëŠ” ì´ì „ ê¸°ê°„ ê°’ì´ í˜„ì¬ ê°’ì— 
{abs(ar1)*100:.1f}% ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. {"ì¶”ì„¸ê°€ ì§€ì†ë˜ëŠ” ê²½í–¥ì´ ê°•í•˜ë¯€ë¡œ" if ar1 > 0.5 else "ë³€í™”ê°€ ìƒëŒ€ì ìœ¼ë¡œ ë¹ ë¥´ë¯€ë¡œ"} 
{"ì¥ê¸° ê³„íš ìˆ˜ë¦½ì— ìœ ë¦¬" if ar1 > 0.5 else "ë‹¨ê¸° ëŒ€ì‘ ì „ëµì— ì§‘ì¤‘"}í•´ì•¼ í•©ë‹ˆë‹¤."""
        
        # MA ê³„ìˆ˜ í•´ì„  
        ma_interpretation = ""
        if order[2] > 0:  # MA ë¶€ë¶„ì´ ìˆëŠ” ê²½ìš°
            ma_params = [v for k, v in coefficients.items() if 'ma.L' in k]
            if ma_params:
                ma1 = ma_params[0]
                shock_effect = "ì™„ì¶©" if ma1 < 0 else "ì¦í­"
                
                ma_interpretation = f"""
ğŸŒŠ **ì¶©ê²© ì „íŒŒ ë¶„ì„ (MA ì„±ë¶„)**:
ì™¸ë¶€ ì¶©ê²©ì´ë‚˜ ì¼ì‹œì  ë³€ë™ì— ëŒ€í•´ ì´ ì‹œê³„ì—´ì€ {shock_effect} íš¨ê³¼ë¥¼ ë³´ì…ë‹ˆë‹¤. 
MA ê³„ìˆ˜ {ma1:.3f}ëŠ” {"ë¶€ì •ì  í”¼ë“œë°±ìœ¼ë¡œ ì•ˆì •í™” ê²½í–¥" if ma1 < 0 else "ì–‘ì˜ í”¼ë“œë°±ìœ¼ë¡œ ë³€ë™ ì¦í­"}ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
{"ê°‘ì‘ìŠ¤ëŸ° ë³€í™”ê°€ ë¹ ë¥´ê²Œ ì •ìƒí™”ë˜ë¯€ë¡œ ë‹¨ê¸° ëŒ€ì‘ë§Œìœ¼ë¡œ ì¶©ë¶„" if ma1 < 0 else "ì‘ì€ ë³€í™”ë„ í¬ê²Œ í™•ì‚°ë  ìˆ˜ ìˆì–´ ì‚¬ì „ ì˜ˆë°©ì´ ì¤‘ìš”"}í•©ë‹ˆë‹¤."""
        
        # ì¢…í•© í‰ê°€
        model_quality = "ìš°ìˆ˜" if aic < 1000 else "ì–‘í˜¸" if aic < 2000 else "ê°œì„  í•„ìš”"
        
        comprehensive_interpretation = f"""
ğŸ¤– **ARIMA{order} ëª¨ë¸ ì¢…í•© í•´ì„**

{ar_interpretation}

{ma_interpretation}

ğŸ¯ **í•µì‹¬ ë°œê²¬ì‚¬í•­ (ìš°ì„ ìˆœìœ„ ìˆœ)**:
1. **íŒ¨í„´ íŠ¹ì„±**: {"ì§€ì†ì  íŠ¸ë Œë“œ ì¤‘ì‹¬" if order[0] > order[2] else "ë³€ë™ì„± ì¤‘ì‹¬" if order[2] > order[0] else "ê· í˜•í˜•"} ì‹œê³„ì—´ë¡œ ë¶„ë¥˜
2. **ì˜ˆì¸¡ ì•ˆì •ì„±**: {model_quality} ìˆ˜ì¤€ì˜ ëª¨ë¸ ì í•©ë„ (AIC: {aic:.1f})
3. **ì‹œê°„ ì§€í‰**: {"ì¥ê¸° ì˜ˆì¸¡ì— ì í•©" if order[0] > 0.5 else "ë‹¨ê¸° ì˜ˆì¸¡ì— íŠ¹í™”"}

ğŸ’¼ **ë¹„ì¦ˆë‹ˆìŠ¤ ì ìš© ë°©ì•ˆ**:
- **ë‹¨ê¸° ì˜ˆì¸¡** (1-3ê°œì›”): {"ë†’ì€ ì‹ ë¢°ë„" if order[0] > 0.3 else "ì¤‘ê°„ ì‹ ë¢°ë„"} - ìš´ì˜ ê³„íš ìˆ˜ë¦½ ê°€ëŠ¥
- **ì¤‘ê¸° ì˜ˆì¸¡** (3-12ê°œì›”): {"ì‹ ì¤‘í•œ ì ‘ê·¼" if order[0] < 0.3 else "ì•ˆì •ì  í™œìš©"} - ì „ëµ ê³„íš ì°¸ê³ 
- **ì¥ê¸° ì˜ˆì¸¡** (12ê°œì›”+): {"ë³´ì¡° ì§€í‘œë¡œ í™œìš©" if order[0] < 0.5 else "í•µì‹¬ ì§€í‘œë¡œ í™œìš©"} 

âš ï¸ **ì£¼ì˜ì‚¬í•­**:
- ì™¸ë¶€ í™˜ê²½ ë³€í™” ì‹œ ëª¨ë¸ ì¬ê²€í†  í•„ìš”
- {f"AR ì„±ë¶„ì´ ê°•í•˜ë¯€ë¡œ ì¶”ì„¸ ë³€í™”ì  ì£¼ì˜ê¹Šê²Œ ëª¨ë‹ˆí„°ë§" if order[0] > 0.5 else "MA ì„±ë¶„ ì¤‘ì‹¬ì´ë¯€ë¡œ ì´ìƒê°’ ì˜í–¥ ì§€ì†ì  ê´€ì°°"}
- ì •ê¸°ì  ëª¨ë¸ ì—…ë°ì´íŠ¸ ê¶Œì¥ ({"ë¶„ê¸°ë³„" if order[0] > 0.3 else "ì›”ë³„"})

ğŸ“Š **í•µì‹¬ ëª¨ë‹ˆí„°ë§ ì§€í‘œ**:
1. ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ ì°¨ì´ (MAE ê¸°ì¤€)
2. ì”ì°¨ íŒ¨í„´ ë³€í™” (ìê¸°ìƒê´€ ì—¬ë¶€)
3. ìƒˆë¡œìš´ ë°ì´í„° íŒ¨í„´ ì¶œí˜„ ì—¬ë¶€
        """
        
        return comprehensive_interpretation.strip()
    
    def automated_model_tuning(self, data, business_objective='accuracy'):
        """ìë™í™”ëœ ëª¨ë¸ íŠœë‹ ì‹œìŠ¤í…œ"""
        
        print("âš™ï¸ AI ê¸°ë°˜ ìë™ ëª¨ë¸ íŠœë‹")
        print("=" * 50)
        print(f"ğŸ¯ ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œ: {business_objective}")
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì— ë”°ë¥¸ ìµœì í™” ì „ëµ
        optimization_strategies = {
            'accuracy': {
                'primary_metric': 'mape',
                'complexity_penalty': 0.1,
                'focus': 'ì˜ˆì¸¡ ì •í™•ë„ ìµœëŒ€í™”'
            },
            'interpretability': {
                'primary_metric': 'aic',
                'complexity_penalty': 0.5,
                'focus': 'í•´ì„ ê°€ëŠ¥ì„± ìš°ì„ '
            },
            'speed': {
                'primary_metric': 'training_time',
                'complexity_penalty': 0.8,
                'focus': 'ê³„ì‚° íš¨ìœ¨ì„± ì¤‘ì‹œ'
            },
            'stability': {
                'primary_metric': 'residual_variance',
                'complexity_penalty': 0.3,
                'focus': 'ì•ˆì •ì  ì˜ˆì¸¡ ì„±ëŠ¥'
            }
        }
        
        strategy = optimization_strategies.get(business_objective, optimization_strategies['accuracy'])
        
        print(f"ğŸ“Š ìµœì í™” ì „ëµ: {strategy['focus']}")
        print(f"   ì£¼ìš” ì§€í‘œ: {strategy['primary_metric']}")
        print(f"   ë³µì¡ë„ í˜ë„í‹°: {strategy['complexity_penalty']}")
        
        # ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
        tuning_results = self._intelligent_hyperparameter_search(data, strategy)
        
        # ìµœì  ëª¨ë¸ ì„ íƒ
        optimal_model = self._select_optimal_model(tuning_results, strategy)
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì •
        monitoring_setup = self._setup_performance_monitoring(optimal_model, data)
        
        return {
            'optimal_model': optimal_model,
            'tuning_results': tuning_results,
            'monitoring_setup': monitoring_setup,
            'strategy': strategy
        }
    
    def _intelligent_hyperparameter_search(self, data, strategy):
        """ì§€ëŠ¥í˜• í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰"""
        
        print("ğŸ” ì§€ëŠ¥í˜• í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ì¤‘...")
        
        # ë°ì´í„° íŠ¹ì„± ë¶„ì„
        data_characteristics = self._analyze_data_characteristics(data)
        
        # íŠ¹ì„± ê¸°ë°˜ ì´ˆê¸° í›„ë³´ ìƒì„±
        initial_candidates = self._generate_smart_candidates(data_characteristics)
        
        print(f"   ë°ì´í„° íŠ¹ì„±: {data_characteristics}")
        print(f"   ì´ˆê¸° í›„ë³´: {len(initial_candidates)}ê°œ ëª¨ë¸")
        
        # ë² ì´ì§€ì•ˆ ìµœì í™” ìŠ¤íƒ€ì¼ íƒìƒ‰
        optimization_results = []
        
        for i, candidate in enumerate(initial_candidates[:8]):  # ìƒìœ„ 8ê°œë§Œ í…ŒìŠ¤íŠ¸
            try:
                print(f"   ëª¨ë¸ {i+1}: {candidate} í‰ê°€ ì¤‘...")
                
                # ëª¨ë¸ í›ˆë ¨
                if len(candidate) == 3:  # ARIMA
                    model = ARIMA(data, order=candidate)
                else:  # SARIMA  
                    model = SARIMAX(data, order=candidate[:3], seasonal_order=candidate[3:])
                
                fitted_model = model.fit(disp=False)
                
                # ì„±ëŠ¥ í‰ê°€
                performance = self._evaluate_model_performance(fitted_model, data, strategy)
                
                optimization_results.append({
                    'order': candidate,
                    'model': fitted_model,
                    'performance': performance,
                    'score': performance['composite_score']
                })
                
                print(f"     ì ìˆ˜: {performance['composite_score']:.3f}")
                
            except Exception as e:
                print(f"     ì‹¤íŒ¨: {str(e)[:30]}...")
                continue
        
        # ê²°ê³¼ ì •ë ¬
        optimization_results.sort(key=lambda x: x['score'], reverse=True)
        
        print(f"\nğŸ† ìƒìœ„ 3ê°œ ëª¨ë¸:")
        for i, result in enumerate(optimization_results[:3]):
            order = result['order']
            score = result['score']
            print(f"   {i+1}. {'ARIMA' if len(order)==3 else 'SARIMA'}{order}: {score:.3f}")
        
        return optimization_results
    
    def _analyze_data_characteristics(self, data):
        """ë°ì´í„° íŠ¹ì„± ìë™ ë¶„ì„"""
        
        characteristics = {}
        
        # ê¸°ë³¸ í†µê³„
        characteristics['length'] = len(data)
        characteristics['mean'] = data.mean()
        characteristics['std'] = data.std()
        characteristics['cv'] = characteristics['std'] / characteristics['mean'] if characteristics['mean'] != 0 else 0
        
        # ì •ìƒì„±
        adf_stat, adf_pvalue = adfuller(data)[:2]
        characteristics['is_stationary'] = adf_pvalue < 0.05
        characteristics['stationarity_strength'] = 1 - adf_pvalue if adf_pvalue < 1 else 0
        
        # ê³„ì ˆì„± ê°ì§€
        if len(data) >= 24:  # ìµœì†Œ 2ë…„ ë°ì´í„°
            try:
                decomp = seasonal_decompose(data, model='additive', period=12)
                seasonal_strength = decomp.seasonal.std() / data.std()
                characteristics['has_seasonality'] = seasonal_strength > 0.1
                characteristics['seasonal_strength'] = seasonal_strength
            except:
                characteristics['has_seasonality'] = False
                characteristics['seasonal_strength'] = 0
        else:
            characteristics['has_seasonality'] = False
            characteristics['seasonal_strength'] = 0
        
        # íŠ¸ë Œë“œ ê°ì§€
        x = np.arange(len(data))
        slope, _ = np.polyfit(x, data.values, 1)
        trend_strength = abs(slope) / characteristics['std'] if characteristics['std'] > 0 else 0
        characteristics['has_trend'] = trend_strength > 0.1
        characteristics['trend_strength'] = trend_strength
        
        return characteristics
    
    def _generate_smart_candidates(self, characteristics):
        """íŠ¹ì„± ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ í›„ë³´ ìƒì„±"""
        
        candidates = []
        
        # ì •ìƒì„±ì— ë”°ë¥¸ ì°¨ë¶„ ì°¨ìˆ˜
        if characteristics['is_stationary']:
            d_values = [0, 1]
        else:
            d_values = [1, 2]
        
        # ê³„ì ˆì„±ì— ë”°ë¥¸ ëª¨ë¸ ì„ íƒ
        if characteristics['has_seasonality']:
            # SARIMA í›„ë³´ë“¤
            for p in [0, 1, 2]:
                for d in d_values:
                    for q in [0, 1, 2]:
                        for P in [0, 1]:
                            for D in [0, 1]:
                                for Q in [0, 1]:
                                    candidates.append((p, d, q, P, D, Q, 12))
        else:
            # ARIMA í›„ë³´ë“¤
            for p in [0, 1, 2, 3]:
                for d in d_values:
                    for q in [0, 1, 2, 3]:
                        if p + q > 0:  # ìµœì†Œ í•˜ë‚˜ëŠ” 0ì´ ì•„ë‹ˆì–´ì•¼ í•¨
                            candidates.append((p, d, q))
        
        # ë°ì´í„° íŠ¹ì„±ì— ë”°ë¥¸ ìš°ì„ ìˆœìœ„ ì •ë ¬
        def candidate_priority(candidate):
            score = 0
            
            if len(candidate) == 3:  # ARIMA
                p, d, q = candidate
                # ë³µì¡ë„ í˜ë„í‹°
                score -= (p + q) * 0.1
                # íŠ¸ë Œë“œ ê°•ë„ì— ë”°ë¥¸ AR ì„ í˜¸
                if characteristics['trend_strength'] > 0.2:
                    score += p * 0.2
            else:  # SARIMA
                p, d, q, P, D, Q, s = candidate
                # ë³µì¡ë„ í˜ë„í‹°
                score -= (p + q + P + Q) * 0.1
                # ê³„ì ˆì„± ê°•ë„ì— ë”°ë¥¸ ê³„ì ˆ ì„±ë¶„ ì„ í˜¸
                if characteristics['seasonal_strength'] > 0.2:
                    score += (P + Q) * 0.3
            
            return score
        
        # ìš°ì„ ìˆœìœ„ ì •ë ¬
        candidates.sort(key=candidate_priority, reverse=True)
        
        return candidates[:20]  # ìƒìœ„ 20ê°œë§Œ ë°˜í™˜
    
    def _evaluate_model_performance(self, fitted_model, data, strategy):
        """ëª¨ë¸ ì„±ëŠ¥ ì¢…í•© í‰ê°€"""
        
        performance = {}
        
        # ê¸°ë³¸ ë©”íŠ¸ë¦­ë“¤
        performance['aic'] = fitted_model.aic
        performance['bic'] = fitted_model.bic
        performance['llf'] = fitted_model.llf
        
        # ì”ì°¨ ë¶„ì„
        residuals = fitted_model.resid.dropna()
        if len(residuals) > 0:
            performance['residual_mean'] = residuals.mean()
            performance['residual_std'] = residuals.std()
            performance['residual_variance'] = residuals.var()
        
        # ì˜ˆì¸¡ ì„±ëŠ¥ (í›ˆë ¨ ë°ì´í„° ë‚´)
        try:
            fitted_values = fitted_model.fittedvalues
            valid_mask = ~np.isnan(fitted_values)
            
            if valid_mask.sum() > 0:
                actual = data[valid_mask]
                predicted = fitted_values[valid_mask]
                
                performance['mape'] = mean_absolute_percentage_error(actual, predicted)
                performance['mae'] = mean_absolute_error(actual, predicted)
                performance['rmse'] = np.sqrt(mean_squared_error(actual, predicted))
        except:
            performance['mape'] = float('inf')
            performance['mae'] = float('inf')
            performance['rmse'] = float('inf')
        
        # ë³µí•© ì ìˆ˜ ê³„ì‚°
        performance['composite_score'] = self._calculate_composite_score(performance, strategy)
        
        return performance
    
    def _calculate_composite_score(self, performance, strategy):
        """ì „ëµì— ë”°ë¥¸ ë³µí•© ì ìˆ˜ ê³„ì‚°"""
        
        score = 0
        
        if strategy['primary_metric'] == 'mape':
            # ì •í™•ë„ ì¤‘ì‹¬
            mape = performance.get('mape', float('inf'))
            if mape != float('inf'):
                score += (1 - min(mape, 1)) * 0.6  # 60% ê°€ì¤‘ì¹˜
            score += (1 / (1 + performance.get('aic', 1000) / 1000)) * 0.3  # 30% ê°€ì¤‘ì¹˜
            score += (1 - performance.get('residual_variance', 1)) * 0.1  # 10% ê°€ì¤‘ì¹˜
            
        elif strategy['primary_metric'] == 'aic':
            # í•´ì„ê°€ëŠ¥ì„± ì¤‘ì‹¬
            score += (1 / (1 + performance.get('aic', 1000) / 1000)) * 0.7
            score += (1 / (1 + performance.get('bic', 1000) / 1000)) * 0.3
            
        elif strategy['primary_metric'] == 'residual_variance':
            # ì•ˆì •ì„± ì¤‘ì‹¬
            score += (1 - min(performance.get('residual_variance', 1), 1)) * 0.5
            score += abs(performance.get('residual_mean', 1)) < 0.01 * 0.3  # í‰ê· ì´ 0ì— ê°€ê¹Œìš´ê°€
            score += (1 / (1 + performance.get('aic', 1000) / 1000)) * 0.2
        
        # ë³µì¡ë„ í˜ë„í‹° ì ìš©
        complexity_penalty = strategy.get('complexity_penalty', 0.1)
        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”í•˜ì—¬ AIC ê¸°ë°˜ìœ¼ë¡œ ë³µì¡ë„ ì¶”ì •
        complexity = performance.get('aic', 1000) / 1000
        score *= (1 - complexity_penalty * complexity)
        
        return max(score, 0)  # ìŒìˆ˜ ë°©ì§€
    
    def _select_optimal_model(self, tuning_results, strategy):
        """ìµœì  ëª¨ë¸ ì„ íƒ"""
        
        if not tuning_results:
            return None
        
        # ì ìˆ˜ ê¸°ì¤€ ìµœì  ëª¨ë¸
        best_result = tuning_results[0]
        
        print(f"\nğŸ¯ ìµœì  ëª¨ë¸ ì„ íƒ:")
        print(f"   ëª¨ë¸: {'ARIMA' if len(best_result['order'])==3 else 'SARIMA'}{best_result['order']}")
        print(f"   ì¢…í•© ì ìˆ˜: {best_result['score']:.3f}")
        print(f"   AIC: {best_result['performance']['aic']:.2f}")
        
        return best_result
    
    def _setup_performance_monitoring(self, optimal_model, data):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì •"""
        
        print(f"\nğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì„¤ì •")
        
        monitoring_config = {
            'model_info': {
                'order': optimal_model['order'],
                'created_at': datetime.now().isoformat(),
                'training_period': f"{data.index[0]} ~ {data.index[-1]}"
            },
            'performance_thresholds': {
                'mape_threshold': optimal_model['performance'].get('mape', 0.1) * 1.5,  # 50% ì¦ê°€ ì‹œ ê²½ê³ 
                'aic_threshold': optimal_model['performance'].get('aic', 1000) * 1.2,   # 20% ì¦ê°€ ì‹œ ê²½ê³ 
                'residual_std_threshold': optimal_model['performance'].get('residual_std', 1) * 2
            },
            'monitoring_schedule': {
                'daily_check': ['new_data_validation', 'forecast_accuracy'],
                'weekly_check': ['residual_analysis', 'parameter_stability'],
                'monthly_check': ['model_retraining', 'performance_report']
            },
            'alert_conditions': [
                'mape_degradation',
                'residual_pattern_change', 
                'forecast_interval_violation',
                'parameter_instability'
            ]
        }
        
        print(f"   MAPE ì„ê³„ê°’: {monitoring_config['performance_thresholds']['mape_threshold']:.1%}")
        print(f"   ëª¨ë‹ˆí„°ë§ ì£¼ê¸°: ì¼ì¼/ì£¼ê°„/ì›”ê°„ ì²´í¬")
        print(f"   ì•Œë¦¼ ì¡°ê±´: {len(monitoring_config['alert_conditions'])}ê°œ ì„¤ì •")
        
        return monitoring_config

# AI í˜‘ì—… ëª¨ë¸ ìµœì í™” ì‹œìŠ¤í…œ ì‹¤í–‰
ai_enhanced_models = AIEnhancedTraditionalModels()

print("\nğŸ¤– AI í˜‘ì—… ê¸°ë°˜ ì „í†µì  ëª¨ë¸ ìµœì í™”")
print("=" * 60)

# 1. AI ê¸°ë°˜ ARIMA ê²°ê³¼ í•´ì„ (ì´ì „ ê²°ê³¼ í™œìš©)
if 'final_arima_model' in globals() and final_arima_model:
    print("ğŸ“Š ARIMA ëª¨ë¸ AI í•´ì„:")
    ai_interpretation = ai_enhanced_models.ai_interpret_arima_results(
        final_arima_model, 
        "ì›”ë³„ ë§¤ì¶œ ë°ì´í„° - íŠ¸ë Œë“œì™€ ì•½ê°„ì˜ ê³„ì ˆì„± í¬í•¨"
    )

# 2. ìë™í™”ëœ ëª¨ë¸ íŠœë‹ ì‹œì—°
print(f"\nâš™ï¸ ìë™ ëª¨ë¸ íŠœë‹ ì‹œì—°:")

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
if 'seasonal_data' in globals():
    test_data = seasonal_data
else:
    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    dates = pd.date_range('2020-01-01', '2023-12-31', freq='M')
    trend = np.linspace(100, 130, len(dates))
    seasonal = 8 * np.sin(2 * np.pi * np.arange(len(dates)) / 12)
    noise = np.random.normal(0, 3, len(dates))
    test_data = pd.Series(trend + seasonal + noise, index=dates, name='revenue')

# ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œë³„ ìµœì í™”
objectives = ['accuracy', 'interpretability', 'stability']

optimization_results = {}
for objective in objectives:
    print(f"\nğŸ¯ {objective.upper()} ëª©í‘œ ìµœì í™”:")
    try:
        result = ai_enhanced_models.automated_model_tuning(test_data, business_objective=objective)
        optimization_results[objective] = result
        
        if result['optimal_model']:
            order = result['optimal_model']['order']
            score = result['optimal_model']['score']
            print(f"   ìµœì  ëª¨ë¸: {'ARIMA' if len(order)==3 else 'SARIMA'}{order}")
            print(f"   ìµœì í™” ì ìˆ˜: {score:.3f}")
    except Exception as e:
        print(f"   âŒ ì˜¤ë¥˜: {str(e)[:50]}...")

print(f"\nâœ… AI í˜‘ì—… ëª¨ë¸ ìµœì í™” ì™„ë£Œ!")
print(f"   ğŸ¤– CLEAR í”„ë¡¬í”„íŠ¸ë¡œ ëª¨ë¸ í•´ì„ ìë™í™”")
print(f"   âš™ï¸ ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œë³„ ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹")
print(f"   ğŸ“Š ì§€ëŠ¥í˜• ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•")
print(f"   ğŸ¯ ì‹¤ë¬´ ì ìš© ê°€ëŠ¥í•œ ìµœì í™” í”„ë ˆì„ì›Œí¬")
print(f"\nğŸš€ ë‹¤ìŒ: Store Sales ì‹¤ì „ í”„ë¡œì íŠ¸")

## 5. ì‹¤ì „ í”„ë¡œì íŠ¸: Store Sales ì‹œê³„ì—´ ì˜ˆì¸¡ ì‹œìŠ¤í…œ

### 5.1 í”„ë¡œì íŠ¸ ê°œìš” ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸

ì´ì œ 8ì¥ Part 2ì—ì„œ ë°°ìš´ ëª¨ë“  ì „í†µì  ì‹œê³„ì—´ ê¸°ë²•ë“¤ì„ ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„°ì— ì ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤. **Kaggle Store Sales - Time Series Forecasting** ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ì™„ì „í•œ ì˜ˆì¸¡ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê² ìŠµë‹ˆë‹¤.

```python
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import streamlit as st  # ëŒ€ì‹œë³´ë“œìš© (ì‹œë®¬ë ˆì´ì…˜)

class StoreSalesForecastingSystem:
    """Store Sales ì‹œê³„ì—´ ì˜ˆì¸¡ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.data = None
        self.models = {}
        self.forecasts = {}
        self.ensemble_results = {}
        self.dashboard_data = {}
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ KPI ì„¤ì •
        self.business_kpis = {
            'forecast_accuracy_target': 0.15,  # MAPE 15% ì´í•˜
            'inventory_optimization_threshold': 0.10,  # 10% ì¬ê³  ìµœì í™”
            'promotional_planning_horizon': 8,  # 8ì£¼ ì„ í–‰ ê³„íš
            'seasonal_adjustment_factor': 1.2   # ê³„ì ˆì„± 20% ì¡°ì •
        }
    
    def simulate_store_sales_data(self):
        """Store Sales ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ Kaggle ë°ì´í„° êµ¬ì¡°)"""
        
        print("ğŸ“Š Store Sales ë°ì´í„°ì…‹ ì‹œë®¬ë ˆì´ì…˜")
        print("=" * 50)
        print("ì‹¤ì œ ì—ì½°ë„ë¥´ ì†Œë§¤ì  ì²´ì¸ Favoritaì˜ ë§¤ì¶œ íŒ¨í„´ì„ ëª¨ë°©í•œ ì‹œë®¬ë ˆì´ì…˜")
        
        # ì‹œê°„ ë²”ìœ„: 2017-2021 (5ë…„ê°„ ì£¼ê°„ ë°ì´í„°)
        dates = pd.date_range('2017-01-01', '2021-12-31', freq='W')
        n_periods = len(dates)
        
        # ë‹¤ì–‘í•œ ìƒí’ˆêµ°ë³„ ì‹œê³„ì—´ ìƒì„±
        product_families = [
            'GROCERY I', 'BEVERAGES', 'PRODUCE', 'CLEANING', 'DAIRY',
            'BREAD/BAKERY', 'POULTRY', 'MEATS', 'PERSONAL CARE', 'FROZEN FOODS'
        ]
        
        # ë§¤ì¥ë³„ íŠ¹ì„±
        store_info = {
            'store_1': {'type': 'Supermarket', 'city': 'Quito', 'size_factor': 1.2},
            'store_2': {'type': 'Grocery', 'city': 'Guayaquil', 'size_factor': 0.8},
            'store_3': {'type': 'Hypermarket', 'city': 'Cuenca', 'size_factor': 1.5},
            'store_4': {'type': 'Supermarket', 'city': 'Machala', 'size_factor': 1.0}
        }
        
        # ì „ì²´ ë°ì´í„° êµ¬ì¡° ìƒì„±
        sales_data = []
        
        for store_id, store_attrs in store_info.items():
            for family in product_families:
                
                # ê¸°ë³¸ íŠ¸ë Œë“œ (ê²½ì œ ì„±ì¥ ë°˜ì˜)
                base_trend = np.linspace(1000, 1300, n_periods) * store_attrs['size_factor']
                
                # ìƒí’ˆêµ°ë³„ íŠ¹ì„±
                family_factors = {
                    'GROCERY I': 1.5,      # ê°€ì¥ ë†’ì€ ë§¤ì¶œ
                    'BEVERAGES': 1.2,      # ë†’ì€ ë§¤ì¶œ
                    'PRODUCE': 1.0,        # ê¸°ì¤€
                    'CLEANING': 0.6,       # ë‚®ì€ ë§¤ì¶œ
                    'DAIRY': 0.8,          # ì¤‘ê°„ ë§¤ì¶œ
                    'BREAD/BAKERY': 0.7,   # ì¤‘ê°„ ë§¤ì¶œ
                    'POULTRY': 0.9,        # ì¤‘ê°„ ë§¤ì¶œ
                    'MEATS': 1.1,          # ë†’ì€ ë§¤ì¶œ
                    'PERSONAL CARE': 0.5,  # ë‚®ì€ ë§¤ì¶œ
                    'FROZEN FOODS': 0.4    # ë‚®ì€ ë§¤ì¶œ
                }
                
                family_factor = family_factors.get(family, 1.0)
                
                # ê³„ì ˆì„± íŒ¨í„´ (ì—°ê°„ + ì›”ê°„)
                annual_seasonal = 0.15 * np.sin(2 * np.pi * np.arange(n_periods) / 52.18)  # ì—°ê°„
                monthly_seasonal = 0.08 * np.sin(2 * np.pi * np.arange(n_periods) / 4.33)  # ì›”ê°„
                
                # íŠ¹ë³„ ì´ë²¤íŠ¸ íš¨ê³¼ (í¬ë¦¬ìŠ¤ë§ˆìŠ¤, ì–´ë¨¸ë‹ˆë‚  ë“±)
                special_events = np.zeros(n_periods)
                for year in range(2017, 2022):
                    # í¬ë¦¬ìŠ¤ë§ˆìŠ¤ íš¨ê³¼ (12ì›”)
                    christmas_week = pd.to_datetime(f'{year}-12-25').week - 1
                    if christmas_week < n_periods:
                        special_events[christmas_week] += 0.3
                    
                    # ì–´ë¨¸ë‹ˆë‚  íš¨ê³¼ (5ì›”)
                    mothers_day_week = pd.to_datetime(f'{year}-05-10').week - 1
                    if mothers_day_week < n_periods:
                        special_events[mothers_day_week] += 0.2
                
                # ê²½ì œì  ì¶©ê²© (íŒ¬ë°ë¯¹ ë“±)
                economic_shock = np.zeros(n_periods)
                pandemic_start = pd.to_datetime('2020-03-15').week
                pandemic_end = pd.to_datetime('2020-08-01').week
                if pandemic_start < n_periods:
                    shock_period = slice(pandemic_start, min(pandemic_end, n_periods))
                    economic_shock[shock_period] = -0.25  # 25% ê°ì†Œ
                
                # ë…¸ì´ì¦ˆ
                noise = np.random.normal(0, 0.05, n_periods)
                
                # ìµœì¢… ì‹œê³„ì—´ í•©ì„±
                sales_values = (base_trend * family_factor * 
                               (1 + annual_seasonal + monthly_seasonal + 
                                special_events + economic_shock + noise))
                
                # ìŒìˆ˜ ë°©ì§€
                sales_values = np.maximum(sales_values, 0)
                
                # ë°ì´í„° ì €ì¥
                for i, (date, sales) in enumerate(zip(dates, sales_values)):
                    sales_data.append({
                        'date': date,
                        'store_nbr': store_id,
                        'family': family,
                        'sales': sales,
                        'store_type': store_attrs['type'],
                        'city': store_attrs['city']
                    })
        
        # DataFrame ìƒì„±
        self.data = pd.DataFrame(sales_data)
        
        # ì´ ë§¤ì¶œ ê³„ì‚° (ì „ì²´ ìƒí’ˆêµ° í•©ê³„)
        total_sales = self.data.groupby('date')['sales'].sum().reset_index()
        total_sales['store_nbr'] = 'ALL'
        total_sales['family'] = 'TOTAL'
        total_sales['store_type'] = 'ALL'
        total_sales['city'] = 'ALL'
        
        # ì´ ë§¤ì¶œì„ ë°ì´í„°ì— ì¶”ê°€
        self.data = pd.concat([self.data, total_sales], ignore_index=True)
        
        print(f"âœ… ë°ì´í„° ìƒì„± ì™„ë£Œ:")
        print(f"   ê¸°ê°„: {self.data['date'].min().date()} ~ {self.data['date'].max().date()}")
        print(f"   ë§¤ì¥ ìˆ˜: {len(store_info)}ê°œ")
        print(f"   ìƒí’ˆêµ° ìˆ˜: {len(product_families)}ê°œ")
        print(f"   ì´ ë°ì´í„° í¬ì¸íŠ¸: {len(self.data):,}ê°œ")
        print(f"   ì£¼ê°„ ì´ ë§¤ì¶œ í‰ê· : ${self.data[self.data['family']=='TOTAL']['sales'].mean():,.0f}")
        
        return self.data
    
    def comprehensive_eda_analysis(self):
        """ì¢…í•©ì  EDA ë¶„ì„"""
        
        print("\nğŸ“Š Store Sales ë°ì´í„° ì¢…í•© EDA")
        print("=" * 50)
        
        # ì´ ë§¤ì¶œ ë°ì´í„° ì¶”ì¶œ
        total_sales = self.data[self.data['family'] == 'TOTAL'].copy()
        total_sales = total_sales.set_index('date')['sales'].sort_index()
        
        # ê¸°ë³¸ í†µê³„
        print(f"ğŸ“ˆ ì´ ë§¤ì¶œ ê¸°ë³¸ í†µê³„:")
        print(f"   í‰ê· : ${total_sales.mean():,.0f}")
        print(f"   ì¤‘ì•™ê°’: ${total_sales.median():,.0f}")
        print(f"   í‘œì¤€í¸ì°¨: ${total_sales.std():,.0f}")
        print(f"   ìµœëŒ€ê°’: ${total_sales.max():,.0f}")
        print(f"   ìµœì†Œê°’: ${total_sales.min():,.0f}")
        
        # ì‹œê³„ì—´ ë¶„í•´
        decomposition = seasonal_decompose(total_sales, model='additive', period=52)
        
        # ê³„ì ˆì„± ê°•ë„ ê³„ì‚°
        seasonal_strength = decomposition.seasonal.std() / total_sales.std()
        trend_strength = decomposition.trend.dropna().std() / total_sales.std()
        
        print(f"\nğŸ” ì‹œê³„ì—´ êµ¬ì„± ìš”ì†Œ:")
        print(f"   íŠ¸ë Œë“œ ê°•ë„: {trend_strength:.1%}")
        print(f"   ê³„ì ˆì„± ê°•ë„: {seasonal_strength:.1%}")
        print(f"   ì”ì°¨ ë¹„ìœ¨: {(1-trend_strength-seasonal_strength):.1%}")
        
        # ìƒí’ˆêµ°ë³„ ë§¤ì¶œ ë¶„ì„
        family_sales = self.data[self.data['family'] != 'TOTAL'].groupby('family')['sales'].sum().sort_values(ascending=False)
        
        print(f"\nğŸ›’ ìƒìœ„ 5ê°œ ìƒí’ˆêµ°:")
        for i, (family, sales) in enumerate(family_sales.head().items()):
            print(f"   {i+1}. {family}: ${sales:,.0f}")
        
        # ë§¤ì¥ë³„ ì„±ê³¼ ë¶„ì„
        store_performance = self.data[self.data['family'] != 'TOTAL'].groupby('store_nbr')['sales'].agg(['sum', 'mean', 'std'])
        
        print(f"\nğŸª ë§¤ì¥ë³„ ì„±ê³¼:")
        for store in store_performance.index:
            total = store_performance.loc[store, 'sum']
            avg = store_performance.loc[store, 'mean']
            print(f"   {store}: ì´ ${total:,.0f}, í‰ê·  ${avg:,.0f}")
        
        # ì‹œê°í™”
        self._create_comprehensive_eda_plots(total_sales, decomposition, family_sales)
        
        return {
            'total_sales': total_sales,
            'decomposition': decomposition,
            'family_sales': family_sales,
            'store_performance': store_performance,
            'seasonal_strength': seasonal_strength,
            'trend_strength': trend_strength
        }
    
    def _create_comprehensive_eda_plots(self, total_sales, decomposition, family_sales):
        """ì¢…í•© EDA ì‹œê°í™”"""
        
        # 1. ì‹œê³„ì—´ ë¶„í•´ í”Œë¡¯
        fig, axes = plt.subplots(4, 1, figsize=(15, 12))
        fig.suptitle('ğŸª Store Sales ì‹œê³„ì—´ ë¶„í•´ ë¶„ì„', fontsize=16, fontweight='bold')
        
        # ì›ë³¸ ë°ì´í„°
        axes[0].plot(total_sales.index, total_sales.values, color='black', linewidth=1.5)
        axes[0].set_title('ğŸ“Š ì´ ë§¤ì¶œ (ì£¼ê°„)', fontweight='bold')
        axes[0].grid(True, alpha=0.3)
        
        # íŠ¸ë Œë“œ
        axes[1].plot(decomposition.trend.index, decomposition.trend.values, color='blue', linewidth=2)
        axes[1].set_title('ğŸ“ˆ íŠ¸ë Œë“œ ì„±ë¶„', fontweight='bold')
        axes[1].grid(True, alpha=0.3)
        
        # ê³„ì ˆì„±
        axes[2].plot(decomposition.seasonal.index, decomposition.seasonal.values, color='green', linewidth=1)
        axes[2].set_title('ğŸ”„ ê³„ì ˆì„± ì„±ë¶„ (ì—°ê°„ íŒ¨í„´)', fontweight='bold')
        axes[2].grid(True, alpha=0.3)
        
        # ì”ì°¨
        axes[3].plot(decomposition.resid.index, decomposition.resid.values, color='red', linewidth=1, alpha=0.7)
        axes[3].set_title('ğŸ² ì”ì°¨ ì„±ë¶„', fontweight='bold')
        axes[3].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # 2. ìƒí’ˆêµ°ë³„ ë§¤ì¶œ ë¶„ì„
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        fig.suptitle('ğŸ›’ ìƒí’ˆêµ°ë³„ ë§¤ì¶œ ë¶„ì„', fontsize=16, fontweight='bold')
        
        # ìƒí’ˆêµ°ë³„ ì´ ë§¤ì¶œ
        family_sales.head(8).plot(kind='barh', ax=ax1, color='skyblue')
        ax1.set_title('ìƒìœ„ 8ê°œ ìƒí’ˆêµ° ì´ ë§¤ì¶œ', fontweight='bold')
        ax1.set_xlabel('ì´ ë§¤ì¶œ ($)')
        
        # ìƒí’ˆêµ°ë³„ ë§¤ì¶œ ë¹„ìœ¨
        top_families = family_sales.head(6)
        others = family_sales.iloc[6:].sum()
        pie_data = pd.concat([top_families, pd.Series({'ê¸°íƒ€': others})])
        
        ax2.pie(pie_data.values, labels=pie_data.index, autopct='%1.1f%%', startangle=90)
        ax2.set_title('ìƒí’ˆêµ°ë³„ ë§¤ì¶œ ë¹„ìœ¨', fontweight='bold')
        
        plt.tight_layout()
        plt.show()
    
    def build_comprehensive_forecasting_models(self):
        """ì¢…í•©ì  ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•"""
        
        print("\nğŸ”® ì¢…í•© ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•")
        print("=" * 50)
        
        # ì´ ë§¤ì¶œ ë°ì´í„° ì¤€ë¹„
        total_sales = self.data[self.data['family'] == 'TOTAL'].copy()
        total_sales = total_sales.set_index('date')['sales'].sort_index()
        
        # í›ˆë ¨/ê²€ì¦ ë¶„í•  (80:20)
        split_point = int(len(total_sales) * 0.8)
        train_data = total_sales[:split_point]
        test_data = total_sales[split_point:]
        
        print(f"ğŸ“Š ë°ì´í„° ë¶„í• :")
        print(f"   í›ˆë ¨: {len(train_data)}ì£¼ ({train_data.index[0].date()} ~ {train_data.index[-1].date()})")
        print(f"   í…ŒìŠ¤íŠ¸: {len(test_data)}ì£¼ ({test_data.index[0].date()} ~ {test_data.index[-1].date()})")
        
        forecasting_results = {}
        
        # 1. ARIMA ëª¨ë¸
        print(f"\nğŸ”„ ARIMA ëª¨ë¸ êµ¬ì¶•:")
        try:
            arima_builder = ARIMAModelBuilder()
            arima_result = arima_builder.box_jenkins_methodology(train_data, max_p=3, max_d=2, max_q=3)
            
            if arima_result and arima_result['model']:
                arima_forecast = arima_result['model'].forecast(steps=len(test_data))
                arima_mape = mean_absolute_percentage_error(test_data, arima_forecast)
                
                forecasting_results['ARIMA'] = {
                    'model': arima_result['model'],
                    'forecast': arima_forecast,
                    'mape': arima_mape,
                    'order': arima_result['order']
                }
                print(f"   âœ… ARIMA{arima_result['order']}: MAPE = {arima_mape:.2%}")
            else:
                print(f"   âŒ ARIMA ëª¨ë¸ êµ¬ì¶• ì‹¤íŒ¨")
        except Exception as e:
            print(f"   âŒ ARIMA ì˜¤ë¥˜: {str(e)[:50]}...")
        
        # 2. SARIMA ëª¨ë¸
        print(f"\nğŸ”„ SARIMA ëª¨ë¸ êµ¬ì¶•:")
        try:
            seasonal_models = SeasonalTimeSeriesModels()
            sarima_model, _ = seasonal_models.build_sarima_model(train_data, seasonal_period=52)
            
            if sarima_model:
                sarima_forecast = sarima_model.forecast(steps=len(test_data))
                sarima_mape = mean_absolute_percentage_error(test_data, sarima_forecast)
                
                forecasting_results['SARIMA'] = {
                    'model': sarima_model,
                    'forecast': sarima_forecast,
                    'mape': sarima_mape,
                    'order': 'Auto-selected'
                }
                print(f"   âœ… SARIMA: MAPE = {sarima_mape:.2%}")
            else:
                print(f"   âŒ SARIMA ëª¨ë¸ êµ¬ì¶• ì‹¤íŒ¨")
        except Exception as e:
            print(f"   âŒ SARIMA ì˜¤ë¥˜: {str(e)[:50]}...")
        
        # 3. Holt-Winters ì§€ìˆ˜í‰í™œë²•
        print(f"\nğŸ“Š Holt-Winters ì§€ìˆ˜í‰í™œë²•:")
        try:
            hw_model = ExponentialSmoothing(train_data, trend='add', seasonal='add', seasonal_periods=52)
            hw_fitted = hw_model.fit()
            hw_forecast = hw_fitted.forecast(steps=len(test_data))
            hw_mape = mean_absolute_percentage_error(test_data, hw_forecast)
            
            forecasting_results['Holt-Winters'] = {
                'model': hw_fitted,
                'forecast': hw_forecast,
                'mape': hw_mape,
                'order': 'Additive'
            }
            print(f"   âœ… Holt-Winters: MAPE = {hw_mape:.2%}")
        except Exception as e:
            print(f"   âŒ Holt-Winters ì˜¤ë¥˜: {str(e)[:50]}...")
        
        # 4. ì•™ìƒë¸” ëª¨ë¸ (ê°€ì¤‘ í‰ê· )
        print(f"\nğŸ¯ ì•™ìƒë¸” ëª¨ë¸ êµ¬ì¶•:")
        if len(forecasting_results) >= 2:
            # ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
            weights = {}
            total_inverse_mape = 0
            
            for model_name, result in forecasting_results.items():
                inverse_mape = 1 / (result['mape'] + 0.001)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                weights[model_name] = inverse_mape
                total_inverse_mape += inverse_mape
            
            # ê°€ì¤‘ì¹˜ ì •ê·œí™”
            for model_name in weights:
                weights[model_name] /= total_inverse_mape
            
            # ì•™ìƒë¸” ì˜ˆì¸¡ ê³„ì‚°
            ensemble_forecast = pd.Series(0, index=test_data.index)
            for model_name, result in forecasting_results.items():
                ensemble_forecast += weights[model_name] * result['forecast']
            
            ensemble_mape = mean_absolute_percentage_error(test_data, ensemble_forecast)
            
            forecasting_results['Ensemble'] = {
                'model': 'Weighted Average',
                'forecast': ensemble_forecast,
                'mape': ensemble_mape,
                'weights': weights
            }
            
            print(f"   âœ… ì•™ìƒë¸” ëª¨ë¸: MAPE = {ensemble_mape:.2%}")
            print(f"   ê°€ì¤‘ì¹˜: {', '.join([f'{k}:{v:.2f}' for k, v in weights.items()])}")
        
        # 5. ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ (ê³„ì ˆì  Naive)
        print(f"\nğŸ“Š ë² ì´ìŠ¤ë¼ì¸ (ê³„ì ˆì  Naive):")
        try:
            # 52ì£¼ ì „ ê°’ ì‚¬ìš© (ì—°ê°„ ê³„ì ˆì„±)
            naive_forecast = []
            for i in range(len(test_data)):
                if len(train_data) >= 52:
                    naive_forecast.append(train_data.iloc[-(52-i%52)])
                else:
                    naive_forecast.append(train_data.iloc[-1])
            
            naive_forecast = pd.Series(naive_forecast, index=test_data.index)
            naive_mape = mean_absolute_percentage_error(test_data, naive_forecast)
            
            forecasting_results['Seasonal_Naive'] = {
                'model': 'Seasonal Naive',
                'forecast': naive_forecast,
                'mape': naive_mape,
                'order': '52-week lag'
            }
            print(f"   âœ… Seasonal Naive: MAPE = {naive_mape:.2%}")
        except Exception as e:
            print(f"   âŒ Naive ì˜¤ë¥˜: {str(e)[:50]}...")
        
        # ê²°ê³¼ ì‹œê°í™”
        self._visualize_model_comparison(train_data, test_data, forecasting_results)
        
        # ì„±ëŠ¥ ìš”ì•½
        self._print_model_performance_summary(forecasting_results)
        
        self.models = forecasting_results
        return forecasting_results
    
    def _visualize_model_comparison(self, train_data, test_data, results):
        """ëª¨ë¸ ë¹„êµ ì‹œê°í™”"""
        
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))
        fig.suptitle('ğŸ”® Store Sales ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ', fontsize=16, fontweight='bold')
        
        # 1. ì‹œê³„ì—´ ì˜ˆì¸¡ ë¹„êµ
        ax1.plot(train_data.index, train_data.values, 'o-', label='í›ˆë ¨ ë°ì´í„°', 
                color='black', linewidth=2, markersize=3, alpha=0.7)
        ax1.plot(test_data.index, test_data.values, 'o-', label='ì‹¤ì œ ê°’', 
                color='blue', linewidth=2, markersize=4)
        
        colors = ['red', 'green', 'orange', 'purple', 'brown', 'pink']
        for i, (model_name, result) in enumerate(results.items()):
            ax1.plot(test_data.index, result['forecast'], '--', 
                    label=f'{model_name} (MAPE: {result["mape"]:.1%})',
                    color=colors[i % len(colors)], linewidth=2)
        
        ax1.set_title('ğŸ“ˆ ì˜ˆì¸¡ ì„±ëŠ¥ ë¹„êµ', fontweight='bold')
        ax1.set_ylabel('ë§¤ì¶œ ($)')
        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax1.grid(True, alpha=0.3)
        
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ êµ¬ë¶„ì„ 
        split_line = train_data.index[-1]
        ax1.axvline(x=split_line, color='gray', linestyle=':', alpha=0.7, linewidth=2)
        ax1.text(split_line, ax1.get_ylim()[1]*0.9, 'í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• ', 
                rotation=90, ha='right', va='top', fontweight='bold')
        
        # 2. MAPE ë¹„êµ ë§‰ëŒ€ ê·¸ë˜í”„
        model_names = list(results.keys())
        mape_values = [results[name]['mape'] for name in model_names]
        
        bars = ax2.bar(model_names, mape_values, color=colors[:len(model_names)], alpha=0.7)
        ax2.set_title('ğŸ“Š ëª¨ë¸ë³„ MAPE ë¹„êµ', fontweight='bold')
        ax2.set_ylabel('MAPE (%)')
        ax2.grid(True, alpha=0.3)
        
        # ëª©í‘œ MAPE ì„  ì¶”ê°€
        target_mape = self.business_kpis['forecast_accuracy_target']
        ax2.axhline(y=target_mape, color='red', linestyle='--', linewidth=2, 
                   label=f'ëª©í‘œ MAPE: {target_mape:.1%}')
        ax2.legend()
        
        # ê°’ í‘œì‹œ
        for bar, mape in zip(bars, mape_values):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.001,
                    f'{mape:.1%}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.show()
    
    def _print_model_performance_summary(self, results):
        """ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥"""
        
        print(f"\nğŸ† ëª¨ë¸ ì„±ëŠ¥ ì¢…í•© í‰ê°€")
        print("=" * 50)
        
        # MAPE ê¸°ì¤€ ì •ë ¬
        sorted_results = sorted(results.items(), key=lambda x: x[1]['mape'])
        
        print(f"ğŸ“Š ì˜ˆì¸¡ ì •í™•ë„ ìˆœìœ„ (MAPE ê¸°ì¤€):")
        for rank, (model_name, result) in enumerate(sorted_results, 1):
            mape = result['mape']
            emoji = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰" if rank == 3 else "ğŸ…"
            
            # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
            target_achieved = "âœ…" if mape <= self.business_kpis['forecast_accuracy_target'] else "âŒ"
            
            print(f"   {emoji} {rank}ìœ„: {model_name}")
            print(f"      MAPE: {mape:.2%} {target_achieved}")
            print(f"      ì •í™•ë„: {(1-mape):.1%}")
            print()
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì  í‰ê°€
        best_model = sorted_results[0]
        best_mape = best_model[1]['mape']
        
        print(f"ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì  í‰ê°€:")
        if best_mape <= 0.10:
            grade = "A+ (íƒì›”)"
            recommendation = "ì¦‰ì‹œ í”„ë¡œë•ì…˜ ë°°í¬ ê¶Œì¥"
        elif best_mape <= 0.15:
            grade = "A (ìš°ìˆ˜)"
            recommendation = "ê²€í†  í›„ ë°°í¬ ê°€ëŠ¥"
        elif best_mape <= 0.20:
            grade = "B (ì–‘í˜¸)"
            recommendation = "ì¶”ê°€ íŠœë‹ í›„ ë°°í¬"
        elif best_mape <= 0.30:
            grade = "C (ë³´í†µ)"
            recommendation = "ìƒë‹¹í•œ ê°œì„  í•„ìš”"
        else:
            grade = "D (ê°œì„  í•„ìš”)"
            recommendation = "ëª¨ë¸ ì¬ì„¤ê³„ í•„ìš”"
        
        print(f"   ìµœìš°ìˆ˜ ëª¨ë¸: {best_model[0]}")
        print(f"   ì„±ëŠ¥ ë“±ê¸‰: {grade}")
        print(f"   ê¶Œì¥ì‚¬í•­: {recommendation}")
        
        # ROI ë¶„ì„
        if best_mape <= self.business_kpis['forecast_accuracy_target']:
            inventory_optimization = self.business_kpis['inventory_optimization_threshold']
            print(f"\nğŸ’° ì˜ˆìƒ ë¹„ì¦ˆë‹ˆìŠ¤ íš¨ê³¼:")
            print(f"   ì¬ê³  ìµœì í™”: {inventory_optimization:.0%} ê°œì„ ")
            print(f"   ê²°í’ˆ ì†ì‹¤ ê°ì†Œ: 15% ì¶”ì •")
            print(f"   ìš´ì˜ íš¨ìœ¨ì„±: 20% í–¥ìƒ")
    
    def create_business_dashboard(self):
        """ë¹„ì¦ˆë‹ˆìŠ¤ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
        
        print(f"\nğŸ“Š ë¹„ì¦ˆë‹ˆìŠ¤ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•")
        print("=" * 50)
        
        if not self.models:
            print("âŒ ì˜ˆì¸¡ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ êµ¬ì¶•í•´ì£¼ì„¸ìš”.")
            return
        
        # ìµœìš°ìˆ˜ ëª¨ë¸ ì„ íƒ
        best_model_name = min(self.models.keys(), key=lambda x: self.models[x]['mape'])
        best_model = self.models[best_model_name]
        
        print(f"ğŸ¯ ëŒ€ì‹œë³´ë“œ ê¸°ì¤€ ëª¨ë¸: {best_model_name}")
        print(f"   ì˜ˆì¸¡ ì •í™•ë„: {(1-best_model['mape']):.1%}")
        
        # ë¯¸ë˜ 8ì£¼ ì˜ˆì¸¡ (ë¹„ì¦ˆë‹ˆìŠ¤ ê³„íšìš©)
        forecast_horizon = self.business_kpis['promotional_planning_horizon']
        
        # ì´ ë§¤ì¶œ ë°ì´í„°
        total_sales = self.data[self.data['family'] == 'TOTAL'].copy()
        total_sales = total_sales.set_index('date')['sales'].sort_index()
        
        # ë¯¸ë˜ ì˜ˆì¸¡
        if best_model_name == 'Ensemble':
            # ì•™ìƒë¸”ì˜ ê²½ìš° ê°œë³„ ëª¨ë¸ë“¤ë¡œ ì˜ˆì¸¡ í›„ ê°€ì¤‘ í‰ê· 
            future_forecast = pd.Series(0, index=pd.date_range(
                total_sales.index[-1] + pd.Timedelta(weeks=1), 
                periods=forecast_horizon, freq='W'))
            
            for model_name, weight in best_model['weights'].items():
                if model_name in self.models and hasattr(self.models[model_name]['model'], 'forecast'):
                    individual_forecast = self.models[model_name]['model'].forecast(steps=forecast_horizon)
                    future_forecast += weight * individual_forecast
        else:
            # ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡
            future_forecast = best_model['model'].forecast(steps=forecast_horizon)
        
        # ëŒ€ì‹œë³´ë“œ ë°ì´í„° êµ¬ì„±
        dashboard_data = {
            'historical_data': total_sales,
            'future_forecast': future_forecast,
            'model_performance': {
                'best_model': best_model_name,
                'accuracy': f"{(1-best_model['mape']):.1%}",
                'mape': f"{best_model['mape']:.1%}",
                'last_updated': datetime.now().strftime("%Y-%m-%d %H:%M")
            },
            'business_metrics': self._calculate_business_metrics(total_sales, future_forecast),
            'alerts': self._generate_business_alerts(total_sales, future_forecast)
        }
        
        # ëŒ€ì‹œë³´ë“œ ì‹œê°í™”
        self._create_dashboard_visualization(dashboard_data)
        
        self.dashboard_data = dashboard_data
        return dashboard_data
    
    def _calculate_business_metrics(self, historical_data, forecast):
        """ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        
        # ìµœê·¼ 4ì£¼ vs ì˜ˆì¸¡ 4ì£¼ ë¹„êµ
        recent_4weeks = historical_data.tail(4).mean()
        forecast_4weeks = forecast.head(4).mean()
        
        growth_rate = (forecast_4weeks - recent_4weeks) / recent_4weeks
        
        # ê³„ì ˆì„± ì¡°ì •
        seasonal_factor = self.business_kpis['seasonal_adjustment_factor']
        seasonal_adjusted_forecast = forecast * seasonal_factor
        
        return {
            'recent_avg_weekly_sales': f"${recent_4weeks:,.0f}",
            'forecast_avg_weekly_sales': f"${forecast_4weeks:,.0f}",
            'growth_rate': f"{growth_rate:+.1%}",
            'total_forecast_8weeks': f"${forecast.sum():,.0f}",
            'seasonal_adjusted_total': f"${seasonal_adjusted_forecast.sum():,.0f}",
            'peak_week_forecast': f"${forecast.max():,.0f}",
            'lowest_week_forecast': f"${forecast.min():,.0f}"
        }
    
    def _generate_business_alerts(self, historical_data, forecast):
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì•Œë¦¼ ìƒì„±"""
        
        alerts = []
        
        # 1. ê¸‰ê²©í•œ ë³€í™” ê°ì§€
        recent_avg = historical_data.tail(4).mean()
        forecast_avg = forecast.head(4).mean()
        change_rate = (forecast_avg - recent_avg) / recent_avg
        
        if abs(change_rate) > 0.15:  # 15% ì´ìƒ ë³€í™”
            alert_type = "ğŸ“ˆ ê¸‰ì¦ ì˜ˆìƒ" if change_rate > 0 else "ğŸ“‰ ê¸‰ê° ì˜ˆìƒ"
            alerts.append({
                'type': alert_type,
                'message': f"ë‹¤ìŒ 4ì£¼ í‰ê·  ë§¤ì¶œì´ {change_rate:+.1%} ë³€í™” ì˜ˆìƒ",
                'priority': 'HIGH' if abs(change_rate) > 0.25 else 'MEDIUM'
            })
        
        # 2. ì¬ê³  ìµœì í™” ì•Œë¦¼
        peak_forecast = forecast.max()
        if peak_forecast > historical_data.quantile(0.9):  # ìƒìœ„ 10% ìˆ˜ì¤€
            alerts.append({
                'type': 'ğŸ“¦ ì¬ê³  ì¤€ë¹„',
                'message': f"ì˜ˆì¸¡ í”¼í¬ ë§¤ì¶œ ${peak_forecast:,.0f} - ì¬ê³  í™•ë³´ í•„ìš”",
                'priority': 'MEDIUM'
            })
        
        # 3. í”„ë¡œëª¨ì…˜ ê¸°íšŒ
        lowest_forecast = forecast.min()
        if lowest_forecast < historical_data.quantile(0.3):  # í•˜ìœ„ 30% ìˆ˜ì¤€
            alerts.append({
                'type': 'ğŸ¯ í”„ë¡œëª¨ì…˜ ê¸°íšŒ',
                'message': f"ì˜ˆì¸¡ ìµœì € ë§¤ì¶œ ì£¼ê°„ - ë§ˆì¼€íŒ… ìº í˜ì¸ ê³ ë ¤",
                'priority': 'LOW'
            })
        
        return alerts
    
    def _create_dashboard_visualization(self, dashboard_data):
        """ëŒ€ì‹œë³´ë“œ ì‹œê°í™”"""
        
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=['ğŸ“ˆ ë§¤ì¶œ ì˜ˆì¸¡', 'ğŸ“Š ì£¼ê°„ ì„±ì¥ë¥ ', 'ğŸ¯ ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­', 'âš ï¸ ì•Œë¦¼ ë° ê¶Œê³ ì‚¬í•­'],
            specs=[[{"colspan": 2}, None],
                   [{"type": "bar"}, {"type": "table"}]]
        )
        
        historical = dashboard_data['historical_data']
        forecast = dashboard_data['future_forecast']
        
        # 1. ë§¤ì¶œ ì˜ˆì¸¡ ì°¨íŠ¸
        fig.add_trace(
            go.Scatter(x=historical.index, y=historical.values, 
                      mode='lines', name='ê³¼ê±° ë§¤ì¶œ', line=dict(color='blue')),
            row=1, col=1
        )
        
        fig.add_trace(
            go.Scatter(x=forecast.index, y=forecast.values,
                      mode='lines+markers', name='ì˜ˆì¸¡ ë§¤ì¶œ', line=dict(color='red', dash='dash')),
            row=1, col=1
        )
        
        # 2. ì£¼ê°„ ì„±ì¥ë¥ 
        growth_rates = forecast.pct_change().fillna(0) * 100
        fig.add_trace(
            go.Bar(x=forecast.index, y=growth_rates.values, name='ì£¼ê°„ ì„±ì¥ë¥  (%)', marker_color='green'),
            row=2, col=1
        )
        
        # 3. ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ í…Œì´ë¸”
        metrics = dashboard_data['business_metrics']
        metric_names = list(metrics.keys())
        metric_values = list(metrics.values())
        
        fig.add_trace(
            go.Table(
                header=dict(values=['ë©”íŠ¸ë¦­', 'ê°’'], fill_color='lightblue'),
                cells=dict(values=[metric_names, metric_values], fill_color='white')
            ),
            row=2, col=2
        )
        
        fig.update_layout(
            title_text="ğŸª Store Sales ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ",
            title_x=0.5,
            height=800,
            showlegend=True
        )
        
        fig.show()
        
        # ì•Œë¦¼ ì¶œë ¥
        print(f"\nâš ï¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì•Œë¦¼:")
        for alert in dashboard_data['alerts']:
            priority_emoji = "ğŸ”´" if alert['priority'] == 'HIGH' else "ğŸŸ¡" if alert['priority'] == 'MEDIUM' else "ğŸŸ¢"
            print(f"   {priority_emoji} {alert['type']}: {alert['message']}")
        
        return dashboard_data
    
    def generate_executive_report(self):
        """ê²½ì˜ì§„ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        
        if not self.models or not self.dashboard_data:
            print("âŒ ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•´ì„œëŠ” ëª¨ë¸ê³¼ ëŒ€ì‹œë³´ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ“‹ ê²½ì˜ì§„ ìš”ì•½ ë³´ê³ ì„œ")
        print("=" * 50)
        
        # ìµœìš°ìˆ˜ ëª¨ë¸ ì •ë³´
        best_model_name = min(self.models.keys(), key=lambda x: self.models[x]['mape'])
        best_model = self.models[best_model_name]
        
        # ì´ ë§¤ì¶œ ë°ì´í„°
        total_sales = self.data[self.data['family'] == 'TOTAL'].copy()
        total_sales = total_sales.set_index('date')['sales'].sort_index()
        
        # ì—°ê°„ ë§¤ì¶œ ì¶”ì´
        annual_sales = total_sales.resample('Y').sum()
        
        print(f"ğŸ“Š **í•µì‹¬ ì„±ê³¼ ì§€í‘œ**")
        print(f"   ì˜ˆì¸¡ ì •í™•ë„: {(1-best_model['mape']):.1%} ({best_model_name} ëª¨ë¸)")
        print(f"   ì—°ê°„ ì´ ë§¤ì¶œ: ${annual_sales.iloc[-1]:,.0f}")
        print(f"   ì „ë…„ ëŒ€ë¹„ ì„±ì¥ë¥ : {annual_sales.pct_change().iloc[-1]:+.1%}")
        
        # ì˜ˆì¸¡ ìš”ì•½
        forecast_data = self.dashboard_data['future_forecast']
        metrics = self.dashboard_data['business_metrics']
        
        print(f"\nğŸ”® **8ì£¼ ì˜ˆì¸¡ ìš”ì•½**")
        print(f"   ì˜ˆì¸¡ ì´ ë§¤ì¶œ: {metrics['total_forecast_8weeks']}")
        print(f"   ì£¼ê°„ í‰ê· : {metrics['forecast_avg_weekly_sales']}")
        print(f"   ì„±ì¥ë¥ : {metrics['growth_rate']}")
        print(f"   í”¼í¬ ì˜ˆìƒ: {metrics['peak_week_forecast']}")
        
        # ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ
        alerts = self.dashboard_data['alerts']
        high_priority_alerts = [a for a in alerts if a['priority'] == 'HIGH']
        
        print(f"\nâš ï¸ **ì£¼ìš” ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ**")
        if high_priority_alerts:
            for alert in high_priority_alerts:
                print(f"   ğŸ”´ {alert['type']}: {alert['message']}")
        else:
            print(f"   âœ… í˜„ì¬ ê³ ìœ„í—˜ ì•Œë¦¼ ì—†ìŒ")
        
        # ê¶Œê³ ì‚¬í•­
        print(f"\nğŸ’¡ **ê¶Œê³ ì‚¬í•­**")
        print(f"   1. ì˜ˆì¸¡ ëª¨ë¸ ì •í™•ë„ê°€ ëª©í‘œ ë‹¬ì„± - í”„ë¡œë•ì…˜ ë°°í¬ ê¶Œì¥")
        print(f"   2. ì£¼ê°„ ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ì˜ˆì¸¡ ì„±ëŠ¥ ì§€ì† ê´€ì°°")
        print(f"   3. ê³„ì ˆì„± íŒ¨í„´ì„ ê³ ë ¤í•œ ì¬ê³  ê³„íš ìˆ˜ë¦½")
        print(f"   4. ì™¸ë¶€ ë³€ìˆ˜(í”„ë¡œëª¨ì…˜, ê²½ì œì§€í‘œ) í†µí•© ê³ ë ¤")
        
        return {
            'model_performance': f"{(1-best_model['mape']):.1%}",
            'annual_sales': f"${annual_sales.iloc[-1]:,.0f}",
            'forecast_summary': metrics,
            'alerts': alerts,
            'recommendations': [
                "í”„ë¡œë•ì…˜ ë°°í¬ ê¶Œì¥",
                "ì£¼ê°„ ëª¨ë‹ˆí„°ë§ ì‹¤ì‹œ", 
                "ê³„ì ˆì„± ê¸°ë°˜ ì¬ê³  ê³„íš",
                "ì™¸ë¶€ ë³€ìˆ˜ í†µí•© ê²€í† "
            ]
        }

# Store Sales ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹¤í–‰
# Store Sales ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹¤í–‰
print("\nğŸª Store Sales ì¢…í•© ì˜ˆì¸¡ ì‹œìŠ¤í…œ êµ¬ì¶•")
print("=" * 60)

# 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ë°ì´í„° ìƒì„±
forecasting_system = StoreSalesForecastingSystem()
store_data = forecasting_system.simulate_store_sales_data()

# 2. ì¢…í•© EDA ë¶„ì„
eda_results = forecasting_system.comprehensive_eda_analysis()

# 3. ì¢…í•© ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•
model_results = forecasting_system.build_comprehensive_forecasting_models()

# 4. ë¹„ì¦ˆë‹ˆìŠ¤ ëŒ€ì‹œë³´ë“œ ìƒì„±
dashboard = forecasting_system.create_business_dashboard()

# 5. ê²½ì˜ì§„ ë³´ê³ ì„œ ìƒì„±
executive_report = forecasting_system.generate_executive_report()

print(f"\nâœ… Store Sales ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì™„ì „ êµ¬ì¶•!")
print(f"   ğŸ“Š 5ë…„ê°„ ì£¼ê°„ ë§¤ì¶œ ë°ì´í„° ë¶„ì„")
print(f"   ğŸ”® 5ê°œ ì˜ˆì¸¡ ëª¨ë¸ ë¹„êµ (ARIMA, SARIMA, Holt-Winters, ì•™ìƒë¸”, Naive)")
print(f"   ğŸ“ˆ ì‹¤ì‹œê°„ ë¹„ì¦ˆë‹ˆìŠ¤ ëŒ€ì‹œë³´ë“œ")
print(f"   ğŸ¯ ìë™ ì•Œë¦¼ ë° ì˜ì‚¬ê²°ì • ì§€ì›")
print(f"   ğŸ’¼ ì™„ì „í•œ í”„ë¡œë•ì…˜ ì¤€ë¹„ ì‹œìŠ¤í…œ")
print(f"   ğŸ“‹ ê²½ì˜ì§„ ìš”ì•½ ë³´ê³ ì„œ")

## ì§ì ‘ í•´ë³´ê¸° / ì—°ìŠµ ë¬¸ì œ

### ğŸ¯ ì—°ìŠµ ë¬¸ì œ 1: ARIMA ëª¨ë¸ ì»¤ìŠ¤í„°ë§ˆì´ì§• (ë‚œì´ë„: â­â­â­)

**ë¬¸ì œ**: ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ARIMA ëª¨ë¸ì„ êµ¬ì¶•í•˜ì„¸ìš”.

```python
# ë‹¤ìŒ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬:
custom_data = pd.Series([120, 125, 118, 130, 135, 128, 142, 138, 145, 152, 
                        148, 155, 162, 158, 165, 172, 168, 175, 182, 178])

# ìš”êµ¬ì‚¬í•­:
# 1. ì •ìƒì„± ê²€ì •ì„ ìˆ˜í–‰í•˜ê³  í•„ìš”ì‹œ ì°¨ë¶„ ì ìš©
# 2. ACF/PACF ë¶„ì„ìœ¼ë¡œ ì´ˆê¸° ì°¨ìˆ˜ ì¶”ì •
# 3. 3ê°œ ì´ìƒì˜ ARIMA ëª¨ë¸ ë¹„êµ
# 4. ìµœì  ëª¨ë¸ë¡œ 5ê¸°ê°„ ì˜ˆì¸¡
# 5. ì˜ˆì¸¡ êµ¬ê°„ê¹Œì§€ í¬í•¨í•œ ì‹œê°í™”

# íŒíŠ¸: Box-Jenkins 4ë‹¨ê³„ ë°©ë²•ë¡  í™œìš©
```

**ê¸°ëŒ€ ê²°ê³¼**: ì²´ê³„ì ì¸ ARIMA ëª¨ë¸ë§ ê³¼ì •ê³¼ ì‹ ë¢°ë„ ë†’ì€ ì˜ˆì¸¡

### ğŸ¯ ì—°ìŠµ ë¬¸ì œ 2: ê³„ì ˆì„± ëª¨ë¸ ì‹¬í™” ë¶„ì„ (ë‚œì´ë„: â­â­â­â­)

**ë¬¸ì œ**: ì›”ë³„ ê´€ê´‘ê° ìˆ˜ ë°ì´í„°ë¡œ SARIMA vs Holt-Winters ë¹„êµ ë¶„ì„í•˜ì„¸ìš”.

```python
# ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
np.random.seed(123)
months = pd.date_range('2019-01-01', '2023-12-31', freq='M')
base_trend = np.linspace(10000, 15000, len(months))
seasonal_pattern = 3000 * np.sin(2 * np.pi * np.arange(len(months)) / 12)
tourism_data = base_trend + seasonal_pattern + np.random.normal(0, 500, len(months))

# ë¶„ì„ ê³¼ì œ:
# 1. ê³„ì ˆì„± ë¶„í•´ì™€ ê°•ë„ ë¶„ì„
# 2. SARIMA(p,d,q)(P,D,Q)12 ëª¨ë¸ êµ¬ì¶•
# 3. Holt-Winters ê°€ë²•/ìŠ¹ë²• ëª¨ë¸ ë¹„êµ
# 4. êµì°¨ê²€ì¦ ê¸°ë°˜ ì„±ëŠ¥ í‰ê°€
# 5. ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„ê³¼ ê¶Œê³ ì‚¬í•­ ë„ì¶œ
```

**í‰ê°€ ê¸°ì¤€**: ëª¨ë¸ ì„ íƒì˜ ë…¼ë¦¬ì„±, í•´ì„ì˜ ì •í™•ì„±, ì‹¤ë¬´ ì ìš©ì„±

### ğŸ¯ ì—°ìŠµ ë¬¸ì œ 3: AI í˜‘ì—… ëª¨ë¸ í•´ì„ ì‹œìŠ¤í…œ (ë‚œì´ë„: â­â­â­â­â­)

**ë¬¸ì œ**: 7ì¥ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì„ í™œìš©í•œ ìë™ ëª¨ë¸ í•´ì„ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì„¸ìš”.

```python
# êµ¬í˜„ ìš”êµ¬ì‚¬í•­:
class AutoModelInterpreter:
    def __init__(self):
        self.interpretation_templates = {
            'arima': "ARIMA ëª¨ë¸ í•´ì„ í…œí”Œë¦¿",
            'sarima': "SARIMA ëª¨ë¸ í•´ì„ í…œí”Œë¦¿", 
            'exponential': "ì§€ìˆ˜í‰í™œë²• í•´ì„ í…œí”Œë¦¿"
        }
    
    def generate_interpretation(self, model_result, business_context):
        """
        ëª¨ë¸ ê²°ê³¼ë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì–¸ì–´ë¡œ ìë™ ë²ˆì—­
        
        ì…ë ¥: ëª¨ë¸ ê°ì²´, ë¹„ì¦ˆë‹ˆìŠ¤ ë§¥ë½
        ì¶œë ¥: ê²½ì˜ì§„ìš© í•´ì„, ì‹¤ë¬´ì§„ìš© í•´ì„, ì•¡ì…˜ ì•„ì´í…œ
        """
        pass
    
    def create_business_narrative(self, forecast_results):
        """
        ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìŠ¤í† ë¦¬í…”ë§ í˜•íƒœë¡œ ë³€í™˜
        """
        pass

# í‰ê°€ ìš”ì†Œ:
# 1. CLEAR í”„ë¡¬í”„íŠ¸ ì›ì¹™ ì ìš©
# 2. ë‹¤ì–‘í•œ ëª¨ë¸ íƒ€ì… ì§€ì›
# 3. ì²­ì¤‘ë³„ ë§ì¶¤ í•´ì„
# 4. ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œê³ ì‚¬í•­ ìƒì„±
```

**ë„ì „ ê³¼ì œ**: GPT API ì—°ë™í•˜ì—¬ ì‹¤ì œ AI í•´ì„ êµ¬í˜„

### ğŸ¯ ì—°ìŠµ ë¬¸ì œ 4: ì¢…í•© ì˜ˆì¸¡ ì‹œìŠ¤í…œ í™•ì¥ (ë‚œì´ë„: â­â­â­â­â­)

**ë¬¸ì œ**: Store Sales ì‹œìŠ¤í…œì„ ë‹¤ìŒ ê¸°ëŠ¥ìœ¼ë¡œ í™•ì¥í•˜ì„¸ìš”.

1. **ë©€í‹° ì‹œê³„ì—´ ì²˜ë¦¬**: ìƒí’ˆêµ°ë³„ ë™ì‹œ ì˜ˆì¸¡
2. **ì™¸ë¶€ ë³€ìˆ˜ í†µí•©**: ë‚ ì”¨, ê²½ì œì§€í‘œ, ì´ë²¤íŠ¸ ë°ì´í„°
3. **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: ì˜ˆì¸¡ ì„±ëŠ¥ ìë™ ì¶”ì 
4. **A/B í…ŒìŠ¤íŠ¸**: ëª¨ë¸ ì—…ë°ì´íŠ¸ íš¨ê³¼ ê²€ì¦
5. **ë°°í¬ íŒŒì´í”„ë¼ì¸**: MLOps ê´€ì ì˜ ì‹œìŠ¤í…œ ì„¤ê³„

**êµ¬í˜„ ê°€ì´ë“œë¼ì¸**:
```python
# í™•ì¥ ì•„í‚¤í…ì²˜ ì˜ˆì‹œ
class AdvancedForecastingSystem:
    def __init__(self):
        self.multi_series_manager = MultiSeriesManager()
        self.external_data_integrator = ExternalDataIntegrator()
        self.performance_monitor = RealTimeMonitor()
        self.ab_tester = ModelABTester()
        self.deployment_pipeline = MLOpsPipeline()
    
    def forecast_all_series(self, external_data=None):
        """ëª¨ë“  ì‹œê³„ì—´ ë™ì‹œ ì˜ˆì¸¡"""
        pass
    
    def monitor_performance(self):
        """ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
        pass
    
    def deploy_model_update(self, new_model):
        """ì•ˆì „í•œ ëª¨ë¸ ì—…ë°ì´íŠ¸"""
        pass
```

## ìš”ì•½ / í•µì‹¬ ì •ë¦¬

### âœ… 8ì¥ Part 2 í•™ìŠµ ì„±ê³¼

**ğŸ”„ ì „í†µì  ì‹œê³„ì—´ ëª¨ë¸ ì™„ì „ ì •ë³µ**
- **AR/MA/ARMA ëª¨ë¸**: ì‹œê³„ì—´ì˜ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œì™€ ìˆ˜í•™ì  ì›ë¦¬ ì™„ì „ ì´í•´
- **Box-Jenkins ë°©ë²•ë¡ **: ì²´ê³„ì ì¸ ARIMA ëª¨ë¸ë§ 4ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ ë§ˆìŠ¤í„°
- **ì •ìƒì„±ê³¼ ì°¨ë¶„**: ADF/KPSS ê²€ì •ê³¼ ì ì • ì°¨ë¶„ ì°¨ìˆ˜ ìë™ ê²°ì •
- **ACF/PACF ë¶„ì„**: ëª¨ë¸ ì‹ë³„ì˜ í•µì‹¬ ë„êµ¬ í™œìš©ë²•ê³¼ íŒ¨í„´ í•´ì„

**ğŸ“Š ê³ ê¸‰ ì‹œê³„ì—´ ëª¨ë¸ë§ ê¸°ë²•**
- **SARIMA ëª¨ë¸**: ê³„ì ˆì„±ê¹Œì§€ ê³ ë ¤í•œ ê³ ê¸‰ ëª¨ë¸ë§ê³¼ ìë™ ì°¨ìˆ˜ ì„ íƒ
- **ì§€ìˆ˜í‰í™œë²•**: ë‹¨ìˆœ/ì´ì¤‘/ì‚¼ì¤‘ í‰í™œë²•ê³¼ Holt-Winters ëª¨ë¸ ë¹„êµ
- **ì„±ëŠ¥ í‰ê°€**: MAPE, MAE, RMSE ë“± ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œì™€ êµì°¨ê²€ì¦
- **ëª¨ë¸ ì§„ë‹¨**: Ljung-Box, Jarque-Bera ê²€ì •ì„ í†µí•œ ëª¨ë¸ ì í•©ì„± ê²€ì¦

**ğŸ¤– AI í˜‘ì—… ìµœì í™”**
- **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**: 7ì¥ CLEAR ì›ì¹™ì„ ì‹œê³„ì—´ ëª¨ë¸ í•´ì„ì— íŠ¹í™” ì ìš©
- **ìë™ ëª¨ë¸ íŠœë‹**: ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œë³„ ìµœì í™” ì „ëµê³¼ ì§€ëŠ¥í˜• í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
- **ëª¨ë¸ í•´ì„**: ë³µì¡í•œ í†µê³„ ê²°ê³¼ë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì–¸ì–´ë¡œ ìë™ ë²ˆì—­
- **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ ëª¨ë¸ ì„±ëŠ¥ ì¶”ì ê³¼ ìë™ ì•Œë¦¼ ì‹œìŠ¤í…œ

**ğŸª ì‹¤ì „ ë¹„ì¦ˆë‹ˆìŠ¤ ì‹œìŠ¤í…œ**
- **Store Sales ì˜ˆì¸¡**: 5ë…„ê°„ ì£¼ê°„ ë°ì´í„°ë¡œ ì™„ì „í•œ ì˜ˆì¸¡ ì‹œìŠ¤í…œ êµ¬ì¶•
- **ì•™ìƒë¸” ëª¨ë¸**: ë‹¤ì¤‘ ëª¨ë¸ ê²°í•©ê³¼ ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ í‰ê· 
- **ë¹„ì¦ˆë‹ˆìŠ¤ ëŒ€ì‹œë³´ë“œ**: ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œê°í™”ì™€ KPI ëª¨ë‹ˆí„°ë§
- **ì˜ì‚¬ê²°ì • ì§€ì›**: ìë™ ì•Œë¦¼ê³¼ ê¶Œê³ ì‚¬í•­ìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ì•¡ì…˜ ê°€ì´ë“œ

### ğŸ¯ ì‹¤ë¬´ ì ìš© ëŠ¥ë ¥

**ğŸ“Š ë°ì´í„° ë¶„ì„ ì „ë¬¸ì„±**
- ì‹œê³„ì—´ ë°ì´í„°ì˜ íŠ¹ì„±ì„ ì •í™•íˆ íŒŒì•…í•˜ê³  ì ì ˆí•œ ëª¨ë¸ ì„ íƒ
- ì •ìƒì„±, ê³„ì ˆì„±, íŠ¸ë Œë“œ ë“± í•µì‹¬ ê°œë…ì˜ ì‹¤ë¬´ì  í™œìš©
- ëª¨ë¸ ì§„ë‹¨ê³¼ ê²€ì¦ì„ í†µí•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼ ë„ì¶œ

**ğŸ”® ì˜ˆì¸¡ ëª¨ë¸ë§ ì—­ëŸ‰**
- Box-Jenkins ë°©ë²•ë¡  ê¸°ë°˜ ì²´ê³„ì  ëª¨ë¸ êµ¬ì¶•
- ë‹¤ì–‘í•œ ì‹œê³„ì—´ ëª¨ë¸ì˜ ì¥ë‹¨ì  ì´í•´ì™€ ìƒí™©ë³„ ìµœì  ì„ íƒ
- ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”ì™€ ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬ìŠ¤í¬ í‰ê°€

**ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì°½ì¶œ**
- í†µê³„ ëª¨ë¸ ê²°ê³¼ë¥¼ ê²½ì˜ì§„ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì–¸ì–´ë¡œ ë²ˆì—­
- ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜(ë§¤ì¶œ, ë¹„ìš©ì ˆê° ë“±)ë¡œ ì—°ê²°
- ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì œê³µ

**ğŸš€ ì‹œìŠ¤í…œ êµ¬ì¶• ê²½í—˜**
- í”„ë¡œí† íƒ€ì…ë¶€í„° í”„ë¡œë•ì…˜ê¹Œì§€ ì™„ì „í•œ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì„¤ê³„
- ëª¨ë¸ ëª¨ë‹ˆí„°ë§ê³¼ ì„±ëŠ¥ ê´€ë¦¬ë¥¼ ìœ„í•œ ìš´ì˜ ì²´ê³„ êµ¬ì¶•
- AI í˜‘ì—…ì„ í†µí•œ íš¨ìœ¨ì  ê°œë°œê³¼ ì§€ì†ì  ê°œì„  í”„ë¡œì„¸ìŠ¤

### ğŸ”— ë‹¤ìŒ í•™ìŠµ ê²½ë¡œ

**ğŸ“ˆ 8ì¥ Part 3: ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡**
- ì‹œê³„ì—´ ë¬¸ì œì˜ ì§€ë„í•™ìŠµ ë³€í™˜ê³¼ íŠ¹ì„± ê³µí•™
- ëœë¤ í¬ë ˆìŠ¤íŠ¸, XGBoostë¥¼ í™œìš©í•œ ë¹„ì„ í˜• íŒ¨í„´ í•™ìŠµ
- ì™¸ë¶€ ë³€ìˆ˜ í†µí•©ê³¼ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ëª¨ë¸ë§

**ğŸ§  8ì¥ Part 4: ë”¥ëŸ¬ë‹ ì‹œê³„ì—´ ëª¨ë¸**
- LSTM, GRUë¥¼ í™œìš©í•œ ìˆœí™˜ ì‹ ê²½ë§ ì‹œê³„ì—´ ì˜ˆì¸¡
- Transformerì™€ Attention ë©”ì»¤ë‹ˆì¦˜ì˜ ì‹œê³„ì—´ ì ìš©
- ì‹œê³„ì—´ ìƒì„± ëª¨ë¸ê³¼ ì´ìƒ íƒì§€ ê¸°ë²•

**ğŸ’¡ 8ì¥ Part 5: ê³ ê¸‰ ì•™ìƒë¸”ê³¼ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸**
- ì „í†µì  + ML + ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ìµœì  ê²°í•©
- ë™ì  ì•™ìƒë¸”ê³¼ ì ì‘ì  ê°€ì¤‘ì¹˜ ì¡°ì •
- ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”ì™€ í™•ë¥ ì  ì˜ˆì¸¡

**ğŸŒ 8ì¥ Part 6: ì‹¤ì‹œê°„ ì‹œê³„ì—´ ë¶„ì„ ì‹œìŠ¤í…œ**
- ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬ì™€ ì˜¨ë¼ì¸ í•™ìŠµ
- ë¶„ì‚° ì²˜ë¦¬ì™€ í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ ì„¤ê³„
- MLOps ê´€ì ì˜ ì‹œê³„ì—´ ëª¨ë¸ ìš´ì˜ê³¼ ê´€ë¦¬

### ğŸ¨ 8ì¥ Part 2 ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸

"Traditional time series forecasting dashboard showing ARIMA, SARIMA, exponential smoothing models comparison with business metrics, sales forecast charts, performance indicators, professional analytics interface, modern business intelligence design, data science visualization, Box-Jenkins methodology workflow, seasonal decomposition plots, statistical diagnostics charts"

---

**ğŸ“ 8ì¥ Part 2 ì™„ë£Œ!**

ì „í†µì  ì‹œê³„ì—´ ëª¨ë¸ì˜ ì´ë¡ ì  ê¸°ì´ˆë¶€í„° ì‹¤ë¬´ ì ìš©ê¹Œì§€ ì™„ì „íˆ ë§ˆìŠ¤í„°í–ˆìŠµë‹ˆë‹¤. ARIMA, SARIMA, ì§€ìˆ˜í‰í™œë²•ì˜ í•µì‹¬ ì›ë¦¬ë¥¼ ì´í•´í•˜ê³ , AI í˜‘ì—…ì„ í†µí•´ ëª¨ë¸ í•´ì„ê³¼ ìµœì í™”ë¥¼ ìë™í™”í•˜ëŠ” ëŠ¥ë ¥ì„ ê°–ì¶”ì—ˆìŠµë‹ˆë‹¤. 

ì´ì œ Part 3ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ì˜ í˜ì„ ë¹Œë ¤ ì‹œê³„ì—´ ì˜ˆì¸¡ì˜ ìƒˆë¡œìš´ ì§€í‰ì„ ì—´ì–´ë³´ê² ìŠµë‹ˆë‹¤! ğŸš€