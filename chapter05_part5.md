# 5ì¥ Part 5: í”„ë¡œì íŠ¸ - ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ ë° í‰ê°€

## í•™ìŠµ ëª©í‘œ
ì´ë²ˆ íŒŒíŠ¸ë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œë¥¼ ë¨¸ì‹ ëŸ¬ë‹ ë¬¸ì œë¡œ ì²´ê³„ì ìœ¼ë¡œ ì •ì˜í•  ìˆ˜ ìˆë‹¤
- ì „ì²´ ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸ì„ ì²˜ìŒë¶€í„° ëê¹Œì§€ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤
- ëª¨ë¸ ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•œ ë‹¤ì–‘í•œ ê¸°ë²•ì„ ì²´ê³„ì ìœ¼ë¡œ ì ìš©í•  ìˆ˜ ìˆë‹¤
- ìµœì¢… ê²°ê³¼ë¥¼ í•´ì„í•˜ê³  ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ì˜ë¯¸ ìˆëŠ” ë³´ê³ ì„œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆë‹¤

## ì´ë²ˆ íŒŒíŠ¸ ë¯¸ë¦¬ë³´ê¸°

ì§€ê¸ˆê¹Œì§€ Part 1~4ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ì˜ ì´ë¡ ê³¼ ê°œë³„ ê¸°ë²•ë“¤ì„ ë°°ì› ë‹¤ë©´, ì´ì œëŠ” ê·¸ ëª¨ë“  ê²ƒì„ ì¢…í•©í•˜ì—¬ **ì‹¤ì œ í”„ë¡œì íŠ¸**ë¥¼ ìˆ˜í–‰í•  ì°¨ë¡€ì…ë‹ˆë‹¤! 

ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œëŠ” **íƒ€ì´íƒ€ë‹‰ ìƒì¡´ ì˜ˆì¸¡**ê³¼ **ì£¼íƒ ê°€ê²© ì˜ˆì¸¡**ì´ë¼ëŠ” ë‘ ê°€ì§€ ëŒ€í‘œì ì¸ ë¬¸ì œë¥¼ í†µí•´, ì‹¤ë¬´ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ì²´í—˜í•˜ê²Œ ë©ë‹ˆë‹¤.

> ğŸ’¡ **ì™œ ì´ ë‘ í”„ë¡œì íŠ¸ì¸ê°€ìš”?**
> - **íƒ€ì´íƒ€ë‹‰**: ë¶„ë¥˜ ë¬¸ì œì˜ ì •ì„! ì—­ì‚¬ì  ë°ì´í„°ë¡œ í¥ë¯¸ë¡­ê³ , ë‹¤ì–‘í•œ íŠ¹ì„±ì´ ìˆì–´ íŠ¹ì„± ê³µí•™ì„ ì—°ìŠµí•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤.
> - **ì£¼íƒ ê°€ê²©**: íšŒê·€ ë¬¸ì œì˜ ëŒ€í‘œì£¼ì! ì‹¤ìƒí™œê³¼ ë°€ì ‘í•˜ê³ , ë³µì¡í•œ ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ì—°ìŠµì— ìµœì ì…ë‹ˆë‹¤.

## 1. ë¬¸ì œ ì •ì˜ì™€ ê³„íš ìˆ˜ë¦½

### 1.1 ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œ ì´í•´í•˜ê¸°

ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ì˜ ì²« ë‹¨ê³„ëŠ” **ë¬¸ì œë¥¼ ëª…í™•íˆ ì •ì˜**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 

```python
# í”„ë¡œì íŠ¸ ëª©í‘œ ì •ì˜ í”„ë ˆì„ì›Œí¬
class ProjectDefinition:
    def __init__(self, project_name):
        self.project_name = project_name
        self.business_goal = None
        self.ml_problem_type = None
        self.evaluation_metric = None
        self.constraints = []
        self.deliverables = []
    
    def define_project(self):
        """í”„ë¡œì íŠ¸ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì •ì˜í•©ë‹ˆë‹¤."""
        print(f"=== {self.project_name} í”„ë¡œì íŠ¸ ì •ì˜ ===")
        print(f"ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œ: {self.business_goal}")
        print(f"ML ë¬¸ì œ ìœ í˜•: {self.ml_problem_type}")
        print(f"í‰ê°€ ì§€í‘œ: {self.evaluation_metric}")
        print(f"ì œì•½ ì‚¬í•­: {', '.join(self.constraints)}")
        print(f"ì‚°ì¶œë¬¼: {', '.join(self.deliverables)}")

# í”„ë¡œì íŠ¸ 1: íƒ€ì´íƒ€ë‹‰ ìƒì¡´ ì˜ˆì¸¡
titanic_project = ProjectDefinition("íƒ€ì´íƒ€ë‹‰ ìƒì¡´ ì˜ˆì¸¡")
titanic_project.business_goal = "ìŠ¹ê° ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì¡´ ê°€ëŠ¥ì„± ì˜ˆì¸¡"
titanic_project.ml_problem_type = "ì´ì§„ ë¶„ë¥˜ (Binary Classification)"
titanic_project.evaluation_metric = "ì •í™•ë„(Accuracy), ì •ë°€ë„(Precision), ì¬í˜„ìœ¨(Recall)"
titanic_project.constraints = ["1912ë…„ ë‹¹ì‹œ ë°ì´í„°ë§Œ ì‚¬ìš©", "ê²°ì¸¡ì¹˜ ì²˜ë¦¬ í•„ìš”"]
titanic_project.deliverables = ["ì˜ˆì¸¡ ëª¨ë¸", "íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„", "ìƒì¡´ ìš”ì¸ ë³´ê³ ì„œ"]

titanic_project.define_project()
```

**ğŸ¯ ì™œ ë¬¸ì œ ì •ì˜ê°€ ì¤‘ìš”í•œê°€ìš”?**
- **ë°©í–¥ì„± ì œì‹œ**: í”„ë¡œì íŠ¸ì˜ ëª©í‘œê°€ ëª…í™•í•´ì•¼ ì˜¬ë°”ë¥¸ ë°©í–¥ìœ¼ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **í‰ê°€ ê¸°ì¤€ ì„¤ì •**: ì–´ë–¤ ì§€í‘œë¡œ ì„±ê³µì„ ì¸¡ì •í• ì§€ ë¯¸ë¦¬ ì •í•´ì•¼ í•©ë‹ˆë‹¤.
- **ìì› ê³„íš**: í•„ìš”í•œ ë°ì´í„°, ì‹œê°„, ì¸ë ¥ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 1.2 ë°ì´í„° ì´í•´ì™€ íƒìƒ‰ ê³„íš

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

# ë°ì´í„° íƒìƒ‰ ì²´í¬ë¦¬ìŠ¤íŠ¸
class DataExplorationChecklist:
    def __init__(self, df):
        self.df = df
        self.checks = {
            'ë°ì´í„° í¬ê¸°': self.check_shape,
            'ë°ì´í„° íƒ€ì…': self.check_dtypes,
            'ê²°ì¸¡ì¹˜': self.check_missing,
            'ì¤‘ë³µê°’': self.check_duplicates,
            'ê¸°ë³¸ í†µê³„': self.check_statistics
        }
    
    def check_shape(self):
        return f"í–‰: {self.df.shape[0]}, ì—´: {self.df.shape[1]}"
    
    def check_dtypes(self):
        return self.df.dtypes.value_counts()
    
    def check_missing(self):
        missing = self.df.isnull().sum()
        return missing[missing > 0]
    
    def check_duplicates(self):
        return f"ì¤‘ë³µ í–‰ ìˆ˜: {self.df.duplicated().sum()}"
    
    def check_statistics(self):
        return self.df.describe()
    
    def run_all_checks(self):
        """ëª¨ë“  ì²´í¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        for check_name, check_func in self.checks.items():
            print(f"\n=== {check_name} ===")
            print(check_func())


## 2. íƒ€ì´íƒ€ë‹‰ ìƒì¡´ ì˜ˆì¸¡ í”„ë¡œì íŠ¸

### 2.1 ë°ì´í„° ë¡œë“œ ë° ì´ˆê¸° íƒìƒ‰

```python
# íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ë¡œë“œ
# ì‹¤ì œë¡œëŠ” pd.read_csv('titanic.csv')ë¡œ ë¡œë“œí•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
def load_titanic_data():
    """íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” Kaggleì—ì„œ ë‹¤ìš´ë¡œë“œ)
    np.random.seed(42)
    n_samples = 891
    
    data = {
        'PassengerId': range(1, n_samples + 1),
        'Survived': np.random.randint(0, 2, n_samples),
        'Pclass': np.random.choice([1, 2, 3], n_samples, p=[0.24, 0.21, 0.55]),
        'Name': ['Passenger_' + str(i) for i in range(n_samples)],
        'Sex': np.random.choice(['male', 'female'], n_samples, p=[0.65, 0.35]),
        'Age': np.random.normal(30, 15, n_samples),
        'SibSp': np.random.poisson(0.5, n_samples),
        'Parch': np.random.poisson(0.4, n_samples),
        'Ticket': ['Ticket_' + str(i) for i in range(n_samples)],
        'Fare': np.random.exponential(32, n_samples),
        'Cabin': np.random.choice(['A', 'B', 'C', 'D', 'E', 'F', 'G', np.nan], 
                                 n_samples, p=[0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.86]),
        'Embarked': np.random.choice(['S', 'C', 'Q', np.nan], 
                                    n_samples, p=[0.70, 0.20, 0.09, 0.01])
    }
    
    df = pd.DataFrame(data)
    # ì¼ë¶€ Ageë¥¼ ê²°ì¸¡ì¹˜ë¡œ ë§Œë“¤ê¸°
    df.loc[np.random.choice(df.index, 177, replace=False), 'Age'] = np.nan
    
    return df

# ë°ì´í„° ë¡œë“œ
df_titanic = load_titanic_data()

# ì´ˆê¸° íƒìƒ‰
explorer = DataExplorationChecklist(df_titanic)
explorer.run_all_checks()
```

### 2.2 íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)

```python
def perform_titanic_eda(df):
    """íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì— ëŒ€í•œ EDAë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # 1. ìƒì¡´ìœ¨ ë¶„í¬
    survival_counts = df['Survived'].value_counts()
    axes[0, 0].pie(survival_counts, labels=['ì‚¬ë§', 'ìƒì¡´'], autopct='%1.1f%%', 
                   colors=['#ff6b6b', '#4ecdc4'])
    axes[0, 0].set_title('ì „ì²´ ìƒì¡´ìœ¨')
    
    # 2. ì„±ë³„ì— ë”°ë¥¸ ìƒì¡´ìœ¨
    survival_by_sex = df.groupby('Sex')['Survived'].mean()
    axes[0, 1].bar(survival_by_sex.index, survival_by_sex.values, 
                   color=['#5f9ea0', '#ff69b4'])
    axes[0, 1].set_title('ì„±ë³„ ìƒì¡´ìœ¨')
    axes[0, 1].set_ylabel('ìƒì¡´ìœ¨')
    
    # 3. ê°ì‹¤ ë“±ê¸‰ë³„ ìƒì¡´ìœ¨
    survival_by_class = df.groupby('Pclass')['Survived'].mean()
    axes[0, 2].bar(survival_by_class.index, survival_by_class.values,
                   color=['#ffd700', '#c0c0c0', '#cd7f32'])
    axes[0, 2].set_title('ê°ì‹¤ ë“±ê¸‰ë³„ ìƒì¡´ìœ¨')
    axes[0, 2].set_xlabel('ê°ì‹¤ ë“±ê¸‰')
    axes[0, 2].set_ylabel('ìƒì¡´ìœ¨')
    
    # 4. ë‚˜ì´ ë¶„í¬
    df['Age'].dropna().hist(bins=30, ax=axes[1, 0], color='#6c5ce7')
    axes[1, 0].set_title('ìŠ¹ê° ë‚˜ì´ ë¶„í¬')
    axes[1, 0].set_xlabel('ë‚˜ì´')
    
    # 5. ë‚˜ì´ëŒ€ë³„ ìƒì¡´ìœ¨
    age_bins = [0, 18, 35, 50, 65, 100]
    age_labels = ['ì•„ë™', 'ì²­ë…„', 'ì¤‘ë…„', 'ì¥ë…„', 'ë…¸ë…„']
    df['AgeGroup'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels)
    
    survival_by_age = df.groupby('AgeGroup')['Survived'].mean()
    axes[1, 1].bar(survival_by_age.index, survival_by_age.values,
                   color='#74b9ff')
    axes[1, 1].set_title('ë‚˜ì´ëŒ€ë³„ ìƒì¡´ìœ¨')
    axes[1, 1].set_xlabel('ë‚˜ì´ëŒ€')
    axes[1, 1].set_ylabel('ìƒì¡´ìœ¨')
    
    # 6. ìš”ê¸ˆ ë¶„í¬
    df['Fare'].hist(bins=30, ax=axes[1, 2], color='#fdcb6e')
    axes[1, 2].set_title('í‹°ì¼“ ìš”ê¸ˆ ë¶„í¬')
    axes[1, 2].set_xlabel('ìš”ê¸ˆ')
    
    plt.tight_layout()
    plt.show()
    
    return df

# EDA ìˆ˜í–‰
df_titanic = perform_titanic_eda(df_titanic)
```

**ğŸ’¡ EDAì—ì„œ ë°œê²¬í•œ ì¸ì‚¬ì´íŠ¸**
1. **ì„±ë³„ ì°¨ì´**: ì—¬ì„±ì˜ ìƒì¡´ìœ¨ì´ ë‚¨ì„±ë³´ë‹¤ í›¨ì”¬ ë†’ìŒ (ì—¬ì„±ê³¼ ì•„ì´ ë¨¼ì € ì›ì¹™)
2. **ê°ì‹¤ ë“±ê¸‰**: 1ë“±ê¸‰ ìŠ¹ê°ì˜ ìƒì¡´ìœ¨ì´ 3ë“±ê¸‰ë³´ë‹¤ ë†’ìŒ (ê²½ì œì  ì§€ìœ„ì˜ ì˜í–¥)
3. **ë‚˜ì´**: ì•„ë™ì˜ ìƒì¡´ìœ¨ì´ ìƒëŒ€ì ìœ¼ë¡œ ë†’ìŒ
4. **ìš”ê¸ˆ**: ë†’ì€ ìš”ê¸ˆì„ ì§€ë¶ˆí•œ ìŠ¹ê°ì˜ ìƒì¡´ìœ¨ì´ ë†’ìŒ

### 2.3 íŠ¹ì„± ê³µí•™ (Feature Engineering)

```python
def feature_engineering_titanic(df):
    """íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì— ëŒ€í•œ íŠ¹ì„± ê³µí•™ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    df_copy = df.copy()
    
    # 1. ê°€ì¡± í¬ê¸° íŠ¹ì„± ìƒì„±
    df_copy['FamilySize'] = df_copy['SibSp'] + df_copy['Parch'] + 1
    
    # 2. í˜¼ì ì—¬í–‰ ì—¬ë¶€
    df_copy['IsAlone'] = (df_copy['FamilySize'] == 1).astype(int)
    
    # 3. ë‚˜ì´ ê·¸ë£¹ (ì´ë¯¸ ìƒì„±ë¨)
    
    # 4. ìš”ê¸ˆ êµ¬ê°„
    df_copy['FareGroup'] = pd.qcut(df_copy['Fare'], q=4, 
                                   labels=['ì €ê°€', 'ì¤‘ì €ê°€', 'ì¤‘ê³ ê°€', 'ê³ ê°€'])
    
    # 5. íƒ€ì´í‹€ ì¶”ì¶œ (ì‹¤ì œ ë°ì´í„°ì—ì„œëŠ” ì´ë¦„ì—ì„œ ì¶”ì¶œ)
    df_copy['Title'] = df_copy['Name'].str.extract(r' ([A-Za-z]+)\.')
    
    # 6. ìºë¹ˆ ìœ ë¬´
    df_copy['HasCabin'] = df_copy['Cabin'].notna().astype(int)
    
    print("=== ìƒˆë¡œ ìƒì„±ëœ íŠ¹ì„±ë“¤ ===")
    print(f"ê°€ì¡± í¬ê¸° ë¶„í¬:\n{df_copy['FamilySize'].value_counts()}")
    print(f"\ní˜¼ì ì—¬í–‰í•˜ëŠ” ìŠ¹ê° ë¹„ìœ¨: {df_copy['IsAlone'].mean():.2%}")
    print(f"\nìš”ê¸ˆ ê·¸ë£¹ ë¶„í¬:\n{df_copy['FareGroup'].value_counts()}")
    print(f"\nìºë¹ˆ ì •ë³´ê°€ ìˆëŠ” ìŠ¹ê° ë¹„ìœ¨: {df_copy['HasCabin'].mean():.2%}")
    
    return df_copy

# íŠ¹ì„± ê³µí•™ ì ìš©
df_titanic = feature_engineering_titanic(df_titanic)
```

**ğŸ”§ íŠ¹ì„± ê³µí•™ì´ ì¤‘ìš”í•œ ì´ìœ **
1. **ë„ë©”ì¸ ì§€ì‹ í™œìš©**: íƒ€ì´íƒ€ë‹‰ ì‚¬ê±´ì˜ ì—­ì‚¬ì  ë§¥ë½ì„ ë°˜ì˜
2. **ì •ë³´ ì¶”ì¶œ**: ê¸°ì¡´ íŠ¹ì„±ì—ì„œ ìˆ¨ê²¨ì§„ íŒ¨í„´ ë°œê²¬
3. **ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ**: ë” ì˜ë¯¸ ìˆëŠ” íŠ¹ì„±ìœ¼ë¡œ ì˜ˆì¸¡ë ¥ ì¦ê°€
4. **í•´ì„ ê°€ëŠ¥ì„±**: ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ì´í•´í•˜ê¸° ì‰¬ìš´ íŠ¹ì„±

### 2.4 ë°ì´í„° ì „ì²˜ë¦¬

```python
class TitanicPreprocessor:
    """íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.scaler = StandardScaler()
        self.label_encoders = {}
        
    def handle_missing_values(self, df):
        """ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        df_copy = df.copy()
        
        # ë‚˜ì´: ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´
        age_median = df_copy['Age'].median()
        df_copy['Age'].fillna(age_median, inplace=True)
        print(f"ë‚˜ì´ ê²°ì¸¡ì¹˜ë¥¼ ì¤‘ì•™ê°’ {age_median:.1f}ë¡œ ëŒ€ì²´í–ˆìŠµë‹ˆë‹¤.")
        
        # Embarked: ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´
        embarked_mode = df_copy['Embarked'].mode()[0]
        df_copy['Embarked'].fillna(embarked_mode, inplace=True)
        print(f"Embarked ê²°ì¸¡ì¹˜ë¥¼ ìµœë¹ˆê°’ '{embarked_mode}'ë¡œ ëŒ€ì²´í–ˆìŠµë‹ˆë‹¤.")
        
        # Fare: í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
        fare_mean = df_copy['Fare'].mean()
        df_copy['Fare'].fillna(fare_mean, inplace=True)
        
        return df_copy
    
    def encode_categorical_features(self, df):
        """ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ì¸ì½”ë”©í•©ë‹ˆë‹¤."""
        df_copy = df.copy()
        
        # ì›-í•« ì¸ì½”ë”©í•  ë³€ìˆ˜ë“¤
        categorical_cols = ['Sex', 'Embarked', 'Pclass']
        
        for col in categorical_cols:
            # ì›-í•« ì¸ì½”ë”©
            dummies = pd.get_dummies(df_copy[col], prefix=col, drop_first=True)
            df_copy = pd.concat([df_copy, dummies], axis=1)
            df_copy.drop(col, axis=1, inplace=True)
        
        # ìˆœì„œí˜• ë³€ìˆ˜ ì¸ì½”ë”©
        if 'FareGroup' in df_copy.columns:
            fare_group_map = {'ì €ê°€': 0, 'ì¤‘ì €ê°€': 1, 'ì¤‘ê³ ê°€': 2, 'ê³ ê°€': 3}
            df_copy['FareGroup'] = df_copy['FareGroup'].map(fare_group_map)
        
        return df_copy
    
    def select_features(self, df):
        """ëª¨ë¸ë§ì— ì‚¬ìš©í•  íŠ¹ì„±ì„ ì„ íƒí•©ë‹ˆë‹¤."""
        # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
        columns_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin', 
                          'AgeGroup', 'Title']
        
        df_copy = df.copy()
        for col in columns_to_drop:
            if col in df_copy.columns:
                df_copy.drop(col, axis=1, inplace=True)
        
        return df_copy
    
    def preprocess(self, df):
        """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print("=== ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ ===")
        
        # 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df = self.handle_missing_values(df)
        
        # 2. ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        df = self.encode_categorical_features(df)
        
        # 3. íŠ¹ì„± ì„ íƒ
        df = self.select_features(df)
        
        print(f"\nìµœì¢… íŠ¹ì„± ìˆ˜: {df.shape[1]}")
        print(f"ìµœì¢… íŠ¹ì„± ëª©ë¡: {list(df.columns)}")
        
        return df

# ì „ì²˜ë¦¬ ìˆ˜í–‰
preprocessor = TitanicPreprocessor()
df_processed = preprocessor.preprocess(df_titanic)
```

### 2.5 ëª¨ë¸ í•™ìŠµ ë° í‰ê°€

```python
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.model_selection import cross_val_score

def train_and_evaluate_models(df):
    """ì—¬ëŸ¬ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•©ë‹ˆë‹¤."""
    
    # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
    X = df.drop('Survived', axis=1)
    y = df['Survived']
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # ëª¨ë¸ ì •ì˜
    models = {
        'Logistic Regression': LogisticRegression(random_state=42),
        'Decision Tree': DecisionTreeClassifier(random_state=42),
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
        'SVM': SVC(probability=True, random_state=42)
    }
    
    # ê²°ê³¼ ì €ì¥
    results = {}
    
    print("=== ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ===")
    
    for name, model in models.items():
        print(f"\n{name} í•™ìŠµ ì¤‘...")
        
        # ëª¨ë¸ í•™ìŠµ
        if name in ['Logistic Regression', 'SVM']:
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_test_scaled)
            y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
        else:
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test)[:, 1]
        
        # í‰ê°€ ì§€í‘œ ê³„ì‚°
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        auc = roc_auc_score(y_test, y_pred_proba)
        
        # êµì°¨ ê²€ì¦
        if name in ['Logistic Regression', 'SVM']:
            cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)
        else:
            cv_scores = cross_val_score(model, X_train, y_train, cv=5)
        
        results[name] = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'auc': auc,
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'model': model
        }
        
        print(f"ì •í™•ë„: {accuracy:.4f}")
        print(f"ì •ë°€ë„: {precision:.4f}")
        print(f"ì¬í˜„ìœ¨: {recall:.4f}")
        print(f"F1 ì ìˆ˜: {f1:.4f}")
        print(f"AUC: {auc:.4f}")
        print(f"êµì°¨ ê²€ì¦ í‰ê· : {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")
    
    return results, X_train, X_test, y_train, y_test, scaler

# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
results, X_train, X_test, y_train, y_test, scaler = train_and_evaluate_models(df_processed)
```

**ğŸ“Š ì™œ ì—¬ëŸ¬ ëª¨ë¸ì„ ë¹„êµí•˜ë‚˜ìš”?**
1. **No Free Lunch ì •ë¦¬**: ëª¨ë“  ë¬¸ì œì— ìµœì ì¸ ë‹¨ì¼ ì•Œê³ ë¦¬ì¦˜ì€ ì—†ìŠµë‹ˆë‹¤
2. **ë‹¤ì–‘í•œ ê´€ì **: ê° ì•Œê³ ë¦¬ì¦˜ì€ ë°ì´í„°ë¥¼ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤
3. **ì•™ìƒë¸” ê°€ëŠ¥ì„±**: ì—¬ëŸ¬ ëª¨ë¸ì„ ì¡°í•©í•˜ë©´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤
4. **í•´ì„ ê°€ëŠ¥ì„± vs ì„±ëŠ¥**: ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

### 2.6 ëª¨ë¸ ìµœì í™”

```python
from sklearn.model_selection import GridSearchCV

def optimize_best_model(results, X_train, y_train, scaler):
    """ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ì„ íƒí•˜ê³  ìµœì í™”í•©ë‹ˆë‹¤."""
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ (F1 ì ìˆ˜ ê¸°ì¤€)
    best_model_name = max(results.items(), key=lambda x: x[1]['f1'])[0]
    print(f"ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")
    
    # Random Forest í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
    if best_model_name == 'Random Forest':
        param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [10, 20, None],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        }
        
        rf = RandomForestClassifier(random_state=42)
        
        grid_search = GridSearchCV(
            rf, param_grid, cv=5, 
            scoring='f1', n_jobs=-1, verbose=1
        )
        
        print("\ní•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì§„í–‰ ì¤‘...")
        grid_search.fit(X_train, y_train)
        
        print(f"\nìµœì  íŒŒë¼ë¯¸í„°: {grid_search.best_params_}")
        print(f"ìµœì  F1 ì ìˆ˜: {grid_search.best_score_:.4f}")
        
        return grid_search.best_estimator_
    
    return results[best_model_name]['model']

# ëª¨ë¸ ìµœì í™”
best_model = optimize_best_model(results, X_train, y_train, scaler)
```

### 2.7 íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„

```python
def analyze_feature_importance(model, feature_names):
    """íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤."""
    
    if hasattr(model, 'feature_importances_'):
        importances = model.feature_importances_
        
        # íŠ¹ì„± ì¤‘ìš”ë„ ì •ë ¬
        indices = np.argsort(importances)[::-1]
        
        # ì‹œê°í™”
        plt.figure(figsize=(10, 6))
        plt.title('íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„')
        plt.bar(range(len(importances)), importances[indices])
        plt.xticks(range(len(importances)), 
                  [feature_names[i] for i in indices], 
                  rotation=45, ha='right')
        plt.tight_layout()
        plt.show()
        
        # ìƒìœ„ 5ê°œ íŠ¹ì„± ì¶œë ¥
        print("\n=== ìƒìœ„ 5ê°œ ì¤‘ìš” íŠ¹ì„± ===")
        for i in range(min(5, len(importances))):
            print(f"{i+1}. {feature_names[indices[i]]}: {importances[indices[i]]:.4f}")
    
    else:
        print("ì´ ëª¨ë¸ì€ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
feature_names = X_train.columns.tolist()
analyze_feature_importance(best_model, feature_names)
```

**ğŸ¯ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ì˜ ì˜ì˜**
1. **ëª¨ë¸ í•´ì„**: ì–´ë–¤ íŠ¹ì„±ì´ ì˜ˆì¸¡ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì´í•´
2. **ë„ë©”ì¸ ê²€ì¦**: ë¶„ì„ ê²°ê³¼ê°€ ì‹¤ì œ ë„ë©”ì¸ ì§€ì‹ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
3. **íŠ¹ì„± ì„ íƒ**: ë¶ˆí•„ìš”í•œ íŠ¹ì„±ì„ ì œê±°í•˜ì—¬ ëª¨ë¸ ë‹¨ìˆœí™”
4. **ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸**: ì˜ì‚¬ê²°ì •ì— í™œìš©í•  ìˆ˜ ìˆëŠ” ì¸ì‚¬ì´íŠ¸ ë„ì¶œ

## 3. ì£¼íƒ ê°€ê²© ì˜ˆì¸¡ í”„ë¡œì íŠ¸

### 3.1 í”„ë¡œì íŠ¸ ì„¤ì •

```python
# ì£¼íƒ ê°€ê²© ì˜ˆì¸¡ í”„ë¡œì íŠ¸ ì •ì˜
house_project = ProjectDefinition("ì£¼íƒ ê°€ê²© ì˜ˆì¸¡")
house_project.business_goal = "ì£¼íƒ íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ íŒë§¤ ê°€ê²© ì˜ˆì¸¡"
house_project.ml_problem_type = "íšŒê·€ (Regression)"
house_project.evaluation_metric = "RMSE, MAE, RÂ²"
house_project.constraints = ["ë‹¤ì¤‘ê³µì„ ì„± ì²˜ë¦¬", "ì´ìƒì¹˜ ì œê±°"]
house_project.deliverables = ["ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸", "ì£¼ìš” ê°€ê²© ê²°ì • ìš”ì¸ ë¶„ì„"]

house_project.define_project()
```

### 3.2 ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬

```python
from sklearn.datasets import fetch_california_housing
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def load_and_prepare_housing_data():
    """ì£¼íƒ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    # California Housing ë°ì´í„°ì…‹ ì‚¬ìš©
    housing = fetch_california_housing()
    
    df = pd.DataFrame(housing.data, columns=housing.feature_names)
    df['Price'] = housing.target
    
    print("=== ë°ì´í„° ì •ë³´ ===")
    print(f"ë°ì´í„° í¬ê¸°: {df.shape}")
    print(f"\níŠ¹ì„± ì„¤ëª…:")
    print("- MedInc: ì¤‘ê°„ ì†Œë“")
    print("- HouseAge: ì£¼íƒ ì—°ë ¹")
    print("- AveRooms: í‰ê·  ë°© ìˆ˜")
    print("- AveBedrms: í‰ê·  ì¹¨ì‹¤ ìˆ˜")
    print("- Population: ì¸êµ¬")
    print("- AveOccup: í‰ê·  ê±°ì£¼ì ìˆ˜")
    print("- Latitude: ìœ„ë„")
    print("- Longitude: ê²½ë„")
    print("- Price: ì£¼íƒ ê°€ê²© (ë‹¨ìœ„: 10ë§Œ ë‹¬ëŸ¬)")
    
    return df

# ë°ì´í„° ë¡œë“œ
df_housing = load_and_prepare_housing_data()

# ê¸°ë³¸ í†µê³„ í™•ì¸
print("\n=== ê¸°ë³¸ í†µê³„ ===")
print(df_housing.describe())
```

### 3.3 íŠ¹ì„± ê³µí•™ ë° EDA

```python
def housing_feature_engineering(df):
    """ì£¼íƒ ë°ì´í„°ì— ëŒ€í•œ íŠ¹ì„± ê³µí•™ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    df_copy = df.copy()
    
    # 1. ë°©ë‹¹ ì¹¨ì‹¤ ë¹„ìœ¨
    df_copy['BedroomRatio'] = df_copy['AveBedrms'] / df_copy['AveRooms']
    
    # 2. ì¸êµ¬ ë°€ë„
    df_copy['PopulationDensity'] = df_copy['Population'] / df_copy['AveOccup']
    
    # 3. ì§€ì—­ êµ¬ë¶„ (ìœ„ë„ ê¸°ë°˜)
    df_copy['Region'] = pd.cut(df_copy['Latitude'], 
                               bins=[32, 34, 36, 38, 40, 42],
                               labels=['ë‚¨ë¶€', 'ì¤‘ë‚¨ë¶€', 'ì¤‘ë¶€', 'ì¤‘ë¶ë¶€', 'ë¶ë¶€'])
    
    # 4. ì£¼íƒ ì—°ë ¹ ê·¸ë£¹
    df_copy['AgeGroup'] = pd.cut(df_copy['HouseAge'],
                                 bins=[0, 10, 20, 30, 40, 60],
                                 labels=['ì‹ ì¶•', '10ë…„ë¯¸ë§Œ', '20ë…„ë¯¸ë§Œ', '30ë…„ë¯¸ë§Œ', 'ë…¸í›„'])
    
    # ì‹œê°í™”
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # ê°€ê²© ë¶„í¬
    df_copy['Price'].hist(bins=50, ax=axes[0, 0], color='#3498db')
    axes[0, 0].set_title('ì£¼íƒ ê°€ê²© ë¶„í¬')
    axes[0, 0].set_xlabel('ê°€ê²© (10ë§Œ ë‹¬ëŸ¬)')
    
    # ì†Œë“ vs ê°€ê²©
    axes[0, 1].scatter(df_copy['MedInc'], df_copy['Price'], 
                      alpha=0.5, color='#e74c3c')
    axes[0, 1].set_title('ì¤‘ê°„ ì†Œë“ vs ì£¼íƒ ê°€ê²©')
    axes[0, 1].set_xlabel('ì¤‘ê°„ ì†Œë“')
    axes[0, 1].set_ylabel('ì£¼íƒ ê°€ê²©')
    
    # ì§€ì—­ë³„ í‰ê·  ê°€ê²©
    region_prices = df_copy.groupby('Region')['Price'].mean()
    axes[1, 0].bar(region_prices.index, region_prices.values, color='#2ecc71')
    axes[1, 0].set_title('ì§€ì—­ë³„ í‰ê·  ì£¼íƒ ê°€ê²©')
    axes[1, 0].set_xlabel('ì§€ì—­')
    axes[1, 0].set_ylabel('í‰ê·  ê°€ê²©')
    
    # ì£¼íƒ ì—°ë ¹ë³„ í‰ê·  ê°€ê²©
    age_prices = df_copy.groupby('AgeGroup')['Price'].mean()
    axes[1, 1].bar(age_prices.index, age_prices.values, color='#f39c12')
    axes[1, 1].set_title('ì£¼íƒ ì—°ë ¹ë³„ í‰ê·  ê°€ê²©')
    axes[1, 1].set_xlabel('ì—°ë ¹ ê·¸ë£¹')
    axes[1, 1].set_ylabel('í‰ê·  ê°€ê²©')
    
    plt.tight_layout()
    plt.show()
    
    return df_copy

# íŠ¹ì„± ê³µí•™ ì ìš©
df_housing = housing_feature_engineering(df_housing)
```
