# 4ì¥ Part 3: íŠ¹ì„± ê³µí•™(Feature Engineering)
## ë°ì´í„°ì—ì„œ ìˆ¨ê²¨ì§„ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°œêµ´í•˜ëŠ” ì°½ì˜ì  ê¸°ë²•

---

## ğŸ“š í•™ìŠµ ëª©í‘œ

ì´ë²ˆ Partì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ í•™ìŠµí•©ë‹ˆë‹¤:

âœ… **íŠ¹ì„± ê³µí•™ì˜ ê°œë…ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì—ì„œì˜ ì¤‘ìš”ì„±ì„ ì´í•´í•  ìˆ˜ ìˆë‹¤**
âœ… **ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ì˜ë¯¸ìˆëŠ” íŒŒìƒ ë³€ìˆ˜ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤**  
âœ… **ìˆ˜í•™ì  ì¡°í•©ìœ¼ë¡œ ìƒˆë¡œìš´ íŠ¹ì„±ì„ ì°½ì¡°í•˜ê³  ê²€ì¦í•  ìˆ˜ ìˆë‹¤**
âœ… **ì‹œê°„ ê¸°ë°˜ íŠ¹ì„±ì„ ì¶”ì¶œí•˜ì—¬ ì‹œê³„ì—´ íŒ¨í„´ì„ í™œìš©í•  ìˆ˜ ìˆë‹¤**
âœ… **íŠ¹ì„± ì„ íƒ ê¸°ë²•ìœ¼ë¡œ ìµœì ì˜ íŠ¹ì„± ì¡°í•©ì„ ì°¾ì„ ìˆ˜ ìˆë‹¤**

---

## ğŸ¯ ì´ë²ˆ Part ë¯¸ë¦¬ë³´ê¸°

**íŠ¹ì„± ê³µí•™(Feature Engineering)**ì€ ë°ì´í„° ê³¼í•™ì˜ ì˜ˆìˆ ì´ì ê³¼í•™ì…ë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°ë¥¼ **ëª¨ë¸ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœ**ë¡œ ë³€í™˜í•˜ê³ , **ìˆ¨ê²¨ì§„ íŒ¨í„´**ì„ ë“œëŸ¬ë‚´ë©°, **ì˜ˆì¸¡ë ¥ì„ ê·¹ëŒ€í™”**í•˜ëŠ” ì°½ì˜ì ì¸ ê³¼ì •ì…ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, ì£¼íƒ ë°ì´í„°ì—ì„œ ë‹¨ìˆœíˆ 'ì¹¨ì‹¤ ê°œìˆ˜'ì™€ 'ì´ ë©´ì 'ì„ ë”°ë¡œ ë³´ëŠ” ê²ƒë³´ë‹¤, **'ë°© í•˜ë‚˜ë‹¹ í‰ê·  ë©´ì '**ì´ë¼ëŠ” ìƒˆë¡œìš´ íŠ¹ì„±ì„ ë§Œë“¤ë©´ ì£¼íƒì˜ ê³µê°„ í™œìš©ë„ë¥¼ ë” ì˜ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ 'ê±´ì„¤ ì—°ë„'ì™€ 'íŒë§¤ ì—°ë„'ë¡œë¶€í„° **'ì£¼íƒ ì—°ë ¹'**ì„ ê³„ì‚°í•˜ë©´ ë…¸í›„ë„ê°€ ê°€ê²©ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë” ì§ì ‘ì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ë²ˆ Partì—ì„œëŠ” House Prices ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ **ë¶€ë™ì‚° ë„ë©”ì¸ ì „ë¬¸ ì§€ì‹**ì„ ë°”íƒ•ìœ¼ë¡œ í•œ íŠ¹ì„± ê³µí•™ë¶€í„°, **í†µê³„ì  ë°©ë²•**ì„ í™œìš©í•œ íŠ¹ì„± ì„ íƒê¹Œì§€ ì „ ê³¼ì •ì„ ì²´ê³„ì ìœ¼ë¡œ ë°°ì›Œë³´ê² ìŠµë‹ˆë‹¤. 

íŠ¹íˆ **"ì™œ ì´ íŠ¹ì„±ì´ ìœ ìš©í•œê°€?"**ì— ëŒ€í•œ ë¹„ì¦ˆë‹ˆìŠ¤ì  í•´ì„ê³¼ **"ì–´ë–»ê²Œ ê²€ì¦í•  ê²ƒì¸ê°€?"**ì— ëŒ€í•œ ê³¼í•™ì  ì ‘ê·¼ì„ ê· í˜•ìˆê²Œ ë‹¤ë£¨ê² ìŠµë‹ˆë‹¤.

> **ğŸ’¡ Part 3ì˜ í•µì‹¬ í¬ì¸íŠ¸**  
> "ì¢‹ì€ íŠ¹ì„± ê³µí•™ì€ ëª¨ë¸ì—ê²Œ 'ë” ë‚˜ì€ ëˆˆ'ì„ ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤. ë°ì´í„°ì˜ ë³¸ì§ˆì„ ê¿°ëš«ì–´ ë³´ëŠ” ìƒˆë¡œìš´ ê´€ì ì„ ì œê³µí•©ë‹ˆë‹¤."

---

## ğŸ“– 4.3.1 íŠ¹ì„± ê³µí•™ì˜ ê°œë…ê³¼ ì¤‘ìš”ì„±

### íŠ¹ì„± ê³µí•™ì´ë€?

**íŠ¹ì„± ê³µí•™(Feature Engineering)**ì€ ì›ë³¸ ë°ì´í„°ë¡œë¶€í„° ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ íŠ¹ì„±(ë³€ìˆ˜)ì„ ìƒì„±, ë³€í™˜, ì„ íƒí•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

> **ğŸ” ì£¼ìš” ìš©ì–´ í•´ì„¤**
> - **íŒŒìƒ ë³€ìˆ˜(Derived Variable)**: ê¸°ì¡´ ë³€ìˆ˜ë“¤ë¡œë¶€í„° ê³„ì‚°ëœ ìƒˆë¡œìš´ ë³€ìˆ˜
> - **íŠ¹ì„± ì¡°í•©(Feature Combination)**: ì—¬ëŸ¬ íŠ¹ì„±ì„ ìˆ˜í•™ì ìœ¼ë¡œ ê²°í•©í•˜ì—¬ ë§Œë“  ìƒˆë¡œìš´ íŠ¹ì„±
> - **ìƒí˜¸ì‘ìš© íŠ¹ì„±(Interaction Feature)**: ë‘ ë³€ìˆ˜ì˜ ê³±ì…ˆ ë“±ìœ¼ë¡œ ë§Œë“  ìƒí˜¸ì‘ìš© íš¨ê³¼ íŠ¹ì„±
> - **ë„ë©”ì¸ ì§€ì‹(Domain Knowledge)**: í•´ë‹¹ ë¶„ì•¼ì˜ ì „ë¬¸ì  ì´í•´ì™€ ê²½í—˜

### íŠ¹ì„± ê³µí•™ì˜ ì¤‘ìš”ì„±

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

# íŠ¹ì„± ê³µí•™ì˜ ì¤‘ìš”ì„± ì‹œì—°
def demonstrate_feature_engineering_importance(df):
    """
    íŠ¹ì„± ê³µí•™ì´ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‹œì—°í•˜ëŠ” í•¨ìˆ˜
    """
    print("ğŸ¯ íŠ¹ì„± ê³µí•™ì˜ ì¤‘ìš”ì„± ì‹œì—°:")
    
    if 'SalePrice' not in df.columns:
        print("âš ï¸ SalePrice ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê¸°ë³¸ íŠ¹ì„±ë“¤ ì„ íƒ
    basic_features = ['GrLivArea', 'BedroomAbvGr', 'FullBath', 'YearBuilt']
    available_basic = [col for col in basic_features if col in df.columns]
    
    if len(available_basic) < 3:
        print("âš ï¸ ì¶©ë¶„í•œ ê¸°ë³¸ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # íƒ€ê²Ÿ ë³€ìˆ˜
    y = df['SalePrice']
    
    # 1ë‹¨ê³„: ê¸°ë³¸ íŠ¹ì„±ë§Œ ì‚¬ìš©
    X_basic = df[available_basic].copy()
    
    # ê²°ì¸¡ì¹˜ ê°„ë‹¨ ì²˜ë¦¬
    X_basic = X_basic.fillna(X_basic.median())
    
    # 2ë‹¨ê³„: íŠ¹ì„± ê³µí•™ ì ìš©
    X_engineered = X_basic.copy()
    
    # ìƒˆë¡œìš´ íŠ¹ì„±ë“¤ ìƒì„±
    if 'GrLivArea' in X_engineered.columns and 'BedroomAbvGr' in X_engineered.columns:
        # ì¹¨ì‹¤ë‹¹ í‰ê·  ë©´ì 
        X_engineered['AreaPerBedroom'] = X_engineered['GrLivArea'] / (X_engineered['BedroomAbvGr'] + 1)
    
    if 'YearBuilt' in X_engineered.columns:
        # ì£¼íƒ ì—°ë ¹ (2023ë…„ ê¸°ì¤€)
        X_engineered['HouseAge'] = 2023 - X_engineered['YearBuilt']
        
        # ê±´ì¶• ì‹œëŒ€ êµ¬ë¶„
        X_engineered['Era_Modern'] = (X_engineered['YearBuilt'] >= 1980).astype(int)
        X_engineered['Era_Contemporary'] = (X_engineered['YearBuilt'] >= 2000).astype(int)
    
    if 'FullBath' in X_engineered.columns and 'BedroomAbvGr' in X_engineered.columns:
        # ì¹¨ì‹¤ ëŒ€ë¹„ í™”ì¥ì‹¤ ë¹„ìœ¨
        X_engineered['BathBedRatio'] = X_engineered['FullBath'] / (X_engineered['BedroomAbvGr'] + 1)
    
    if 'GrLivArea' in X_engineered.columns:
        # ë©´ì  êµ¬ê°„ ë¶„ë¥˜
        area_quartiles = X_engineered['GrLivArea'].quantile([0.25, 0.5, 0.75])
        X_engineered['AreaCategory_Small'] = (X_engineered['GrLivArea'] <= area_quartiles[0.25]).astype(int)
        X_engineered['AreaCategory_Large'] = (X_engineered['GrLivArea'] >= area_quartiles[0.75]).astype(int)
    
    print(f"\nğŸ“Š íŠ¹ì„± ê°œìˆ˜ ë¹„êµ:")
    print(f"   ê¸°ë³¸ íŠ¹ì„±: {X_basic.shape[1]}ê°œ")
    print(f"   íŠ¹ì„± ê³µí•™ í›„: {X_engineered.shape[1]}ê°œ (+{X_engineered.shape[1] - X_basic.shape[1]}ê°œ ì¶”ê°€)")
    
    # ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
    models = {
        'LinearRegression': LinearRegression(),
        'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42)
    }
    
    results = {}
    
    for model_name, model in models.items():
        print(f"\nğŸ¤– {model_name} ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ:")
        
        # ê¸°ë³¸ íŠ¹ì„± ì„±ëŠ¥
        X_train_basic, X_test_basic, y_train, y_test = train_test_split(
            X_basic, y, test_size=0.2, random_state=42
        )
        
        model.fit(X_train_basic, y_train)
        y_pred_basic = model.predict(X_test_basic)
        rmse_basic = np.sqrt(mean_squared_error(y_test, y_pred_basic))
        r2_basic = r2_score(y_test, y_pred_basic)
        
        # íŠ¹ì„± ê³µí•™ í›„ ì„±ëŠ¥
        X_train_eng, X_test_eng, _, _ = train_test_split(
            X_engineered, y, test_size=0.2, random_state=42
        )
        
        model.fit(X_train_eng, y_train)
        y_pred_eng = model.predict(X_test_eng)
        rmse_eng = np.sqrt(mean_squared_error(y_test, y_pred_eng))
        r2_eng = r2_score(y_test, y_pred_eng)
        
        # ì„±ëŠ¥ ê°œì„  ê³„ì‚°
        rmse_improvement = ((rmse_basic - rmse_eng) / rmse_basic) * 100
        r2_improvement = ((r2_eng - r2_basic) / r2_basic) * 100
        
        results[model_name] = {
            'rmse_basic': rmse_basic,
            'rmse_engineered': rmse_eng,
            'r2_basic': r2_basic,
            'r2_engineered': r2_eng,
            'rmse_improvement': rmse_improvement,
            'r2_improvement': r2_improvement
        }
        
        print(f"   ê¸°ë³¸ íŠ¹ì„± - RMSE: ${rmse_basic:,.0f}, RÂ²: {r2_basic:.3f}")
        print(f"   íŠ¹ì„± ê³µí•™ í›„ - RMSE: ${rmse_eng:,.0f}, RÂ²: {r2_eng:.3f}")
        print(f"   ğŸ“ˆ ê°œì„  íš¨ê³¼: RMSE {rmse_improvement:.1f}% ê°ì†Œ, RÂ² {r2_improvement:.1f}% ì¦ê°€")
    
    # ì‹œê°í™”
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    # RMSE ë¹„êµ
    model_names = list(results.keys())
    rmse_basic_values = [results[name]['rmse_basic'] for name in model_names]
    rmse_eng_values = [results[name]['rmse_engineered'] for name in model_names]
    
    x = np.arange(len(model_names))
    width = 0.35
    
    axes[0].bar(x - width/2, rmse_basic_values, width, label='ê¸°ë³¸ íŠ¹ì„±', alpha=0.7, color='skyblue')
    axes[0].bar(x + width/2, rmse_eng_values, width, label='íŠ¹ì„± ê³µí•™ í›„', alpha=0.7, color='lightcoral')
    axes[0].set_title('ëª¨ë¸ë³„ RMSE ë¹„êµ\n(ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)')
    axes[0].set_ylabel('RMSE ($)')
    axes[0].set_xticks(x)
    axes[0].set_xticklabels(model_names)
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # RÂ² ë¹„êµ
    r2_basic_values = [results[name]['r2_basic'] for name in model_names]
    r2_eng_values = [results[name]['r2_engineered'] for name in model_names]
    
    axes[1].bar(x - width/2, r2_basic_values, width, label='ê¸°ë³¸ íŠ¹ì„±', alpha=0.7, color='skyblue')
    axes[1].bar(x + width/2, r2_eng_values, width, label='íŠ¹ì„± ê³µí•™ í›„', alpha=0.7, color='lightcoral')
    axes[1].set_title('ëª¨ë¸ë³„ RÂ² ë¹„êµ\n(ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)')
    axes[1].set_ylabel('RÂ² Score')
    axes[1].set_xticks(x)
    axes[1].set_xticklabels(model_names)
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    axes[1].set_ylim(0, 1)
    
    plt.tight_layout()
    plt.show()
    
    print(f"\nâœ… íŠ¹ì„± ê³µí•™ì˜ íš¨ê³¼:")
    print(f"   ğŸ’¡ ë‹¨ìˆœíˆ ìƒˆë¡œìš´ íŠ¹ì„±ì„ ì¶”ê°€í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œë„ ëª¨ë¸ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤!")
    print(f"   ğŸ’¡ ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•œ ì˜ë¯¸ìˆëŠ” íŠ¹ì„±ì´ í•µì‹¬ì…ë‹ˆë‹¤!")
    
    return X_engineered, results

# House Prices ë°ì´í„° ë¡œë“œ ë° íŠ¹ì„± ê³µí•™ ì¤‘ìš”ì„± ì‹œì—°
try:
    train_data = pd.read_csv('datasets/house_prices/train.csv')
    print("âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ!")
    
    # íŠ¹ì„± ê³µí•™ ì¤‘ìš”ì„± ì‹œì—°
    engineered_features, performance_results = demonstrate_feature_engineering_importance(train_data)
    
except FileNotFoundError:
    print("âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ğŸ’¡ House Prices Datasetì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ datasets/house_prices/ í´ë”ì— ì €ì¥í•˜ì„¸ìš”.")
```

**ğŸ” ì½”ë“œ í•´ì„¤:**
- ê¸°ë³¸ íŠ¹ì„±ê³¼ íŠ¹ì„± ê³µí•™ í›„ ì„±ëŠ¥ì„ ì§ì ‘ ë¹„êµí•˜ì—¬ íš¨ê³¼ ì…ì¦
- `train_test_split()`: ë™ì¼í•œ random_stateë¡œ ê³µì •í•œ ë¹„êµ ë³´ì¥
- ìƒˆë¡œìš´ íŠ¹ì„±ë“¤ì€ ëª¨ë‘ **ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ì˜ë¯¸ìˆëŠ”** ì¡°í•©ë“¤

> **ğŸ“Š ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸:**  
> "Create a compelling before-and-after comparison visualization showing the impact of feature engineering on machine learning model performance. Include: 1) A side-by-side bar chart comparing RMSE values for LinearRegression and RandomForest models using basic features vs engineered features, 2) A similar comparison for RÂ² scores, 3) Visual indicators showing percentage improvements, 4) A small table showing the number of features before and after engineering. Use professional styling with clear legends and improvement indicators (green arrows pointing up for RÂ², down for RMSE)."

---

## ğŸ“– 4.3.2 ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ íŠ¹ì„± ìƒì„±

### ë¶€ë™ì‚° ë„ë©”ì¸ ì „ë¬¸ ì§€ì‹ í™œìš©

ë¶€ë™ì‚° ì‹œì¥ì— ëŒ€í•œ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì˜ë¯¸ìˆëŠ” íŒŒìƒ ë³€ìˆ˜**ë“¤ì„ ìƒì„±í•´ë³´ê² ìŠµë‹ˆë‹¤.

```python
# ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ íŠ¹ì„± ìƒì„± í•¨ìˆ˜
def create_domain_specific_features(df):
    """
    ë¶€ë™ì‚° ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•œ íŠ¹ì„± ìƒì„± í•¨ìˆ˜
    """
    print("ğŸ  ë¶€ë™ì‚° ë„ë©”ì¸ íŠ¹ì„± ìƒì„±:")
    
    # ì›ë³¸ ë°ì´í„° ë³µì‚¬
    df_enhanced = df.copy()
    new_features = []
    
    print(f"\n1ï¸âƒ£ ë©´ì  ê´€ë ¨ íŠ¹ì„±:")
    
    # ì´ ë©´ì  ê³„ì‚°
    area_features = ['TotalBsmtSF', '1stFlrSF', '2ndFlrSF']
    available_area_features = [col for col in area_features if col in df.columns]
    
    if len(available_area_features) >= 2:
        df_enhanced['TotalLivingArea'] = df[available_area_features].sum(axis=1)
        new_features.append('TotalLivingArea')
        print(f"   âœ… TotalLivingArea: ì „ì²´ ê±°ì£¼ ë©´ì ")
    
    # ë©´ì  íš¨ìœ¨ì„±
    if 'GrLivArea' in df.columns and 'LotArea' in df.columns:
        df_enhanced['LotAreaRatio'] = df['GrLivArea'] / df['LotArea']
        new_features.append('LotAreaRatio')
        print(f"   âœ… LotAreaRatio: ëŒ€ì§€ ëŒ€ë¹„ ê±´ë¬¼ ë©´ì  ë¹„ìœ¨ (ê³µê°„ í™œìš©ë„)")
    
    # ë°© í¬ê¸° íš¨ìœ¨ì„±
    if 'GrLivArea' in df.columns and 'TotRmsAbvGrd' in df.columns:
        df_enhanced['AvgRoomSize'] = df['GrLivArea'] / (df['TotRmsAbvGrd'] + 1)
        new_features.append('AvgRoomSize')
        print(f"   âœ… AvgRoomSize: ë°© í•˜ë‚˜ë‹¹ í‰ê·  ë©´ì ")
    
    print(f"\n2ï¸âƒ£ ì‹œê°„ ê´€ë ¨ íŠ¹ì„±:")
    
    # ì£¼íƒ ì—°ë ¹
    if 'YearBuilt' in df.columns:
        current_year = 2023  # ë¶„ì„ ê¸°ì¤€ ì—°ë„
        df_enhanced['HouseAge'] = current_year - df['YearBuilt']
        new_features.append('HouseAge')
        print(f"   âœ… HouseAge: ì£¼íƒ ì—°ë ¹ ({current_year}ë…„ ê¸°ì¤€)")
        
        # ë¦¬ëª¨ë¸ë§ ì •ë³´
        if 'YearRemodAdd' in df.columns:
            df_enhanced['YearsSinceRemodel'] = current_year - df['YearRemodAdd']
            df_enhanced['IsRemodeled'] = (df['YearRemodAdd'] != df['YearBuilt']).astype(int)
            df_enhanced['RecentRemodel'] = (df_enhanced['YearsSinceRemodel'] <= 10).astype(int)
            
            new_features.extend(['YearsSinceRemodel', 'IsRemodeled', 'RecentRemodel'])
            print(f"   âœ… YearsSinceRemodel: ë¦¬ëª¨ë¸ë§ í›„ ê²½ê³¼ ì—°ìˆ˜")
            print(f"   âœ… IsRemodeled: ë¦¬ëª¨ë¸ë§ ì—¬ë¶€ (0/1)")
            print(f"   âœ… RecentRemodel: ìµœê·¼ 10ë…„ ë‚´ ë¦¬ëª¨ë¸ë§ ì—¬ë¶€")
    
    # íŒë§¤ ì‹œê¸° íŠ¹ì„±
    if 'YrSold' in df.columns and 'MoSold' in df.columns:
        # ê³„ì ˆì„±
        df_enhanced['SaleSeasonSpring'] = df['MoSold'].isin([3, 4, 5]).astype(int)
        df_enhanced['SaleSeasonSummer'] = df['MoSold'].isin([6, 7, 8]).astype(int)
        df_enhanced['SaleSeasonFall'] = df['MoSold'].isin([9, 10, 11]).astype(int)
        df_enhanced['SaleSeasonWinter'] = df['MoSold'].isin([12, 1, 2]).astype(int)
        
        new_features.extend(['SaleSeasonSpring', 'SaleSeasonSummer', 'SaleSeasonFall', 'SaleSeasonWinter'])
        print(f"   âœ… SaleSeason*: íŒë§¤ ê³„ì ˆ ë”ë¯¸ ë³€ìˆ˜ (ë¶€ë™ì‚° ê³„ì ˆì„± ë°˜ì˜)")
    
    print(f"\n3ï¸âƒ£ í’ˆì§ˆ ê´€ë ¨ íŠ¹ì„±:")
    
    # í’ˆì§ˆ ì ìˆ˜ í†µí•©
    quality_features = ['OverallQual', 'OverallCond']
    if all(col in df.columns for col in quality_features):
        df_enhanced['QualityScore'] = df['OverallQual'] * df['OverallCond']
        df_enhanced['AvgQuality'] = df[quality_features].mean(axis=1)
        
        new_features.extend(['QualityScore', 'AvgQuality'])
        print(f"   âœ… QualityScore: í’ˆì§ˆ Ã— ìƒíƒœ ë³µí•© ì ìˆ˜")
        print(f"   âœ… AvgQuality: ì „ë°˜ì  í’ˆì§ˆ í‰ê· ")
    
    # ê³ ê¸‰ ì£¼íƒ ì—¬ë¶€
    if 'OverallQual' in df.columns:
        df_enhanced['IsLuxury'] = (df['OverallQual'] >= 8).astype(int)
        new_features.append('IsLuxury')
        print(f"   âœ… IsLuxury: ê³ ê¸‰ ì£¼íƒ ì—¬ë¶€ (í’ˆì§ˆ 8ì  ì´ìƒ)")
    
    print(f"\n4ï¸âƒ£ í¸ì˜ì‹œì„¤ ê´€ë ¨ íŠ¹ì„±:")
    
    # í™”ì¥ì‹¤ ì´ ê°œìˆ˜
    bathroom_features = ['FullBath', 'HalfBath']
    available_bathroom = [col for col in bathroom_features if col in df.columns]
    
    if len(available_bathroom) >= 2:
        df_enhanced['TotalBathrooms'] = df['FullBath'] + 0.5 * df['HalfBath']
        new_features.append('TotalBathrooms')
        print(f"   âœ… TotalBathrooms: ì´ í™”ì¥ì‹¤ ê°œìˆ˜ (í•˜í”„ë°°ìŠ¤ 0.5ê°œë¡œ ê³„ì‚°)")
    
    # ì§€í•˜ì‹¤ ì™„ì„±ë„
    if 'BsmtFinSF1' in df.columns and 'TotalBsmtSF' in df.columns:
        df_enhanced['BsmtFinishedRatio'] = df['BsmtFinSF1'] / (df['TotalBsmtSF'] + 1)
        new_features.append('BsmtFinishedRatio')
        print(f"   âœ… BsmtFinishedRatio: ì§€í•˜ì‹¤ ì™„ì„± ë¹„ìœ¨")
    
    # ì°¨ê³  ìˆ˜ìš© ëŠ¥ë ¥
    if 'GarageCars' in df.columns and 'GarageArea' in df.columns:
        df_enhanced['AvgGarageSize'] = df['GarageArea'] / (df['GarageCars'] + 1)
        new_features.append('AvgGarageSize')
        print(f"   âœ… AvgGarageSize: ì°¨ í•œ ëŒ€ë‹¹ í‰ê·  ì°¨ê³  ë©´ì ")
    
    print(f"\n5ï¸âƒ£ ìƒí™œ í¸ì˜ì„± íŠ¹ì„±:")
    
    # ì¹¨ì‹¤ ëŒ€ë¹„ í™”ì¥ì‹¤ ë¹„ìœ¨
    if 'TotalBathrooms' in df_enhanced.columns and 'BedroomAbvGr' in df.columns:
        df_enhanced['BathPerBedroom'] = df_enhanced['TotalBathrooms'] / (df['BedroomAbvGr'] + 1)
        new_features.append('BathPerBedroom')
        print(f"   âœ… BathPerBedroom: ì¹¨ì‹¤ ëŒ€ë¹„ í™”ì¥ì‹¤ ë¹„ìœ¨ (ìƒí™œ í¸ì˜ì„±)")
    
    # ë²½ë‚œë¡œ í”„ë¦¬ë¯¸ì—„
    if 'Fireplaces' in df.columns:
        df_enhanced['HasFireplace'] = (df['Fireplaces'] > 0).astype(int)
        new_features.append('HasFireplace')
        print(f"   âœ… HasFireplace: ë²½ë‚œë¡œ ë³´ìœ  ì—¬ë¶€")
    
    # ë‹¤ì¸µ ì£¼íƒ ì—¬ë¶€
    if '2ndFlrSF' in df.columns:
        df_enhanced['IsMultiStory'] = (df['2ndFlrSF'] > 0).astype(int)
        new_features.append('IsMultiStory')
        print(f"   âœ… IsMultiStory: ë‹¤ì¸µ ì£¼íƒ ì—¬ë¶€")
    
    print(f"\nğŸ“Š ë„ë©”ì¸ íŠ¹ì„± ìƒì„± ì™„ë£Œ:")
    print(f"   ì›ë³¸ íŠ¹ì„± ìˆ˜: {df.shape[1]}ê°œ")
    print(f"   ìƒì„±ëœ ìƒˆ íŠ¹ì„±: {len(new_features)}ê°œ")
    print(f"   ì´ íŠ¹ì„± ìˆ˜: {df_enhanced.shape[1]}ê°œ")
    
    # ìƒˆë¡œìš´ íŠ¹ì„±ë“¤ì˜ ê¸°ë³¸ í†µê³„
    print(f"\nğŸ“ˆ ìƒˆë¡œìš´ íŠ¹ì„±ë“¤ì˜ í†µê³„:")
    for feature in new_features[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
        if feature in df_enhanced.columns:
            mean_val = df_enhanced[feature].mean()
            std_val = df_enhanced[feature].std()
            print(f"   {feature}: í‰ê·  {mean_val:.2f}, í‘œì¤€í¸ì°¨ {std_val:.2f}")
    
    return df_enhanced, new_features

# ë„ë©”ì¸ íŠ¹ì„± ìƒì„± ì‹¤í–‰
enhanced_data, domain_features = create_domain_specific_features(train_data)
```

**ğŸ” ì½”ë“œ í•´ì„¤:**
- **ë©´ì  íš¨ìœ¨ì„±**: ëŒ€ì§€ í™œìš©ë„, ë°© í¬ê¸° ë“± ê³µê°„ íš¨ìœ¨ì„± ì¸¡ì •
- **ì‹œê°„ ê´€ë ¨**: ë…¸í›„ë„, ë¦¬ëª¨ë¸ë§, ê³„ì ˆì„± ë“± ì‹œê°„ì˜ ì˜í–¥ ë°˜ì˜
- **í’ˆì§ˆ í†µí•©**: ì—¬ëŸ¬ í’ˆì§ˆ ì§€í‘œë¥¼ ì¢…í•©í•œ ë³µí•© ì ìˆ˜
- **í¸ì˜ì‹œì„¤**: ì‹¤ì œ ê±°ì£¼ì ê´€ì ì—ì„œì˜ ìƒí™œ í¸ì˜ì„±

### íŠ¹ì„±ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ì  í•´ì„

```python
# ë„ë©”ì¸ íŠ¹ì„±ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ë¶„ì„
def analyze_feature_business_value(df, new_features, target_col='SalePrice'):
    """
    ìƒˆë¡œ ìƒì„±ëœ íŠ¹ì„±ë“¤ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ì  ê°€ì¹˜ ë¶„ì„
    """
    print("ğŸ’¼ ë„ë©”ì¸ íŠ¹ì„±ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ë¶„ì„:")
    
    if target_col not in df.columns:
        print(f"âš ï¸ íƒ€ê²Ÿ ë³€ìˆ˜ {target_col}ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # íŠ¹ì„±ë³„ ìƒê´€ê´€ê³„ ë° ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„
    correlations = {}
    business_interpretations = {
        'TotalLivingArea': 'ì „ì²´ ê±°ì£¼ ë©´ì ì´ í´ìˆ˜ë¡ ë†’ì€ ê°€ê²© - ë©´ì ì€ ê°€ì¥ ê¸°ë³¸ì ì¸ ê°€ì¹˜ ìš”ì†Œ',
        'LotAreaRatio': 'ëŒ€ì§€ ëŒ€ë¹„ ê±´ë¬¼ ë¹„ìœ¨ì´ ë†’ì„ìˆ˜ë¡ ê³µê°„ í™œìš©ë„ê°€ ì¢‹ì•„ ê°€ê²© ìƒìŠ¹',
        'AvgRoomSize': 'ë°© í•˜ë‚˜ë‹¹ ë©´ì ì´ í´ìˆ˜ë¡ ì¾Œì í•¨ê³¼ ì—¬ìœ ë¡œì›€ìœ¼ë¡œ í”„ë¦¬ë¯¸ì—„',
        'HouseAge': 'ì£¼íƒì´ ìƒˆë¡œìš¸ìˆ˜ë¡ ë†’ì€ ê°€ê²© - ì‹œì„¤ ë…¸í›„í™”ì™€ ìœ í–‰ ë°˜ì˜',
        'IsRemodeled': 'ë¦¬ëª¨ë¸ë§ëœ ì£¼íƒì€ í˜„ëŒ€ì  ì‹œì„¤ë¡œ ì¸í•œ ê°€ê²© í”„ë¦¬ë¯¸ì—„',
        'RecentRemodel': 'ìµœê·¼ ë¦¬ëª¨ë¸ë§ì€ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ìƒíƒœë¡œ ë†’ì€ ê°€ì¹˜',
        'QualityScore': 'í’ˆì§ˆê³¼ ìƒíƒœì˜ ê³±ì€ ì „ë°˜ì  ì£¼íƒ ë“±ê¸‰ì„ ì¢…í•©ì ìœ¼ë¡œ ë°˜ì˜',
        'IsLuxury': 'ê³ ê¸‰ ì£¼íƒì€ ë³„ë„ ì‹œì¥ì„ í˜•ì„±í•˜ì—¬ í”„ë¦¬ë¯¸ì—„ ê°€ê²©ëŒ€',
        'TotalBathrooms': 'í™”ì¥ì‹¤ ê°œìˆ˜ëŠ” ê°€ì¡± êµ¬ì„±ì› ìˆ˜ìš©ë ¥ê³¼ í¸ì˜ì„± ì˜ë¯¸',
        'BsmtFinishedRatio': 'ì§€í•˜ì‹¤ ì™„ì„±ë„ëŠ” í™œìš© ê°€ëŠ¥í•œ ì¶”ê°€ ê³µê°„ì˜ ê°€ì¹˜',
        'BathPerBedroom': 'ì¹¨ì‹¤ ëŒ€ë¹„ í™”ì¥ì‹¤ ë¹„ìœ¨ì€ ìƒí™œ í¸ì˜ì„±ì˜ í•µì‹¬ ì§€í‘œ',
        'HasFireplace': 'ë²½ë‚œë¡œëŠ” ê°ì„±ì  ê°€ì¹˜ì™€ ê²¨ìš¸ì²  ì‹¤ìš©ì„± ì œê³µ',
        'IsMultiStory': 'ë‹¤ì¸µ êµ¬ì¡°ëŠ” ê³µê°„ ë¶„ë¦¬ì™€ í”„ë¼ì´ë²„ì‹œ í–¥ìƒ'
    }
    
    # íŠ¹ì„±ë³„ ìƒê´€ê´€ê³„ ê³„ì‚°
    available_features = [f for f in new_features if f in df.columns]
    
    for feature in available_features:
        if feature in df.columns:
            # ê²°ì¸¡ì¹˜ ì œê±° í›„ ìƒê´€ê´€ê³„ ê³„ì‚°
            valid_data = df[[feature, target_col]].dropna()
            if len(valid_data) > 10:
                correlation = valid_data[feature].corr(valid_data[target_col])
                correlations[feature] = correlation
    
    # ìƒê´€ê´€ê³„ ê¸°ì¤€ ì •ë ¬
    sorted_correlations = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)
    
    print(f"\nğŸ“Š íŠ¹ì„±ë³„ SalePrice ìƒê´€ê´€ê³„ (ì¤‘ìš”ë„ ìˆœ):")
    for i, (feature, corr) in enumerate(sorted_correlations[:10], 1):
        strength = "ê°•í•¨" if abs(corr) > 0.5 else "ì¤‘ê°„" if abs(corr) > 0.3 else "ì•½í•¨"
        direction = "ì–‘ì˜ ìƒê´€ê´€ê³„" if corr > 0 else "ìŒì˜ ìƒê´€ê´€ê³„"
        
        print(f"\n   {i}. {feature}")
        print(f"      ìƒê´€ê³„ìˆ˜: {corr:.3f} ({strength}, {direction})")
        
        if feature in business_interpretations:
            print(f"      ğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„: {business_interpretations[feature]}")
    
    # ì‹œê°í™”
    if len(sorted_correlations) > 0:
        # ìƒìœ„ 8ê°œ íŠ¹ì„± ì‹œê°í™”
        top_features = [item[0] for item in sorted_correlations[:8]]
        top_correlations = [item[1] for item in sorted_correlations[:8]]
        
        plt.figure(figsize=(12, 8))
        
        # ìƒ‰ìƒ ì„¤ì • (ì–‘ìˆ˜: íŒŒë€ìƒ‰, ìŒìˆ˜: ë¹¨ê°„ìƒ‰)
        colors = ['skyblue' if corr > 0 else 'lightcoral' for corr in top_correlations]
        
        bars = plt.barh(range(len(top_features)), top_correlations, color=colors, alpha=0.7)
        plt.yticks(range(len(top_features)), top_features)
        plt.xlabel('SalePriceì™€ì˜ ìƒê´€ê³„ìˆ˜')
        plt.title('ğŸ  ë„ë©”ì¸ íŠ¹ì„±ë“¤ì˜ SalePrice ì˜ˆì¸¡ ê¸°ì—¬ë„')
        plt.grid(True, alpha=0.3)
        
        # ê°’ í‘œì‹œ
        for i, (bar, corr) in enumerate(zip(bars, top_correlations)):
            plt.text(corr + (0.01 if corr > 0 else -0.05), i, f'{corr:.3f}', 
                    va='center', ha='left' if corr > 0 else 'right')
        
        plt.tight_layout()
        plt.show()
    
    # íŠ¹ì„± ì¡°í•©ì˜ ì‹œë„ˆì§€ íš¨ê³¼ ë¶„ì„
    print(f"\nğŸ”— íŠ¹ì„± ì¡°í•©ì˜ ì‹œë„ˆì§€ íš¨ê³¼:")
    
    # ë©´ì  ê´€ë ¨ íŠ¹ì„±ë“¤ì˜ ì¡°í•© íš¨ê³¼
    area_features = ['TotalLivingArea', 'AvgRoomSize', 'LotAreaRatio']
    available_area = [f for f in area_features if f in df.columns]
    
    if len(available_area) >= 2:
        area_combined = df[available_area].sum(axis=1)
        area_correlation = area_combined.corr(df[target_col])
        individual_max = max([abs(correlations.get(f, 0)) for f in available_area])
        
        print(f"   ë©´ì  íŠ¹ì„± ì¡°í•© ìƒê´€ê´€ê³„: {area_correlation:.3f}")
        print(f"   ê°œë³„ íŠ¹ì„± ìµœëŒ€ ìƒê´€ê´€ê³„: {individual_max:.3f}")
        print(f"   ğŸ’¡ ì¡°í•© íš¨ê³¼: {'ìˆìŒ' if abs(area_correlation) > individual_max else 'ì—†ìŒ'}")
    
    return correlations

# ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ë¶„ì„ ì‹¤í–‰
feature_correlations = analyze_feature_business_value(enhanced_data, domain_features)

---

## ğŸ“– 4.3.3 ìˆ˜í•™ì  íŠ¹ì„± ì¡°í•© ê¸°ë²•

### ìˆ˜í•™ì  ì¡°í•©ì˜ ì›ë¦¬

ë‹¨ìˆœíˆ ê°œë³„ ë³€ìˆ˜ë¥¼ ë³´ëŠ” ê²ƒë³´ë‹¤ **ë³€ìˆ˜ë“¤ ê°„ì˜ ê´€ê³„**ë¥¼ ìˆ˜í•™ì ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ë” í’ë¶€í•œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ° ì¡°í•©ë“¤ì€ ì¢…ì¢… ê°œë³„ ë³€ìˆ˜ë¡œëŠ” ë°œê²¬í•  ìˆ˜ ì—†ëŠ” **ìˆ¨ê²¨ì§„ íŒ¨í„´**ì„ ë“œëŸ¬ëƒ…ë‹ˆë‹¤.

```python
# ìˆ˜í•™ì  íŠ¹ì„± ì¡°í•© ìƒì„± í•¨ìˆ˜
def create_mathematical_features(df):
    """
    ìˆ˜í•™ì  ì¡°í•©ì„ í†µí•œ ìƒˆë¡œìš´ íŠ¹ì„± ìƒì„±
    """
    print("ğŸ”¢ ìˆ˜í•™ì  íŠ¹ì„± ì¡°í•© ìƒì„±:")
    
    df_math = df.copy()
    math_features = []
    
    print(f"\n1ï¸âƒ£ ë¹„ìœ¨(Ratio) íŠ¹ì„±:")
    
    # ë©´ì  ê´€ë ¨ ë¹„ìœ¨ë“¤
    if 'GrLivArea' in df.columns and 'LotArea' in df.columns:
        df_math['BuildingDensity'] = df['GrLivArea'] / df['LotArea']
        math_features.append('BuildingDensity')
        print(f"   âœ… BuildingDensity: ê±´ë¬¼ ë°€ë„ (ê±°ì£¼ë©´ì /ëŒ€ì§€ë©´ì )")
    
    if 'TotalBsmtSF' in df.columns and 'GrLivArea' in df.columns:
        df_math['BasementRatio'] = df['TotalBsmtSF'] / (df['GrLivArea'] + 1)
        math_features.append('BasementRatio')
        print(f"   âœ… BasementRatio: ì§€í•˜ì‹¤ ë¹„ìœ¨ (ì§€í•˜ì‹¤ë©´ì /ê±°ì£¼ë©´ì )")
    
    if 'GarageArea' in df.columns and 'GrLivArea' in df.columns:
        df_math['GarageRatio'] = df['GarageArea'] / (df['GrLivArea'] + 1)
        math_features.append('GarageRatio')
        print(f"   âœ… GarageRatio: ì°¨ê³  ë¹„ìœ¨ (ì°¨ê³ ë©´ì /ê±°ì£¼ë©´ì )")
    
    print(f"\n2ï¸âƒ£ ì°¨ì´(Difference) íŠ¹ì„±:")
    
    # ì‹œê°„ ì°¨ì´
    if 'YearRemodAdd' in df.columns and 'YearBuilt' in df.columns:
        df_math['RemodelDelay'] = df['YearRemodAdd'] - df['YearBuilt']
        math_features.append('RemodelDelay')
        print(f"   âœ… RemodelDelay: ë¦¬ëª¨ë¸ë§ ì§€ì—° ê¸°ê°„ (ë¦¬ëª¨ë¸ë§ì—°ë„ - ê±´ì„¤ì—°ë„)")
    
    # í’ˆì§ˆ ì°¨ì´
    if 'OverallQual' in df.columns and 'OverallCond' in df.columns:
        df_math['QualityCondGap'] = df['OverallQual'] - df['OverallCond']
        math_features.append('QualityCondGap')
        print(f"   âœ… QualityCondGap: í’ˆì§ˆ-ìƒíƒœ ê²©ì°¨ (ì„¤ê³„í’ˆì§ˆ vs í˜„ì¬ìƒíƒœ)")
    
    print(f"\n3ï¸âƒ£ ê³±ì…ˆ(Product) íŠ¹ì„± - ìƒí˜¸ì‘ìš© íš¨ê³¼:")
    
    # ë©´ì ê³¼ í’ˆì§ˆì˜ ìƒí˜¸ì‘ìš©
    if 'GrLivArea' in df.columns and 'OverallQual' in df.columns:
        df_math['QualityArea'] = df['GrLivArea'] * df['OverallQual']
        math_features.append('QualityArea')
        print(f"   âœ… QualityArea: í’ˆì§ˆ*ë©´ì  ìƒí˜¸ì‘ìš© (ê³ í’ˆì§ˆ ëŒ€í˜•ì£¼íƒ í”„ë¦¬ë¯¸ì—„)")
    
    # ìš•ì‹¤ê³¼ ì¹¨ì‹¤ì˜ ìƒí˜¸ì‘ìš©
    if 'FullBath' in df.columns and 'BedroomAbvGr' in df.columns:
        df_math['BathBedProduct'] = df['FullBath'] * df['BedroomAbvGr']
        math_features.append('BathBedProduct')
        print(f"   âœ… BathBedProduct: ìš•ì‹¤*ì¹¨ì‹¤ ìƒí˜¸ì‘ìš© (ìƒí™œ í¸ì˜ì„± ì¢…í•© ì§€ìˆ˜)")
    
    print(f"\n4ï¸âƒ£ ì œê³±ê·¼ ë° ê±°ë“­ì œê³± íŠ¹ì„±:")
    
    # ë©´ì ì˜ ì œê³±ê·¼ (ë©´ì  íš¨ê³¼ì˜ ë¹„ì„ í˜•ì„± ë°˜ì˜)
    if 'GrLivArea' in df.columns:
        df_math['SqrtArea'] = np.sqrt(df['GrLivArea'])
        math_features.append('SqrtArea')
        print(f"   âœ… SqrtArea: ë©´ì ì˜ ì œê³±ê·¼ (ë©´ì  íš¨ê³¼ì˜ ì²´ê° ë°˜ì˜)")
    
    # ì—°ë ¹ì˜ ì œê³± (ë…¸í›„í™” ê°€ì† íš¨ê³¼)
    if 'HouseAge' in df.columns:
        df_math['AgeSquared'] = df['HouseAge'] ** 2
        math_features.append('AgeSquared')
        print(f"   âœ… AgeSquared: ì—°ë ¹ì˜ ì œê³± (ë…¸í›„í™” ê°€ì† íš¨ê³¼)")
    
    print(f"\n5ï¸âƒ£ ë³µí•© ì§€ìˆ˜ íŠ¹ì„±:")
    
    # ìƒí™œ í¸ì˜ì„± ì§€ìˆ˜
    convenience_features = ['FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']
    available_convenience = [col for col in convenience_features if col in df.columns]
    
    if len(available_convenience) >= 2:
        # ì •ê·œí™” í›„ ê°€ì¤‘ í‰ê· 
        convenience_normalized = df[available_convenience].apply(lambda x: (x - x.min()) / (x.max() - x.min()))
        df_math['ConvenienceIndex'] = convenience_normalized.mean(axis=1)
        math_features.append('ConvenienceIndex')
        print(f"   âœ… ConvenienceIndex: ìƒí™œ í¸ì˜ì„± ë³µí•© ì§€ìˆ˜")
    
    # íˆ¬ì ë§¤ë ¥ë„ ì§€ìˆ˜ (ë©´ì , í’ˆì§ˆ, ì—°ë ¹ ì¢…í•©)
    investment_features = ['GrLivArea', 'OverallQual']
    if 'HouseAge' in df.columns:
        investment_features.append('HouseAge')
    
    available_investment = [col for col in investment_features if col in df.columns]
    
    if len(available_investment) >= 2:
        # HouseAgeëŠ” ì—­ìˆ˜ë¡œ ë³€í™˜ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
        investment_data = df[available_investment].copy()
        if 'HouseAge' in investment_data.columns:
            investment_data['HouseAge'] = 1 / (investment_data['HouseAge'] + 1)
        
        # ì •ê·œí™” í›„ ê¸°í•˜í‰ê· 
        investment_normalized = investment_data.apply(lambda x: (x - x.min()) / (x.max() - x.min()))
        df_math['InvestmentIndex'] = investment_normalized.prod(axis=1) ** (1/len(available_investment))
        math_features.append('InvestmentIndex')
        print(f"   âœ… InvestmentIndex: íˆ¬ì ë§¤ë ¥ë„ ë³µí•© ì§€ìˆ˜")
    
    print(f"\nğŸ“Š ìˆ˜í•™ì  íŠ¹ì„± ìƒì„± ì™„ë£Œ:")
    print(f"   ìƒì„±ëœ íŠ¹ì„±: {len(math_features)}ê°œ")
    print(f"   ì´ íŠ¹ì„± ìˆ˜: {df_math.shape[1]}ê°œ")
    
    return df_math, math_features

# ìˆ˜í•™ì  íŠ¹ì„± ìƒì„± ì‹¤í–‰
math_enhanced_data, math_features = create_mathematical_features(enhanced_data)
```

**ğŸ” ì½”ë“œ í•´ì„¤:**
- **ë¹„ìœ¨ íŠ¹ì„±**: ì„œë¡œ ë‹¤ë¥¸ í¬ê¸°ì˜ ë³€ìˆ˜ë“¤ì„ ë¹„êµ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¦
- **ì°¨ì´ íŠ¹ì„±**: ì ˆëŒ€ê°’ë³´ë‹¤ ìƒëŒ€ì  ì°¨ì´ê°€ ì¤‘ìš”í•œ ê²½ìš° í™œìš©
- **ê³±ì…ˆ íŠ¹ì„±**: ë‘ ë³€ìˆ˜ì˜ ìƒí˜¸ì‘ìš© íš¨ê³¼ë¥¼ í¬ì°©
- **ê±°ë“­ì œê³± íŠ¹ì„±**: ë¹„ì„ í˜• ê´€ê³„ë‚˜ ê°€ì†í™” íš¨ê³¼ ë°˜ì˜

### íŠ¹ì„± ì¡°í•©ì˜ íš¨ê³¼ ê²€ì¦

```python
# ìˆ˜í•™ì  íŠ¹ì„±ì˜ íš¨ê³¼ ê²€ì¦
def validate_mathematical_features(df, math_features, target_col='SalePrice'):
    """
    ìˆ˜í•™ì  íŠ¹ì„±ë“¤ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ ê¸°ì—¬ë„ ê²€ì¦
    """
    print("ğŸ”¬ ìˆ˜í•™ì  íŠ¹ì„± íš¨ê³¼ ê²€ì¦:")
    
    if target_col not in df.columns:
        print(f"âš ï¸ íƒ€ê²Ÿ ë³€ìˆ˜ {target_col}ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ìˆ˜í•™ì  íŠ¹ì„±ë“¤ì˜ ìƒê´€ê´€ê³„ ë¶„ì„
    available_math_features = [f for f in math_features if f in df.columns]
    
    correlations = {}
    for feature in available_math_features:
        valid_data = df[[feature, target_col]].dropna()
        if len(valid_data) > 10:
            corr = valid_data[feature].corr(valid_data[target_col])
            correlations[feature] = corr
    
    # ìƒê´€ê´€ê³„ ê¸°ì¤€ ì •ë ¬
    sorted_corr = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)
    
    print(f"\nğŸ“Š ìˆ˜í•™ì  íŠ¹ì„±ë³„ ì˜ˆì¸¡ë ¥ (ìƒê´€ê³„ìˆ˜ ê¸°ì¤€):")
    for i, (feature, corr) in enumerate(sorted_corr[:8], 1):
        strength = "ë§¤ìš° ê°•í•¨" if abs(corr) > 0.7 else "ê°•í•¨" if abs(corr) > 0.5 else "ì¤‘ê°„" if abs(corr) > 0.3 else "ì•½í•¨"
        print(f"   {i}. {feature}: {corr:.3f} ({strength})")
    
    # ì‹œê°í™”: ìƒìœ„ íŠ¹ì„±ë“¤ì˜ ì‚°ì ë„
    if len(sorted_corr) >= 4:
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('ğŸ”¢ ìˆ˜í•™ì  íŠ¹ì„±ë“¤ì˜ SalePrice ì˜ˆì¸¡ íš¨ê³¼', fontsize=16, fontweight='bold')
        
        for i, (feature, corr) in enumerate(sorted_corr[:4]):
            row, col = i // 2, i % 2
            
            # ì‚°ì ë„
            valid_data = df[[feature, target_col]].dropna()
            axes[row, col].scatter(valid_data[feature], valid_data[target_col], 
                                 alpha=0.6, color='skyblue', s=20)
            
            # ì¶”ì„¸ì„  ì¶”ê°€
            z = np.polyfit(valid_data[feature], valid_data[target_col], 1)
            p = np.poly1d(z)
            axes[row, col].plot(valid_data[feature], p(valid_data[feature]), 
                              "r--", alpha=0.8, linewidth=2)
            
            axes[row, col].set_xlabel(feature)
            axes[row, col].set_ylabel('SalePrice')
            axes[row, col].set_title(f'{feature}\nìƒê´€ê³„ìˆ˜: {corr:.3f}')
            axes[row, col].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    # íŠ¹ì„± ì¡°í•©ì˜ ì‹œë„ˆì§€ íš¨ê³¼ ê²€ì¦
    print(f"\nğŸ”— íŠ¹ì„± ì¡°í•© ì‹œë„ˆì§€ íš¨ê³¼ ê²€ì¦:")
    
    # ìƒìœ„ 3ê°œ íŠ¹ì„± ì¡°í•©
    if len(sorted_corr) >= 3:
        top_3_features = [item[0] for item in sorted_corr[:3]]
        
        # ê°œë³„ íŠ¹ì„±ë“¤ì˜ í‰ê·  ìƒê´€ê´€ê³„
        individual_corrs = [abs(item[1]) for item in sorted_corr[:3]]
        avg_individual_corr = np.mean(individual_corrs)
        
        # ì¡°í•© íŠ¹ì„± ìƒì„± (ë‹¨ìˆœ í‰ê· )
        valid_data = df[top_3_features + [target_col]].dropna()
        combined_feature = valid_data[top_3_features].mean(axis=1)
        combined_corr = combined_feature.corr(valid_data[target_col])
        
        print(f"   ê°œë³„ íŠ¹ì„± í‰ê·  ìƒê´€ê´€ê³„: {avg_individual_corr:.3f}")
        print(f"   ì¡°í•© íŠ¹ì„± ìƒê´€ê´€ê³„: {abs(combined_corr):.3f}")
        print(f"   ì‹œë„ˆì§€ íš¨ê³¼: {abs(combined_corr) - avg_individual_corr:.3f}")
        print(f"   ğŸ’¡ {'ì¡°í•© íš¨ê³¼ ìˆìŒ' if abs(combined_corr) > avg_individual_corr else 'ì¡°í•© íš¨ê³¼ ì œí•œì '}")
    
    # íŠ¹ì„± ìœ í˜•ë³„ ê¸°ì—¬ë„ ë¶„ì„
    print(f"\nğŸ“ˆ íŠ¹ì„± ìœ í˜•ë³„ ê¸°ì—¬ë„ ë¶„ì„:")
    
    feature_types = {
        'Ratio': ['BuildingDensity', 'BasementRatio', 'GarageRatio'],
        'Difference': ['RemodelDelay', 'QualityCondGap'],
        'Product': ['QualityArea', 'BathBedProduct'],
        'Power': ['SqrtArea', 'AgeSquared'],
        'Index': ['ConvenienceIndex', 'InvestmentIndex']
    }
    
    type_performance = {}
    for ftype, features in feature_types.items():
        available_features = [f for f in features if f in correlations]
        if available_features:
            avg_corr = np.mean([abs(correlations[f]) for f in available_features])
            type_performance[ftype] = avg_corr
            print(f"   {ftype} íŠ¹ì„±: í‰ê·  ìƒê´€ê´€ê³„ {avg_corr:.3f}")
    
    # ê°€ì¥ íš¨ê³¼ì ì¸ íŠ¹ì„± ìœ í˜•
    if type_performance:
        best_type = max(type_performance.items(), key=lambda x: x[1])
        print(f"   ğŸ† ê°€ì¥ íš¨ê³¼ì ì¸ ìœ í˜•: {best_type[0]} (ìƒê´€ê´€ê³„ {best_type[1]:.3f})")
    
    return correlations, type_performance

# ìˆ˜í•™ì  íŠ¹ì„± íš¨ê³¼ ê²€ì¦ ì‹¤í–‰
math_correlations, type_performance = validate_mathematical_features(math_enhanced_data, math_features)
```

**ğŸ” ì½”ë“œ í•´ì„¤:**
- ê° ìˆ˜í•™ì  íŠ¹ì„±ì˜ ê°œë³„ ì˜ˆì¸¡ë ¥ì„ ìƒê´€ê´€ê³„ë¡œ ì¸¡ì •
- ì‚°ì ë„ì™€ ì¶”ì„¸ì„ ìœ¼ë¡œ ê´€ê³„ì˜ ì„ í˜•ì„±/ë¹„ì„ í˜•ì„± í™•ì¸
- íŠ¹ì„± ìœ í˜•ë³„ ì„±ëŠ¥ ë¹„êµë¡œ ì–´ë–¤ ì¢…ë¥˜ì˜ ì¡°í•©ì´ íš¨ê³¼ì ì¸ì§€ íŒŒì•…

---

## ğŸ“– 4.3.4 ì‹œê°„ ê¸°ë°˜ íŠ¹ì„± ì¶”ì¶œ

### ì‹œê°„ ì •ë³´ì˜ í™œìš©

ë¶€ë™ì‚° ì‹œì¥ì€ **ì‹œê°„ì— ë”°ë¥¸ ë³€í™”**ê°€ í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë¶„ì•¼ì…ë‹ˆë‹¤. ê±´ì¶• ì—°ë„, ë¦¬ëª¨ë¸ë§ ì‹œê¸°, íŒë§¤ ì‹œê¸° ë“±ì—ì„œ ë‹¤ì–‘í•œ ì‹œê°„ ê¸°ë°˜ íŠ¹ì„±ì„ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# ì‹œê°„ ê¸°ë°˜ íŠ¹ì„± ì¶”ì¶œ í•¨ìˆ˜
def create_temporal_features(df):
    """
    ì‹œê°„ ê´€ë ¨ ë³€ìˆ˜ë“¤ë¡œë¶€í„° ê³ ê¸‰ ì‹œê°„ íŠ¹ì„± ì¶”ì¶œ
    """
    print("â° ì‹œê°„ ê¸°ë°˜ íŠ¹ì„± ì¶”ì¶œ:")
    
    df_temporal = df.copy()
    temporal_features = []
    
    print(f"\n1ï¸âƒ£ ê±´ì¶• ì‹œëŒ€ ë¶„ë¥˜:")
    
    if 'YearBuilt' in df.columns:
        # ê±´ì¶• ì‹œëŒ€ë³„ ë¶„ë¥˜
        df_temporal['Era_PreWar'] = (df['YearBuilt'] < 1940).astype(int)
        df_temporal['Era_PostWar'] = ((df['YearBuilt'] >= 1940) & (df['YearBuilt'] < 1960)).astype(int)
        df_temporal['Era_Modern'] = ((df['YearBuilt'] >= 1960) & (df['YearBuilt'] < 1980)).astype(int)
        df_temporal['Era_Contemporary'] = ((df['YearBuilt'] >= 1980) & (df['YearBuilt'] < 2000)).astype(int)
        df_temporal['Era_Recent'] = (df['YearBuilt'] >= 2000).astype(int)
        
        temporal_features.extend(['Era_PreWar', 'Era_PostWar', 'Era_Modern', 'Era_Contemporary', 'Era_Recent'])
        
        # ê° ì‹œëŒ€ë³„ ë¶„í¬ í™•ì¸
        era_counts = {
            'Pre-War (~1939)': (df['YearBuilt'] < 1940).sum(),
            'Post-War (1940-1959)': ((df['YearBuilt'] >= 1940) & (df['YearBuilt'] < 1960)).sum(),
            'Modern (1960-1979)': ((df['YearBuilt'] >= 1960) & (df['YearBuilt'] < 1980)).sum(),
            'Contemporary (1980-1999)': ((df['YearBuilt'] >= 1980) & (df['YearBuilt'] < 2000)).sum(),
            'Recent (2000~)': (df['YearBuilt'] >= 2000).sum()
        }
        
        print(f"   ê±´ì¶• ì‹œëŒ€ë³„ ë¶„í¬:")
        for era, count in era_counts.items():
            print(f"      {era}: {count}ê°œ ({count/len(df)*100:.1f}%)")
    
    print(f"\n2ï¸âƒ£ ë¦¬ëª¨ë¸ë§ íŒ¨í„´ ë¶„ì„:")
    
    if 'YearBuilt' in df.columns and 'YearRemodAdd' in df.columns:
        # ë¦¬ëª¨ë¸ë§ ì£¼ê¸° ë¶„ì„
        df_temporal['RemodelCycle'] = df['YearRemodAdd'] - df['YearBuilt']
        
        # ë¦¬ëª¨ë¸ë§ íŒ¨í„´ ë¶„ë¥˜
        df_temporal['NoRemodel'] = (df['YearRemodAdd'] == df['YearBuilt']).astype(int)
        df_temporal['EarlyRemodel'] = ((df_temporal['RemodelCycle'] > 0) & (df_temporal['RemodelCycle'] <= 10)).astype(int)
        df_temporal['MidRemodel'] = ((df_temporal['RemodelCycle'] > 10) & (df_temporal['RemodelCycle'] <= 20)).astype(int)
        df_temporal['LateRemodel'] = (df_temporal['RemodelCycle'] > 20).astype(int)
        
        temporal_features.extend(['RemodelCycle', 'NoRemodel', 'EarlyRemodel', 'MidRemodel', 'LateRemodel'])
        
        print(f"   ë¦¬ëª¨ë¸ë§ íŒ¨í„´:")
        print(f"      ë¦¬ëª¨ë¸ë§ ì—†ìŒ: {df_temporal['NoRemodel'].sum()}ê°œ")
        print(f"      ì¡°ê¸° ë¦¬ëª¨ë¸ë§ (â‰¤10ë…„): {df_temporal['EarlyRemodel'].sum()}ê°œ")
        print(f"      ì¤‘ê¸° ë¦¬ëª¨ë¸ë§ (11-20ë…„): {df_temporal['MidRemodel'].sum()}ê°œ")
        print(f"      í›„ê¸° ë¦¬ëª¨ë¸ë§ (>20ë…„): {df_temporal['LateRemodel'].sum()}ê°œ")
    
    print(f"\n3ï¸âƒ£ íŒë§¤ ì‹œê¸° íŒ¨í„´:")
    
    if 'YrSold' in df.columns:
        # ê²½ê¸° ì‚¬ì´í´ ë°˜ì˜ (ëŒ€ëµì ì¸ ë¶€ë™ì‚° ì‚¬ì´í´)
        df_temporal['CyclePhase_Growth'] = df['YrSold'].isin([2004, 2005, 2006]).astype(int)
        df_temporal['CyclePhase_Peak'] = df['YrSold'].isin([2007]).astype(int)
        df_temporal['CyclePhase_Decline'] = df['YrSold'].isin([2008, 2009]).astype(int)
        df_temporal['CyclePhase_Recovery'] = df['YrSold'].isin([2010]).astype(int)
        
        temporal_features.extend(['CyclePhase_Growth', 'CyclePhase_Peak', 'CyclePhase_Decline', 'CyclePhase_Recovery'])
        
        print(f"   ë¶€ë™ì‚° ì‚¬ì´í´ë³„ íŒë§¤:")
        cycle_counts = {
            'Growth (2004-2006)': df_temporal['CyclePhase_Growth'].sum(),
            'Peak (2007)': df_temporal['CyclePhase_Peak'].sum(),
            'Decline (2008-2009)': df_temporal['CyclePhase_Decline'].sum(),
            'Recovery (2010)': df_temporal['CyclePhase_Recovery'].sum()
        }
        
        for phase, count in cycle_counts.items():
            print(f"      {phase}: {count}ê°œ")
    
    if 'MoSold' in df.columns:
        # ê³„ì ˆì„± ì‹¬í™” ë¶„ì„
        df_temporal['QuarterSold_Q1'] = df['MoSold'].isin([1, 2, 3]).astype(int)
        df_temporal['QuarterSold_Q2'] = df['MoSold'].isin([4, 5, 6]).astype(int)
        df_temporal['QuarterSold_Q3'] = df['MoSold'].isin([7, 8, 9]).astype(int)
        df_temporal['QuarterSold_Q4'] = df['MoSold'].isin([10, 11, 12]).astype(int)
        
        # ì„±ìˆ˜ê¸°/ë¹„ìˆ˜ê¸°
        df_temporal['PeakSeason'] = df['MoSold'].isin([5, 6, 7, 8]).astype(int)  # ë´„-ì—¬ë¦„
        df_temporal['OffSeason'] = df['MoSold'].isin([11, 12, 1, 2]).astype(int)  # ê²¨ìš¸
        
        temporal_features.extend(['QuarterSold_Q1', 'QuarterSold_Q2', 'QuarterSold_Q3', 'QuarterSold_Q4', 
                                'PeakSeason', 'OffSeason'])
        
        print(f"   ê³„ì ˆì„± ë¶„ì„:")
        print(f"      ì„±ìˆ˜ê¸° íŒë§¤ (5-8ì›”): {df_temporal['PeakSeason'].sum()}ê°œ")
        print(f"      ë¹„ìˆ˜ê¸° íŒë§¤ (11-2ì›”): {df_temporal['OffSeason'].sum()}ê°œ")
    
    print(f"\n4ï¸âƒ£ ì‹œê°„ ê²½ê³¼ íš¨ê³¼:")
    
    # í˜„ì¬ ì‹œì  ê¸°ì¤€ ë¶„ì„ (2023ë…„ ê¸°ì¤€)
    current_year = 2023
    
    if 'YearBuilt' in df.columns:
        # ë…¸í›„í™” ë‹¨ê³„ë³„ ë¶„ë¥˜
        df_temporal['HouseAge'] = current_year - df['YearBuilt']
        
        df_temporal['AgeGroup_New'] = (df_temporal['HouseAge'] <= 5).astype(int)
        df_temporal['AgeGroup_Recent'] = ((df_temporal['HouseAge'] > 5) & (df_temporal['HouseAge'] <= 15)).astype(int)
        df_temporal['AgeGroup_Mature'] = ((df_temporal['HouseAge'] > 15) & (df_temporal['HouseAge'] <= 30)).astype(int)
        df_temporal['AgeGroup_Old'] = ((df_temporal['HouseAge'] > 30) & (df_temporal['HouseAge'] <= 50)).astype(int)
        df_temporal['AgeGroup_Historic'] = (df_temporal['HouseAge'] > 50).astype(int)
        
        temporal_features.extend(['AgeGroup_New', 'AgeGroup_Recent', 'AgeGroup_Mature', 'AgeGroup_Old', 'AgeGroup_Historic'])
        
        print(f"   ì—°ë ¹ëŒ€ë³„ ë¶„í¬ ({current_year}ë…„ ê¸°ì¤€):")
        age_groups = {
            'New (â‰¤5ë…„)': df_temporal['AgeGroup_New'].sum(),
            'Recent (6-15ë…„)': df_temporal['AgeGroup_Recent'].sum(),
            'Mature (16-30ë…„)': df_temporal['AgeGroup_Mature'].sum(),
            'Old (31-50ë…„)': df_temporal['AgeGroup_Old'].sum(),
            'Historic (>50ë…„)': df_temporal['AgeGroup_Historic'].sum()
        }
        
        for group, count in age_groups.items():
            print(f"      {group}: {count}ê°œ")
    
    print(f"\nğŸ“Š ì‹œê°„ ê¸°ë°˜ íŠ¹ì„± ìƒì„± ì™„ë£Œ:")
    print(f"   ìƒì„±ëœ íŠ¹ì„±: {len(temporal_features)}ê°œ")
    print(f"   ì´ íŠ¹ì„± ìˆ˜: {df_temporal.shape[1]}ê°œ")
    
    return df_temporal, temporal_features

# ì‹œê°„ ê¸°ë°˜ íŠ¹ì„± ìƒì„± ì‹¤í–‰
temporal_enhanced_data, temporal_features = create_temporal_features(math_enhanced_data)
```

**ğŸ” ì½”ë“œ í•´ì„¤:**
- **ê±´ì¶• ì‹œëŒ€**: ê° ì‹œëŒ€ë³„ ê±´ì¶• ì–‘ì‹ê³¼ ê¸°ì¤€ì´ ê°€ê²©ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
- **ë¦¬ëª¨ë¸ë§ íŒ¨í„´**: ìœ ì§€ë³´ìˆ˜ ì£¼ê¸°ì™€ íˆ¬ì íŒ¨í„´ ë¶„ì„
- **íŒë§¤ ì‹œê¸°**: ë¶€ë™ì‚° ì‹œì¥ ì‚¬ì´í´ê³¼ ê³„ì ˆì„± íš¨ê³¼
- **ë…¸í›„í™” ë‹¨ê³„**: ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ê°€ì¹˜ ë³€í™” íŒ¨í„´

### ì‹œê°„ íŠ¹ì„±ì˜ ì‹œê°í™” ë° ë¶„ì„

```python
# ì‹œê°„ íŠ¹ì„± íš¨ê³¼ ë¶„ì„
def analyze_temporal_effects(df, temporal_features, target_col='SalePrice'):
    """
    ì‹œê°„ ê¸°ë°˜ íŠ¹ì„±ë“¤ì˜ íš¨ê³¼ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë¶„ì„
    """
    print("ğŸ“ˆ ì‹œê°„ íŠ¹ì„± íš¨ê³¼ ë¶„ì„:")
    
    if target_col not in df.columns:
        print(f"âš ï¸ íƒ€ê²Ÿ ë³€ìˆ˜ {target_col}ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 1. ê±´ì¶• ì‹œëŒ€ë³„ ê°€ê²© ë¶„ì„
    print(f"\nğŸ›ï¸ ê±´ì¶• ì‹œëŒ€ë³„ ê°€ê²© ë¶„ì„:")
    
    era_features = [f for f in temporal_features if f.startswith('Era_')]
    if era_features and 'YearBuilt' in df.columns:
        era_mapping = {
            'Era_PreWar': 'Pre-War (~1939)',
            'Era_PostWar': 'Post-War (1940-59)',
            'Era_Modern': 'Modern (1960-79)',
            'Era_Contemporary': 'Contemporary (1980-99)',
            'Era_Recent': 'Recent (2000~)'
        }
        
        era_prices = {}
        for feature in era_features:
            if feature in df.columns:
                era_mask = df[feature] == 1
                if era_mask.sum() > 0:
                    avg_price = df.loc[era_mask, target_col].mean()
                    era_prices[era_mapping.get(feature, feature)] = avg_price
        
        for era, price in era_prices.items():
            print(f"   {era}: ${price:,.0f}")
        
        # ì‹œê°í™”
        if len(era_prices) > 0:
            plt.figure(figsize=(12, 8))
            
            # ì„œë¸Œí”Œë¡¯ ìƒì„±
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle('â° ì‹œê°„ ê¸°ë°˜ íŠ¹ì„±ë“¤ì˜ ë¶€ë™ì‚° ê°€ê²© ì˜í–¥ ë¶„ì„', fontsize=16, fontweight='bold')
            
            # 1. ê±´ì¶• ì‹œëŒ€ë³„ í‰ê·  ê°€ê²©
            eras = list(era_prices.keys())
            prices = list(era_prices.values())
            
            bars = axes[0,0].bar(eras, prices, color='skyblue', alpha=0.7)
            axes[0,0].set_title('ê±´ì¶• ì‹œëŒ€ë³„ í‰ê·  íŒë§¤ ê°€ê²©')
            axes[0,0].set_ylabel('í‰ê·  ê°€ê²© ($)')
            axes[0,0].tick_params(axis='x', rotation=45)
            axes[0,0].grid(True, alpha=0.3)
            
            # ê°’ í‘œì‹œ
            for bar, price in zip(bars, prices):
                axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + price*0.01,
                             f'${price:,.0f}', ha='center', va='bottom')
    
    # 2. ê³„ì ˆì„± íš¨ê³¼ ë¶„ì„
    if 'MoSold' in df.columns:
        monthly_prices = df.groupby('MoSold')[target_col].agg(['mean', 'count']).round(0)
        
        print(f"\nğŸŒ± ì›”ë³„ íŒë§¤ ê°€ê²© íŒ¨í„´:")
        months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 
                 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
        
        axes[0,1].plot(monthly_prices.index, monthly_prices['mean'], 
                      marker='o', linewidth=2, markersize=6, color='green')
        axes[0,1].set_title('ì›”ë³„ í‰ê·  íŒë§¤ ê°€ê²© ì¶”ì´')
        axes[0,1].set_xlabel('ì›”')
        axes[0,1].set_ylabel('í‰ê·  ê°€ê²© ($)')
        axes[0,1].set_xticks(range(1, 13))
        axes[0,1].set_xticklabels(months, rotation=45)
        axes[0,1].grid(True, alpha=0.3)
        
        # ìµœê³ ê°€/ìµœì €ê°€ ì›” í‘œì‹œ
        max_month = monthly_prices['mean'].idxmax()
        min_month = monthly_prices['mean'].idxmin()
        max_price = monthly_prices['mean'].max()
        min_price = monthly_prices['mean'].min()
        
        axes[0,1].scatter(max_month, max_price, color='red', s=100, zorder=5)
        axes[0,1].scatter(min_month, min_price, color='blue', s=100, zorder=5)
        
        print(f"   ìµœê³ ê°€ ì›”: {months[max_month-1]} (${max_price:,.0f})")
        print(f"   ìµœì €ê°€ ì›”: {months[min_month-1]} (${min_price:,.0f})")
        print(f"   ê³„ì ˆì„± íš¨ê³¼: {((max_price-min_price)/min_price*100):.1f}% ì°¨ì´")
    
    # 3. ì£¼íƒ ì—°ë ¹ íš¨ê³¼
    if 'HouseAge' in df.columns:
        # ì—°ë ¹ëŒ€ë³„ ê°€ê²© ë¶„í¬
        age_groups = ['AgeGroup_New', 'AgeGroup_Recent', 'AgeGroup_Mature', 'AgeGroup_Old', 'AgeGroup_Historic']
        age_labels = ['New\n(â‰¤5ë…„)', 'Recent\n(6-15ë…„)', 'Mature\n(16-30ë…„)', 'Old\n(31-50ë…„)', 'Historic\n(>50ë…„)']
        
        available_age_groups = [group for group in age_groups if group in df.columns]
        
        if len(available_age_groups) > 0:
            age_data = []
            age_labels_available = []
            
            for i, group in enumerate(available_age_groups):
                mask = df[group] == 1
                if mask.sum() > 0:
                    prices = df.loc[mask, target_col].values
                    age_data.append(prices)
                    age_labels_available.append(age_labels[age_groups.index(group)])
            
            if age_data:
                axes[1,0].boxplot(age_data, labels=age_labels_available)
                axes[1,0].set_title('ì£¼íƒ ì—°ë ¹ëŒ€ë³„ ê°€ê²© ë¶„í¬')
                axes[1,0].set_ylabel('íŒë§¤ ê°€ê²© ($)')
                axes[1,0].tick_params(axis='x', rotation=45)
                axes[1,0].grid(True, alpha=0.3)
    
    # 4. ë¦¬ëª¨ë¸ë§ íš¨ê³¼
    remodel_features = ['NoRemodel', 'EarlyRemodel', 'MidRemodel', 'LateRemodel']
    available_remodel = [f for f in remodel_features if f in df.columns]
    
    if len(available_remodel) >= 2:
        remodel_labels = ['No Remodel', 'Early\n(â‰¤10ë…„)', 'Mid\n(11-20ë…„)', 'Late\n(>20ë…„)']
        remodel_prices = []
        remodel_labels_available = []
        
        for i, feature in enumerate(remodel_features):
            if feature in df.columns:
                mask = df[feature] == 1
                if mask.sum() > 0:
                    avg_price = df.loc[mask, target_col].mean()
                    remodel_prices.append(avg_price)
                    remodel_labels_available.append(remodel_labels[i])
        
        if remodel_prices:
            bars = axes[1,1].bar(remodel_labels_available, remodel_prices, 
                               color='lightcoral', alpha=0.7)
            axes[1,1].set_title('ë¦¬ëª¨ë¸ë§ ì‹œê¸°ë³„ í‰ê·  ê°€ê²©')
            axes[1,1].set_ylabel('í‰ê·  ê°€ê²© ($)')
            axes[1,1].tick_params(axis='x', rotation=45)
            axes[1,1].grid(True, alpha=0.3)
            
            # ê°’ í‘œì‹œ
            for bar, price in zip(bars, remodel_prices):
                axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + price*0.01,
                             f'${price:,.0f}', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.show()
    
    print(f"\nğŸ’¡ ì‹œê°„ íŠ¹ì„± ì¸ì‚¬ì´íŠ¸:")
    print(f"   ğŸ›ï¸ ê±´ì¶• ì‹œëŒ€ëŠ” ì£¼íƒ ê°€ê²©ì— ëšœë ·í•œ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤")
    print(f"   ğŸŒ± ê³„ì ˆì„±ì€ ë¶€ë™ì‚° ê±°ë˜ì˜ ì¤‘ìš”í•œ íŒ¨í„´ì…ë‹ˆë‹¤")
    print(f"   â° ì£¼íƒ ì—°ë ¹ê³¼ ë¦¬ëª¨ë¸ë§ ì´ë ¥ì€ ê°€ì¹˜ í‰ê°€ì˜ í•µì‹¬ ìš”ì†Œì…ë‹ˆë‹¤")

# ì‹œê°„ íŠ¹ì„± íš¨ê³¼ ë¶„ì„ ì‹¤í–‰
analyze_temporal_effects(temporal_enhanced_data, temporal_features)
```

> **ğŸ“Š ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸:**  
> "Create a comprehensive temporal analysis dashboard for real estate data showing: 1) A bar chart of average house prices by construction era (Pre-War, Post-War, Modern, Contemporary, Recent), 2) A line chart showing monthly price trends throughout the year with seasonal patterns highlighted, 3) Box plots comparing price distributions across different house age groups (New, Recent, Mature, Old, Historic), 4) A bar chart showing the impact of remodeling timing on house prices (No Remodel, Early, Mid, Late). Use professional styling with clear legends, value labels, and distinct colors for each category."

---

## ğŸ“– 4.3.5 íŠ¹ì„± ì„ íƒ ê¸°ë²•

### íŠ¹ì„± ì„ íƒì˜ í•„ìš”ì„±

íŠ¹ì„±ì„ ë§ì´ ìƒì„±í–ˆë‹¤ê³  í•´ì„œ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ì€ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. **ì°¨ì›ì˜ ì €ì£¼**, **ê³¼ì í•©**, **ê³„ì‚° ë¹„ìš©** ë“±ì˜ ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ **ê°€ì¥ ìœ ìš©í•œ íŠ¹ì„±ë“¤ë§Œ ì„ ë³„**í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.

```python
from sklearn.feature_selection import SelectKBest, f_regression, RFE
from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LassoCV

# íŠ¹ì„± ì„ íƒ ì¢…í•© ì‹œìŠ¤í…œ
def comprehensive_feature_selection(df, target_col='SalePrice', k_best=20):
    """
    ë‹¤ì–‘í•œ ë°©ë²•ì„ ì‚¬ìš©í•œ ì¢…í•©ì  íŠ¹ì„± ì„ íƒ
    """
    print("ğŸ¯ ì¢…í•©ì  íŠ¹ì„± ì„ íƒ ì‹œìŠ¤í…œ:")
    
    if target_col not in df.columns:
        print(f"âš ï¸ íƒ€ê²Ÿ ë³€ìˆ˜ {target_col}ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° ì¤€ë¹„
    X = df.drop(columns=[target_col])
    y = df[target_col]
    
    # ìˆ˜ì¹˜í˜• íŠ¹ì„±ë§Œ ì„ íƒ (íŠ¹ì„± ì„ íƒ ì•Œê³ ë¦¬ì¦˜ì„ ìœ„í•´)
    numeric_features = X.select_dtypes(include=[np.number]).columns
    X_numeric = X[numeric_features].fillna(X[numeric_features].median())
    
    print(f"   ì „ì²´ ìˆ˜ì¹˜í˜• íŠ¹ì„±: {X_numeric.shape[1]}ê°œ")
    
    feature_scores = {}
    
    print(f"\n1ï¸âƒ£ í†µê³„ì  íŠ¹ì„± ì„ íƒ (F-í†µê³„ëŸ‰ ê¸°ë°˜):")
    
    # F-í†µê³„ëŸ‰ ê¸°ë°˜ ì„ íƒ
    selector_f = SelectKBest(score_func=f_regression, k=k_best)
    X_selected_f = selector_f.fit_transform(X_numeric, y)
    
    f_scores = selector_f.scores_
    f_selected_features = numeric_features[selector_f.get_support()]
    
    print(f"   ì„ íƒëœ íŠ¹ì„±: {len(f_selected_features)}ê°œ")
    print(f"   ìƒìœ„ 5ê°œ íŠ¹ì„±:")
    
    f_score_dict = dict(zip(numeric_features, f_scores))
    top_f_features = sorted(f_score_dict.items(), key=lambda x: x[1], reverse=True)[:5]
    
    for feature, score in top_f_features:
        print(f"      {feature}: F-score {score:.1f}")
    
    feature_scores['F_statistic'] = f_score_dict
    
    print(f"\n2ï¸âƒ£ ëª¨ë¸ ê¸°ë°˜ íŠ¹ì„± ì„ íƒ (Random Forest):")
    
    # Random Forest ê¸°ë°˜ íŠ¹ì„± ì¤‘ìš”ë„
    rf_selector = RandomForestRegressor(n_estimators=100, random_state=42)
    rf_selector.fit(X_numeric, y)
    
    rf_importances = rf_selector.feature_importances_
    rf_importance_dict = dict(zip(numeric_features, rf_importances))
    
    # ìƒìœ„ íŠ¹ì„± ì„ íƒ
    selector_rf = SelectFromModel(rf_selector, prefit=True, max_features=k_best)
    X_selected_rf = selector_rf.transform(X_numeric)
    rf_selected_features = numeric_features[selector_rf.get_support()]
    
    print(f"   ì„ íƒëœ íŠ¹ì„±: {len(rf_selected_features)}ê°œ")
    print(f"   ìƒìœ„ 5ê°œ íŠ¹ì„±:")
    
    top_rf_features = sorted(rf_importance_dict.items(), key=lambda x: x[1], reverse=True)[:5]
    for feature, importance in top_rf_features:
        print(f"      {feature}: ì¤‘ìš”ë„ {importance:.3f}")
    
    feature_scores['Random_Forest'] = rf_importance_dict
    
    print(f"\n3ï¸âƒ£ ì •ê·œí™” ê¸°ë°˜ íŠ¹ì„± ì„ íƒ (Lasso):")
    
    # Lasso íšŒê·€ ê¸°ë°˜ íŠ¹ì„± ì„ íƒ
    lasso_cv = LassoCV(cv=5, random_state=42)
    lasso_cv.fit(X_numeric, y)
    
    # Lasso ê³„ìˆ˜ê°€ 0ì´ ì•„ë‹Œ íŠ¹ì„±ë“¤
    lasso_coef = np.abs(lasso_cv.coef_)
    lasso_selected_mask = lasso_coef > 0
    lasso_selected_features = numeric_features[lasso_selected_mask]
    
    lasso_coef_dict = dict(zip(numeric_features, lasso_coef))
    
    print(f"   ì„ íƒëœ íŠ¹ì„±: {len(lasso_selected_features)}ê°œ")
    print(f"   ìµœì  alpha: {lasso_cv.alpha_:.6f}")
    print(f"   ìƒìœ„ 5ê°œ íŠ¹ì„±:")
    
    top_lasso_features = sorted(lasso_coef_dict.items(), key=lambda x: x[1], reverse=True)[:5]
    for feature, coef in top_lasso_features:
        if coef > 0:
            print(f"      {feature}: ê³„ìˆ˜ {coef:.3f}")
    
    feature_scores['Lasso'] = lasso_coef_dict
    
    print(f"\n4ï¸âƒ£ ìˆœí™˜ì  íŠ¹ì„± ì œê±° (RFE):")
    
    # RFE (Recursive Feature Elimination)
    rfe_selector = RFE(estimator=RandomForestRegressor(n_estimators=50, random_state=42), 
                       n_features_to_select=k_best)
    rfe_selector.fit(X_numeric, y)
    
    rfe_selected_features = numeric_features[rfe_selector.get_support()]
    rfe_ranking = rfe_selector.ranking_
    
    print(f"   ì„ íƒëœ íŠ¹ì„±: {len(rfe_selected_features)}ê°œ")
    print(f"   ìƒìœ„ 5ê°œ íŠ¹ì„± (ë­í‚¹ ìˆœ):")
    
    rfe_ranking_dict = dict(zip(numeric_features, rfe_ranking))
    top_rfe_features = sorted(rfe_ranking_dict.items(), key=lambda x: x[1])[:5]
    
    for feature, rank in top_rfe_features:
        print(f"      {feature}: ë­í‚¹ {rank}")
    
    feature_scores['RFE'] = rfe_ranking_dict
    
    # 5. í†µí•© íŠ¹ì„± ì ìˆ˜ ê³„ì‚°
    print(f"\n5ï¸âƒ£ í†µí•© íŠ¹ì„± ì„ íƒ (ì•™ìƒë¸” ë°©ì‹):")
    
    # ê° ë°©ë²•ë³„ ì •ê·œí™”ëœ ì ìˆ˜ ê³„ì‚°
    normalized_scores = {}
    
    # F-í†µê³„ëŸ‰ ì •ê·œí™” (0-1)
    f_values = np.array(list(f_score_dict.values()))
    f_normalized = (f_values - f_values.min()) / (f_values.max() - f_values.min())
    normalized_scores['F_stat'] = dict(zip(numeric_features, f_normalized))
    
    # Random Forest ì¤‘ìš”ë„ (ì´ë¯¸ 0-1 ë²”ìœ„)
    normalized_scores['RF'] = rf_importance_dict
    
    # Lasso ê³„ìˆ˜ ì •ê·œí™”
    lasso_values = np.array(list(lasso_coef_dict.values()))
    if lasso_values.max() > 0:
        lasso_normalized = lasso_values / lasso_values.max()
        normalized_scores['Lasso'] = dict(zip(numeric_features, lasso_normalized))
    
    # RFE ë­í‚¹ì„ ì ìˆ˜ë¡œ ë³€í™˜ (ë­í‚¹ì´ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
    rfe_values = np.array(list(rfe_ranking_dict.values()))
    rfe_scores = 1 / rfe_values  # ì—­ìˆ˜ë¡œ ë³€í™˜
    rfe_normalized = (rfe_scores - rfe_scores.min()) / (rfe_scores.max() - rfe_scores.min())
    normalized_scores['RFE'] = dict(zip(numeric_features, rfe_normalized))
    
    # í†µí•© ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
    weights = {'F_stat': 0.2, 'RF': 0.4, 'Lasso': 0.2, 'RFE': 0.2}
    
    ensemble_scores = {}
    for feature in numeric_features:
        total_score = 0
        for method, weight in weights.items():
            if method in normalized_scores:
                total_score += normalized_scores[method].get(feature, 0) * weight
        ensemble_scores[feature] = total_score
    
    # ìµœì¢… íŠ¹ì„± ì„ íƒ
    final_selected = sorted(ensemble_scores.items(), key=lambda x: x[1], reverse=True)[:k_best]
    final_features = [feature for feature, score in final_selected]
    
    print(f"   í†µí•© ì ìˆ˜ ê¸°ë°˜ ìµœì¢… ì„ íƒ: {len(final_features)}ê°œ")
    print(f"   ìƒìœ„ 10ê°œ íŠ¹ì„±:")
    
    for i, (feature, score) in enumerate(final_selected[:10], 1):
        print(f"      {i:2d}. {feature}: {score:.3f}")
    
    return {
        'final_features': final_features,
        'all_scores': feature_scores,
        'ensemble_scores': ensemble_scores,
        'method_features': {
            'F_statistic': f_selected_features,
            'Random_Forest': rf_selected_features,
            'Lasso': lasso_selected_features,
            'RFE': rfe_selected_features
        }
    }

# ì¢…í•© íŠ¹ì„± ì„ íƒ ì‹¤í–‰
selection_results = comprehensive_feature_selection(temporal_enhanced_data, k_best=15)

### íŠ¹ì„± ì„ íƒ ê²°ê³¼ ì‹œê°í™” ë° ê²€ì¦

```python
# íŠ¹ì„± ì„ íƒ ê²°ê³¼ ì‹œê°í™”
def visualize_feature_selection_results(selection_results, df, target_col='SalePrice'):
    """
    íŠ¹ì„± ì„ íƒ ê²°ê³¼ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì„±ëŠ¥ì„ ê²€ì¦í•˜ëŠ” í•¨ìˆ˜
    """
    print("ğŸ“Š íŠ¹ì„± ì„ íƒ ê²°ê³¼ ì‹œê°í™” ë° ê²€ì¦:")
    
    final_features = selection_results['final_features']
    ensemble_scores = selection_results['ensemble_scores']
    method_features = selection_results['method_features']
    
    # ì‹œê°í™”
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('ğŸ¯ íŠ¹ì„± ì„ íƒ ê²°ê³¼ ì¢…í•© ë¶„ì„', fontsize=16, fontweight='bold')
    
    # 1. ìµœì¢… ì„ íƒëœ íŠ¹ì„±ë“¤ì˜ ì ìˆ˜
    top_15_features = final_features[:15]
    top_15_scores = [ensemble_scores[f] for f in top_15_features]
    
    axes[0,0].barh(range(len(top_15_features)), top_15_scores, color='skyblue', alpha=0.7)
    axes[0,0].set_yticks(range(len(top_15_features)))
    axes[0,0].set_yticklabels(top_15_features, fontsize=9)
    axes[0,0].set_xlabel('í†µí•© íŠ¹ì„± ì ìˆ˜')
    axes[0,0].set_title('ìµœì¢… ì„ íƒëœ ìƒìœ„ 15ê°œ íŠ¹ì„±')
    axes[0,0].grid(True, alpha=0.3)
    
    # 2. ë°©ë²•ë³„ ì„ íƒ íŠ¹ì„± ìˆ˜ ë¹„êµ
    method_names = list(method_features.keys())
    method_counts = [len(method_features[method]) for method in method_names]
    
    bars = axes[0,1].bar(method_names, method_counts, color=['lightcoral', 'lightgreen', 'gold', 'lightblue'], alpha=0.7)
    axes[0,1].set_title('ë°©ë²•ë³„ ì„ íƒëœ íŠ¹ì„± ìˆ˜')
    axes[0,1].set_ylabel('ì„ íƒëœ íŠ¹ì„± ìˆ˜')
    axes[0,1].tick_params(axis='x', rotation=45)
    axes[0,1].grid(True, alpha=0.3)
    
    # ê°’ í‘œì‹œ
    for bar, count in zip(bars, method_counts):
        axes[0,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                       str(count), ha='center', va='bottom')
    
    # 3. ë°©ë²• ê°„ íŠ¹ì„± ê²¹ì¹¨ ë¶„ì„
    method_sets = {name: set(features) for name, features in method_features.items()}
    
    # ê° ë°©ë²•ë³„ë¡œ ë‹¤ë¥¸ ë°©ë²•ë“¤ê³¼ì˜ ê²¹ì¹¨ ë¹„ìœ¨ ê³„ì‚°
    overlap_matrix = np.zeros((len(method_names), len(method_names)))
    
    for i, method1 in enumerate(method_names):
        for j, method2 in enumerate(method_names):
            if i != j:
                intersection = len(method_sets[method1] & method_sets[method2])
                union = len(method_sets[method1] | method_sets[method2])
                overlap_matrix[i,j] = intersection / len(method_sets[method1]) if len(method_sets[method1]) > 0 else 0
    
    im = axes[1,0].imshow(overlap_matrix, cmap='Blues', aspect='auto')
    axes[1,0].set_xticks(range(len(method_names)))
    axes[1,0].set_yticks(range(len(method_names)))
    axes[1,0].set_xticklabels(method_names, rotation=45)
    axes[1,0].set_yticklabels(method_names)
    axes[1,0].set_title('ë°©ë²• ê°„ íŠ¹ì„± ê²¹ì¹¨ ë¹„ìœ¨')
    
    # ê²¹ì¹¨ ë¹„ìœ¨ í…ìŠ¤íŠ¸ í‘œì‹œ
    for i in range(len(method_names)):
        for j in range(len(method_names)):
            if i != j:
                axes[1,0].text(j, i, f'{overlap_matrix[i,j]:.2f}', 
                             ha='center', va='center', color='white' if overlap_matrix[i,j] > 0.5 else 'black')
    
    plt.colorbar(im, ax=axes[1,0])
    
    # 4. ê³µí†µìœ¼ë¡œ ì„ íƒëœ íŠ¹ì„±ë“¤
    all_selected = set()
    for features in method_features.values():
        all_selected.update(features)
    
    # ê° íŠ¹ì„±ì´ ëª‡ ê°œ ë°©ë²•ì—ì„œ ì„ íƒë˜ì—ˆëŠ”ì§€ ê³„ì‚°
    feature_vote_count = {}
    for feature in all_selected:
        vote_count = sum(1 for features in method_features.values() if feature in features)
        feature_vote_count[feature] = vote_count
    
    # íˆ¬í‘œ ìˆ˜ë³„ íŠ¹ì„± ë¶„í¬
    vote_counts = list(feature_vote_count.values())
    unique_votes, vote_distribution = np.unique(vote_counts, return_counts=True)
    
    axes[1,1].bar(unique_votes, vote_distribution, color='orange', alpha=0.7)
    axes[1,1].set_xlabel('ì„ íƒí•œ ë°©ë²• ìˆ˜')
    axes[1,1].set_ylabel('íŠ¹ì„± ê°œìˆ˜')
    axes[1,1].set_title('íŠ¹ì„±ë³„ ë°©ë²• ê°„ í•©ì˜ë„')
    axes[1,1].set_xticks(unique_votes)
    axes[1,1].grid(True, alpha=0.3)
    
    # ê°’ í‘œì‹œ
    for vote, count in zip(unique_votes, vote_distribution):
        axes[1,1].text(vote, count + 0.1, str(count), ha='center', va='bottom')
    
    plt.tight_layout()
    plt.show()
    
    # í•©ì˜ë„ê°€ ë†’ì€ íŠ¹ì„±ë“¤ (3ê°œ ì´ìƒ ë°©ë²•ì—ì„œ ì„ íƒ)
    high_consensus_features = [feature for feature, votes in feature_vote_count.items() if votes >= 3]
    
    print(f"\nğŸ¤ ë†’ì€ í•©ì˜ë„ íŠ¹ì„± ({len(high_consensus_features)}ê°œ):")
    consensus_features_sorted = sorted([(f, feature_vote_count[f]) for f in high_consensus_features], 
                                     key=lambda x: x[1], reverse=True)
    
    for feature, votes in consensus_features_sorted:
        print(f"   {feature}: {votes}/4 ë°©ë²•ì—ì„œ ì„ íƒ")
    
    return high_consensus_features

# íŠ¹ì„± ì„ íƒ ê²°ê³¼ ì‹œê°í™” ì‹¤í–‰
consensus_features = visualize_feature_selection_results(selection_results, temporal_enhanced_data)
```

**ğŸ” ì½”ë“œ í•´ì„¤:**
- **í†µí•© ì ìˆ˜**: ì—¬ëŸ¬ ë°©ë²•ì˜ ê²°ê³¼ë¥¼ ê°€ì¤‘ í‰ê· í•˜ì—¬ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íŠ¹ì„± ìˆœìœ„ ìƒì„±
- **ë°©ë²• ê°„ ê²¹ì¹¨**: ì„œë¡œ ë‹¤ë¥¸ ë°©ë²•ë“¤ì´ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
- **í•©ì˜ë„**: ì—¬ëŸ¬ ë°©ë²•ì—ì„œ ê³µí†µìœ¼ë¡œ ì„ íƒëœ íŠ¹ì„±ë“¤ì´ ë” ì•ˆì •ì 

### ìµœì¢… íŠ¹ì„± ì„¸íŠ¸ ì„±ëŠ¥ ê²€ì¦

```python
# íŠ¹ì„± ì„ íƒ íš¨ê³¼ ì„±ëŠ¥ ê²€ì¦
def validate_feature_selection_performance(df, selection_results, target_col='SalePrice'):
    """
    íŠ¹ì„± ì„ íƒì´ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ê²€ì¦
    """
    print("ğŸš€ íŠ¹ì„± ì„ íƒ ì„±ëŠ¥ ê²€ì¦:")
    
    if target_col not in df.columns:
        print(f"âš ï¸ íƒ€ê²Ÿ ë³€ìˆ˜ {target_col}ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    from sklearn.model_selection import cross_val_score
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.linear_model import LinearRegression
    from sklearn.preprocessing import StandardScaler
    
    # ë°ì´í„° ì¤€ë¹„
    y = df[target_col]
    
    # ì „ì²´ ìˆ˜ì¹˜í˜• íŠ¹ì„±
    all_numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()
    if target_col in all_numeric_features:
        all_numeric_features.remove(target_col)
    
    X_all = df[all_numeric_features].fillna(df[all_numeric_features].median())
    
    # ì„ íƒëœ íŠ¹ì„±ë“¤
    final_features = selection_results['final_features']
    available_final_features = [f for f in final_features if f in df.columns]
    X_selected = df[available_final_features].fillna(df[available_final_features].median())
    
    print(f"   ì „ì²´ íŠ¹ì„±: {X_all.shape[1]}ê°œ")
    print(f"   ì„ íƒëœ íŠ¹ì„±: {X_selected.shape[1]}ê°œ")
    print(f"   ì°¨ì› ì¶•ì†Œìœ¨: {(1 - X_selected.shape[1]/X_all.shape[1])*100:.1f}%")
    
    # ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ
    models = {
        'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),
        'LinearRegression': LinearRegression()
    }
    
    results = {}
    
    for model_name, model in models.items():
        print(f"\nğŸ¤– {model_name} ì„±ëŠ¥ ë¹„êµ:")
        
        # ì „ì²´ íŠ¹ì„± ì„±ëŠ¥
        if model_name == 'LinearRegression':
            # ì„ í˜• íšŒê·€ëŠ” ìŠ¤ì¼€ì¼ë§ í•„ìš”
            scaler = StandardScaler()
            X_all_scaled = scaler.fit_transform(X_all)
            scores_all = cross_val_score(model, X_all_scaled, y, cv=5, scoring='neg_root_mean_squared_error')
        else:
            scores_all = cross_val_score(model, X_all, y, cv=5, scoring='neg_root_mean_squared_error')
        
        rmse_all = -scores_all.mean()
        rmse_all_std = scores_all.std()
        
        # ì„ íƒëœ íŠ¹ì„± ì„±ëŠ¥
        if model_name == 'LinearRegression':
            X_selected_scaled = scaler.fit_transform(X_selected)
            scores_selected = cross_val_score(model, X_selected_scaled, y, cv=5, scoring='neg_root_mean_squared_error')
        else:
            scores_selected = cross_val_score(model, X_selected, y, cv=5, scoring='neg_root_mean_squared_error')
        
        rmse_selected = -scores_selected.mean()
        rmse_selected_std = scores_selected.std()
        
        # ì„±ëŠ¥ ë³€í™” ê³„ì‚°
        performance_change = ((rmse_all - rmse_selected) / rmse_all) * 100
        
        results[model_name] = {
            'rmse_all': rmse_all,
            'rmse_selected': rmse_selected,
            'std_all': rmse_all_std,
            'std_selected': rmse_selected_std,
            'improvement': performance_change
        }
        
        print(f"   ì „ì²´ íŠ¹ì„± RMSE: ${rmse_all:,.0f} (Â±${rmse_all_std:,.0f})")
        print(f"   ì„ íƒ íŠ¹ì„± RMSE: ${rmse_selected:,.0f} (Â±${rmse_selected_std:,.0f})")
        
        if performance_change > 0:
            print(f"   ğŸ“ˆ ì„±ëŠ¥ ê°œì„ : {performance_change:.1f}% í–¥ìƒ")
        elif performance_change < -5:  # 5% ì´ìƒ ì„±ëŠ¥ ì €í•˜
            print(f"   ğŸ“‰ ì„±ëŠ¥ ì €í•˜: {abs(performance_change):.1f}% ê°ì†Œ")
        else:
            print(f"   â¡ï¸  ì„±ëŠ¥ ìœ ì§€: {abs(performance_change):.1f}% ì°¨ì´")
    
    # ê²°ê³¼ ì‹œê°í™”
    plt.figure(figsize=(12, 6))
    
    model_names = list(results.keys())
    rmse_all_values = [results[name]['rmse_all'] for name in model_names]
    rmse_selected_values = [results[name]['rmse_selected'] for name in model_names]
    std_all_values = [results[name]['std_all'] for name in model_names]
    std_selected_values = [results[name]['std_selected'] for name in model_names]
    
    x = np.arange(len(model_names))
    width = 0.35
    
    plt.errorbar(x - width/2, rmse_all_values, yerr=std_all_values, 
                fmt='o', capsize=5, capthick=2, label='ì „ì²´ íŠ¹ì„±', color='skyblue', markersize=8)
    plt.errorbar(x + width/2, rmse_selected_values, yerr=std_selected_values, 
                fmt='s', capsize=5, capthick=2, label='ì„ íƒëœ íŠ¹ì„±', color='lightcoral', markersize=8)
    
    plt.ylabel('RMSE ($)')
    plt.title('ğŸ¯ íŠ¹ì„± ì„ íƒ íš¨ê³¼: ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n(ì˜¤ì°¨ ë§‰ëŒ€ëŠ” í‘œì¤€í¸ì°¨)')
    plt.xticks(x, model_names)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # ê°œì„  íš¨ê³¼ í‘œì‹œ
    for i, model_name in enumerate(model_names):
        improvement = results[model_name]['improvement']
        color = 'green' if improvement > 0 else 'red' if improvement < -5 else 'orange'
        plt.text(i, max(rmse_all_values + rmse_selected_values) * 0.95, 
                f'{improvement:+.1f}%', ha='center', va='bottom', 
                color=color, fontweight='bold', fontsize=10)
    
    plt.tight_layout()
    plt.show()
    
    # ìµœì¢… ê¶Œê³ ì‚¬í•­
    print(f"\nğŸ’¡ íŠ¹ì„± ì„ íƒ ê¶Œê³ ì‚¬í•­:")
    
    avg_improvement = np.mean([results[name]['improvement'] for name in model_names])
    
    if avg_improvement > 5:
        print(f"   âœ… íŠ¹ì„± ì„ íƒ íš¨ê³¼ ìš°ìˆ˜: í‰ê·  {avg_improvement:.1f}% ì„±ëŠ¥ í–¥ìƒ")
        print(f"   ğŸ“ ê¶Œê³ : ì„ íƒëœ {len(available_final_features)}ê°œ íŠ¹ì„± ì‚¬ìš© ì¶”ì²œ")
    elif avg_improvement > 0:
        print(f"   âœ… íŠ¹ì„± ì„ íƒ íš¨ê³¼ ì–‘í˜¸: í‰ê·  {avg_improvement:.1f}% ì„±ëŠ¥ í–¥ìƒ")
        print(f"   ğŸ“ ê¶Œê³ : íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì˜ ê· í˜•ì  í™•ë³´")
    elif avg_improvement > -5:
        print(f"   â¡ï¸  íŠ¹ì„± ì„ íƒ íš¨ê³¼ ì¤‘ë¦½: í‰ê·  {abs(avg_improvement):.1f}% ì°¨ì´")
        print(f"   ğŸ“ ê¶Œê³ : ê³„ì‚° íš¨ìœ¨ì„±ì„ ìœ„í•´ ì„ íƒëœ íŠ¹ì„± ì‚¬ìš© ê°€ëŠ¥")
    else:
        print(f"   âš ï¸  íŠ¹ì„± ì„ íƒ íš¨ê³¼ ë¶€ì •ì : í‰ê·  {abs(avg_improvement):.1f}% ì„±ëŠ¥ ì €í•˜")
        print(f"   ğŸ“ ê¶Œê³ : íŠ¹ì„± ì„ íƒ ê¸°ì¤€ ì¬ê²€í†  í•„ìš”")
    
    print(f"\nğŸ” ì„ íƒëœ ìµœì¢… íŠ¹ì„± ëª©ë¡:")
    for i, feature in enumerate(available_final_features[:10], 1):
        score = selection_results['ensemble_scores'].get(feature, 0)
        print(f"   {i:2d}. {feature} (ì ìˆ˜: {score:.3f})")
    
    if len(available_final_features) > 10:
        print(f"   ... ì™¸ {len(available_final_features)-10}ê°œ íŠ¹ì„±")
    
    return results, available_final_features

# ì„±ëŠ¥ ê²€ì¦ ì‹¤í–‰
performance_results, final_feature_list = validate_feature_selection_performance(
    temporal_enhanced_data, selection_results)
```

**ğŸ” ì½”ë“œ í•´ì„¤:**
- **êµì°¨ ê²€ì¦**: 5-fold CVë¡œ íŠ¹ì„± ì„ íƒ íš¨ê³¼ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì¸¡ì •
- **ë‹¤ì¤‘ ëª¨ë¸ ê²€ì¦**: ì„œë¡œ ë‹¤ë¥¸ íŠ¹ì„±ì˜ ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì¼ê´€ëœ íš¨ê³¼ í™•ì¸
- **í†µê³„ì  ìœ ì˜ì„±**: ì˜¤ì°¨ ë§‰ëŒ€ë¥¼ í†µí•´ ì„±ëŠ¥ ì°¨ì´ì˜ ì‹ ë¢°ë„ í‘œì‹œ

---

## ğŸ¯ ì§ì ‘ í•´ë³´ê¸° - ì—°ìŠµ ë¬¸ì œ

### ì—°ìŠµ ë¬¸ì œ 1: ì°½ì˜ì  íŠ¹ì„± ìƒì„± â­â­
ë¶€ë™ì‚° ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ìƒˆë¡œìš´ íŠ¹ì„±ì„ ì°½ì¡°í•´ë³´ì„¸ìš”.

```python
# ì—°ìŠµ ë¬¸ì œ 1: ì°½ì˜ì  íŠ¹ì„± ìƒì„±
def exercise_creative_features(df):
    """
    ì°½ì˜ì ì´ê³  ì˜ë¯¸ìˆëŠ” ìƒˆë¡œìš´ íŠ¹ì„± ìƒì„±
    """
    # TODO: ë‹¤ìŒ ì•„ì´ë””ì–´ë“¤ì„ êµ¬í˜„í•´ë³´ì„¸ìš”
    # 1. 'LifestyleScore': ìˆ˜ì˜ì¥, ë²½ë‚œë¡œ, ë‹¤ì¸µêµ¬ì¡° ë“±ì„ ì¢…í•©í•œ ë¼ì´í”„ìŠ¤íƒ€ì¼ ì ìˆ˜
    # 2. 'MaintenanceIndex': ì£¼íƒ ì—°ë ¹, ìƒíƒœ, ë¦¬ëª¨ë¸ë§ ì´ë ¥ì„ ì¢…í•©í•œ ìœ ì§€ë³´ìˆ˜ í•„ìš”ë„
    # 3. 'LocationValue': ëŒ€ì§€ ë©´ì ê³¼ ê±´ë¬¼ ë°€ë„ë¥¼ ì¡°í•©í•œ ì…ì§€ ê°€ì¹˜ ì§€ìˆ˜
    # 4. 'FutureProofing': ìµœì‹  ê±´ì¶•/ë¦¬ëª¨ë¸ë§ ì—¬ë¶€ì™€ í’ˆì§ˆì„ ì¡°í•©í•œ ë¯¸ë˜ ê°€ì¹˜ ì§€ìˆ˜
    
    new_features = {}
    
    # ì—¬ê¸°ì— ì°½ì˜ì ì¸ íŠ¹ì„± ìƒì„± ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”
    
    return new_features

# íŒíŠ¸: 
# - ì—¬ëŸ¬ ë³€ìˆ˜ë¥¼ ì¡°í•©í•  ë•ŒëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ì  ì˜ë¯¸ë¥¼ ë¨¼ì € ìƒê°í•˜ì„¸ìš”
# - ê°€ì¤‘ í‰ê· , ê³±ì…ˆ, ì¡°ê±´ë¶€ ì ìˆ˜ ë“± ë‹¤ì–‘í•œ ë°©ë²•ì„ ì‹œë„í•´ë³´ì„¸ìš”
# - ìƒì„±í•œ íŠ¹ì„±ì´ SalePriceì™€ ì–¼ë§ˆë‚˜ ìƒê´€ê´€ê³„ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”
```

### ì—°ìŠµ ë¬¸ì œ 2: íŠ¹ì„± ìƒí˜¸ì‘ìš© ë¶„ì„ â­â­â­
ë‘ ë³€ìˆ˜ ê°„ì˜ ìƒí˜¸ì‘ìš© íš¨ê³¼ë¥¼ íƒì§€í•˜ê³  í™œìš©í•´ë³´ì„¸ìš”.

```python
# ì—°ìŠµ ë¬¸ì œ 2: íŠ¹ì„± ìƒí˜¸ì‘ìš© ë¶„ì„
def exercise_interaction_analysis(df, target_col='SalePrice'):
    """
    íŠ¹ì„± ê°„ ìƒí˜¸ì‘ìš© íš¨ê³¼ë¥¼ ë¶„ì„í•˜ê³  í™œìš©í•˜ëŠ” í•¨ìˆ˜
    """
    # TODO: ë‹¤ìŒ ë‹¨ê³„ë¥¼ êµ¬í˜„í•˜ì„¸ìš”
    # 1. ìƒìœ„ 5ê°œ ì¤‘ìš” íŠ¹ì„±ë“¤ ê°„ì˜ ëª¨ë“  2-way ìƒí˜¸ì‘ìš© ìƒì„±
    # 2. ê° ìƒí˜¸ì‘ìš© íŠ¹ì„±ì˜ íƒ€ê²Ÿ ë³€ìˆ˜ì™€ì˜ ìƒê´€ê´€ê³„ ê³„ì‚°
    # 3. ê°œë³„ íŠ¹ì„±ì˜ ìƒê´€ê´€ê³„ í•©ë³´ë‹¤ ë†’ì€ ìƒí˜¸ì‘ìš© íŠ¹ì„± ë°œê²¬
    # 4. ì‹œê°í™”ë¥¼ í†µí•´ ìƒí˜¸ì‘ìš© íš¨ê³¼ ê²€ì¦
    
    interactions = {}
    
    # ì—¬ê¸°ì— ìƒí˜¸ì‘ìš© ë¶„ì„ ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”
    
    return interactions

# íŒíŠ¸:
# - itertools.combinationsë¥¼ ì‚¬ìš©í•´ íŠ¹ì„± ìŒì„ ìƒì„±í•˜ì„¸ìš”
# - ê³±ì…ˆ ìƒí˜¸ì‘ìš© ì™¸ì—ë„ ë‚˜ëˆ—ì…ˆ, ì°¨ì´ ë“±ì„ ì‹œë„í•´ë³´ì„¸ìš”
# - 3D ì‚°ì ë„ë‚˜ íˆíŠ¸ë§µìœ¼ë¡œ ìƒí˜¸ì‘ìš©ì„ ì‹œê°í™”í•´ë³´ì„¸ìš”
```

### ì—°ìŠµ ë¬¸ì œ 3: ë§ì¶¤í˜• íŠ¹ì„± ì„ íƒê¸° êµ¬í˜„ â­â­â­â­
ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì— ë§ëŠ” íŠ¹ì„± ì„ íƒ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•´ë³´ì„¸ìš”.

```python
# ì—°ìŠµ ë¬¸ì œ 3: ë§ì¶¤í˜• íŠ¹ì„± ì„ íƒê¸° êµ¬í˜„
def exercise_custom_selector(df, target_col='SalePrice', business_goal='accuracy'):
    """
    ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì— ë”°ë¥¸ ë§ì¶¤í˜• íŠ¹ì„± ì„ íƒ ì‹œìŠ¤í…œ
    
    Parameters:
    business_goal: 'accuracy' (ì •í™•ë„ ìš°ì„ ), 'interpretability' (í•´ì„ì„± ìš°ì„ ), 
                   'efficiency' (íš¨ìœ¨ì„± ìš°ì„ )
    """
    # TODO: ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì— ë”°ë¼ ë‹¤ë¥¸ ì„ íƒ ê¸°ì¤€ ì ìš©
    # 'accuracy': ì„±ëŠ¥ ìµœìš°ì„ , ë³µì¡í•œ íŠ¹ì„±ë„ í—ˆìš©
    # 'interpretability': ì´í•´í•˜ê¸° ì‰¬ìš´ íŠ¹ì„± ìš°ì„ , ì›ë³¸ íŠ¹ì„± ì„ í˜¸
    # 'efficiency': ìµœì†Œí•œì˜ íŠ¹ì„±ìœ¼ë¡œ ìµœëŒ€ íš¨ê³¼, ê³„ì‚° ë¹„ìš© ê³ ë ¤
    
    selector_config = {}
    selected_features = []
    
    # ì—¬ê¸°ì— ë§ì¶¤í˜• ì„ íƒê¸° ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”
    
    return selected_features, selector_config

# íŒíŠ¸:
# - ê° ëª©í‘œë³„ë¡œ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ì™€ ì œì•½ ì¡°ê±´ì„ ì„¤ì •í•˜ì„¸ìš”
# - íŠ¹ì„±ì˜ ë³µì¡ë„, ê³„ì‚° ë¹„ìš©, í•´ì„ ê°€ëŠ¥ì„±ì„ ì ìˆ˜í™”í•´ë³´ì„¸ìš”
# - íŒŒë ˆí†  ìµœì í™” ê°œë…ì„ í™œìš©í•´ë³´ì„¸ìš”
```

---

## ğŸ“š í•µì‹¬ ì •ë¦¬

ì´ë²ˆ Partì—ì„œ ë°°ìš´ í•µì‹¬ ë‚´ìš©ì„ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

### âœ… íŠ¹ì„± ê³µí•™ í•µì‹¬ í¬ì¸íŠ¸

1. **ë„ë©”ì¸ ì§€ì‹ í™œìš©**: í•´ë‹¹ ë¶„ì•¼ì˜ ì „ë¬¸ ì§€ì‹ì´ ê°€ì¥ ê°•ë ¥í•œ íŠ¹ì„± ìƒì„± ë„êµ¬
2. **ìˆ˜í•™ì  ì¡°í•©**: ë¹„ìœ¨, ì°¨ì´, ê³±ì…ˆ, ê±°ë“­ì œê³± ë“±ìœ¼ë¡œ ìˆ¨ê²¨ì§„ ê´€ê³„ ë°œê²¬
3. **ì‹œê°„ ê¸°ë°˜ íŠ¹ì„±**: ì‹œê°„ì˜ íë¦„ê³¼ ì£¼ê¸°ì„±ì„ í™œìš©í•œ íŒ¨í„´ ì¶”ì¶œ
4. **íŠ¹ì„± ì„ íƒ**: ì°¨ì›ì˜ ì €ì£¼ ë°©ì§€ì™€ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ì²´ê³„ì  ì„ ë³„

### âœ… ì‹¤ë¬´ íŠ¹ì„± ê³µí•™ ì›ì¹™

1. **ì˜ë¯¸ ìš°ì„ **: í†µê³„ì  ìƒê´€ê´€ê³„ë³´ë‹¤ ë¹„ì¦ˆë‹ˆìŠ¤ì  ì˜ë¯¸ê°€ ì¤‘ìš”
2. **ê²€ì¦ í•„ìˆ˜**: ìƒˆë¡œìš´ íŠ¹ì„±ì€ ë°˜ë“œì‹œ ì„±ëŠ¥ ê°œì„  íš¨ê³¼ í™•ì¸
3. **ê³¼ì í•© ì£¼ì˜**: ë„ˆë¬´ ë³µì¡í•œ íŠ¹ì„±ì€ ì¼ë°˜í™” ì„±ëŠ¥ ì €í•˜ ìœ„í—˜
4. **í•´ì„ ê°€ëŠ¥ì„±**: ëª¨ë¸ ê²°ê³¼ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” íŠ¹ì„± ì„ í˜¸

### âœ… íŠ¹ì„± ìœ í˜•ë³„ í™œìš© ê°€ì´ë“œ

- **ë¹„ìœ¨ íŠ¹ì„±**: ì„œë¡œ ë‹¤ë¥¸ ë‹¨ìœ„ì˜ ë³€ìˆ˜ ë¹„êµ (ë°€ë„, íš¨ìœ¨ì„±)
- **ì°¨ì´ íŠ¹ì„±**: ìƒëŒ€ì  ë³€í™”ë‚˜ ê²©ì°¨ í‘œí˜„ (ì—°ë ¹, í’ˆì§ˆ ì°¨ì´)
- **ê³±ì…ˆ íŠ¹ì„±**: ìƒí˜¸ì‘ìš© íš¨ê³¼ í¬ì°© (í¬ê¸° Ã— í’ˆì§ˆ)
- **ì‹œê°„ íŠ¹ì„±**: ì£¼ê¸°ì„±, íŠ¸ë Œë“œ, ë…¸í›„í™” ë°˜ì˜
- **ë³µí•© ì§€ìˆ˜**: ì—¬ëŸ¬ ì¸¡ë©´ì„ ì¢…í•©í•œ í†µí•© ì ìˆ˜

### ğŸ’¡ ì‹¤ë¬´ ì ìš© íŒ

- **ë°˜ë³µì  ì ‘ê·¼**: íŠ¹ì„± ìƒì„± â†’ ê²€ì¦ â†’ ê°œì„ ì˜ ìˆœí™˜ ê³¼ì •
- **í˜‘ì—… ì¤‘ìš”ì„±**: ë„ë©”ì¸ ì „ë¬¸ê°€ì™€ì˜ ê¸´ë°€í•œ í˜‘ë ¥
- **ë¬¸ì„œí™”**: íŠ¹ì„±ì˜ ì •ì˜ì™€ ìƒì„± ë…¼ë¦¬ë¥¼ ëª…í™•íˆ ê¸°ë¡
- **ë²„ì „ ê´€ë¦¬**: íŠ¹ì„± ì„¸íŠ¸ì˜ ë³€í™”ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬

---

## ğŸ¤” ìƒê°í•´ë³´ê¸°

1. **ë„ë©”ì¸ ì§€ì‹ì˜ ê°€ì¹˜**: ë¶€ë™ì‚° ì „ë¬¸ê°€ê°€ ì§ê´€ì ìœ¼ë¡œ ì•„ëŠ” ê²ƒë“¤ì„ ì–´ë–»ê²Œ ë°ì´í„° íŠ¹ì„±ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆì„ê¹Œìš”? ë‹¤ë¥¸ ë„ë©”ì¸(ì˜ë£Œ, ê¸ˆìœµ, ì œì¡°ì—…)ì—ì„œëŠ” ì–´ë–¤ íŠ¹ì„±ë“¤ì´ ì¤‘ìš”í• ê¹Œìš”?

2. **íŠ¹ì„±ì˜ ìƒëª…ì£¼ê¸°**: ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ íŠ¹ì„±ì˜ ì¤‘ìš”ë„ê°€ ë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŒ¬ë°ë¯¹ìœ¼ë¡œ ì¸í•´ í™ˆì˜¤í”¼ìŠ¤ ê³µê°„ì´ ì¤‘ìš”í•´ì¡Œë“¯ì´, ë¯¸ë˜ì—ëŠ” ì–´ë–¤ íŠ¹ì„±ë“¤ì´ ì¤‘ìš”í•´ì§ˆê¹Œìš”?

3. **ìë™í™” vs ìˆ˜ë™**: AIê°€ ìë™ìœ¼ë¡œ íŠ¹ì„±ì„ ìƒì„±í•˜ëŠ” ë„êµ¬ë“¤ì´ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì¸ê°„ì˜ ì°½ì˜ì„±ê³¼ ë„ë©”ì¸ ì§€ì‹ì€ ì—¬ì „íˆ ì¤‘ìš”í• ê¹Œìš”? ë‘˜ì˜ ìµœì  ì¡°í•©ì€ ë¬´ì—‡ì¼ê¹Œìš”?

---

## ğŸ”œ ë‹¤ìŒ Part ì˜ˆê³ : AI ë„êµ¬ë¥¼ í™œìš©í•œ ìë™ ì „ì²˜ë¦¬ì™€ í•œê³„ì 

ë‹¤ìŒ Partì—ì„œëŠ” AI ê¸°ìˆ ì„ í™œìš©í•œ **ìë™í™”ëœ ì „ì²˜ë¦¬ ë„êµ¬**ë“¤ì„ ì‚´í´ë³´ê³ , ê·¸ ì¥ì ê³¼ í•œê³„ì ì„ ë¶„ì„í•©ë‹ˆë‹¤:

- **AutoML ì „ì²˜ë¦¬ ë„êµ¬**: H2O.ai, DataRobot, Google AutoML ë“±ì˜ ìë™ ì „ì²˜ë¦¬ ê¸°ëŠ¥
- **AI ê¸°ë°˜ íŠ¹ì„± ìƒì„±**: Featuretools, AutoFeat ë“± ìë™ íŠ¹ì„± ê³µí•™ ë¼ì´ë¸ŒëŸ¬ë¦¬
- **ì§€ëŠ¥í˜• ë°ì´í„° í´ë¦¬ë‹**: ê²°ì¸¡ì¹˜, ì´ìƒì¹˜, ë¶ˆì¼ì¹˜ ë°ì´í„°ì˜ ìë™ íƒì§€ ë° ì²˜ë¦¬
- **ì¸ê°„-AI í˜‘ì—…**: ìë™í™” ë„êµ¬ì™€ ë„ë©”ì¸ ì „ë¬¸ê°€ì˜ íš¨ê³¼ì  ê²°í•© ë°©ë²•
- **í•œê³„ì ê³¼ ì£¼ì˜ì‚¬í•­**: ë¸”ë™ë°•ìŠ¤ ë¬¸ì œ, í¸í–¥ì„±, ê³¼ì í•© ë“±ì˜ ìœ„í—˜ ìš”ì†Œ

AIì˜ í˜ì„ í™œìš©í•˜ë©´ì„œë„ ê·¸ í•œê³„ë¥¼ ì •í™•íˆ ì´í•´í•˜ì—¬, **ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**ì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ë°°ì›Œë³´ê² ìŠµë‹ˆë‹¤!

---

*"íŠ¹ì„± ê³µí•™ì€ ë°ì´í„°ì— ìƒëª…ì„ ë¶ˆì–´ë„£ëŠ” ì˜ˆìˆ ì…ë‹ˆë‹¤. ìˆ«ì ë’¤ì— ìˆ¨ê²¨ì§„ ì´ì•¼ê¸°ë¥¼ ì°¾ì•„ë‚´ê³ , ëª¨ë¸ì´ ì„¸ìƒì„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ì°½ì¡°ì  ê³¼ì •ì…ë‹ˆë‹¤."*
```

**ğŸ” ì½”ë“œ í•´ì„¤:**
- **F-í†µê³„ëŸ‰**: ê° íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë³€ìˆ˜ ê°„ì˜ ì„ í˜• ê´€ê³„ ê°•ë„ ì¸¡ì •
- **Random Forest**: íŠ¸ë¦¬ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì˜ íŠ¹ì„± ì¤‘ìš”ë„ í™œìš©
- **Lasso**: L1 ì •ê·œí™”ë¡œ ë¶ˆí•„ìš”í•œ íŠ¹ì„±ì˜ ê³„ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¦
- **RFE**: ì¬ê·€ì ìœ¼ë¡œ ê°€ì¥ ì¤‘ìš”í•˜ì§€ ì•Šì€ íŠ¹ì„±ì„ ì œê±°
- **ì•™ìƒë¸” ë°©ì‹**: ì—¬ëŸ¬ ë°©ë²•ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë” ì•ˆì •ì ì¸ ì„ íƒ

---

> **ğŸ“Š ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸:**  
> "Create a comprehensive feature selection performance comparison visualization showing: 1) A side-by-side comparison of model performance (RMSE and RÂ² scores) before and after feature selection for RandomForest and LinearRegression models, 2) Error bars showing standard deviation, 3) Percentage improvement indicators, 4) A summary table showing the number of features before and after selection with dimensionality reduction percentage. Use professional styling with clear legends, value labels, and green/red color coding for improvements/degradations."

---

*"ë°ì´í„°ì˜ ê°€ì¹˜ëŠ” ìš°ë¦¬ê°€ ê·¸ ì†ì—ì„œ ë°œê²¬í•˜ëŠ” íŠ¹ì„±ì˜ ì§ˆì— ë‹¬ë ¤ ìˆìŠµë‹ˆë‹¤. ì¢‹ì€ íŠ¹ì„± ê³µí•™ì€ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ì˜ ì ˆë°˜ì…ë‹ˆë‹¤."*: ê° íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë³€ìˆ˜ ê°„ì˜ ì„ í˜• ê´€ê³„ ê°•ë„ ì¸¡ì •
- **Random Forest**: íŠ¸ë¦¬ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì˜ íŠ¹ì„± ì¤‘ìš”ë„ í™œìš©
- **Lasso**: L1 ì •ê·œí™”ë¡œ ë¶ˆí•„ìš”í•œ íŠ¹ì„±ì˜ ê³„ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¦
- **RFE**: ì¬ê·€ì ìœ¼ë¡œ ê°€ì¥ ì¤‘ìš”í•˜ì§€ ì•Šì€ íŠ¹ì„±ì„ ì œê±°
- **ì•™ìƒë¸” ë°©ì‹**: ì—¬ëŸ¬ ë°©ë²•ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë” ì•ˆì •ì ì¸ ì„ íƒ
```

**ğŸ” ì½”ë“œ í•´ì„¤:**
- ê° íŠ¹ì„±ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ì  ì˜ë¯¸ë¥¼ ëª…í™•íˆ ì •ì˜í•˜ê³  ìƒê´€ê´€ê³„ë¡œ ê²€ì¦
- íŠ¹ì„± ê°„ ì‹œë„ˆì§€ íš¨ê³¼ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ì¸¡ì •
- ì‹œê°í™”ë¥¼ í†µí•´ íŠ¹ì„±ë“¤ì˜ ìƒëŒ€ì  ì¤‘ìš”ë„ë¥¼ í•œëˆˆì— íŒŒì•…

---

## ğŸ¯ ì§ì ‘ í•´ë³´ê¸° - ì—°ìŠµ ë¬¸ì œ

### ì—°ìŠµ ë¬¸ì œ 1: ì°½ì˜ì  íŠ¹ì„± ìƒì„± â­â­
ë¶€ë™ì‚° ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ìƒˆë¡œìš´ íŠ¹ì„±ì„ ì°½ì¡°í•´ë³´ì„¸ìš”.

```python
# ì—°ìŠµ ë¬¸ì œ 1: ì°½ì˜ì  íŠ¹ì„± ìƒì„±
def exercise_creative_features(df):
    """
    ì°½ì˜ì ì´ê³  ì˜ë¯¸ìˆëŠ” ìƒˆë¡œìš´ íŠ¹ì„± ìƒì„±
    
    TODO: ë‹¤ìŒ ì•„ì´ë””ì–´ë“¤ì„ êµ¬í˜„í•´ë³´ì„¸ìš”
    1. 'LifestyleScore': ìˆ˜ì˜ì¥, ë²½ë‚œë¡œ, ë‹¤ì¸µêµ¬ì¡° ë“±ì„ ì¢…í•©í•œ ë¼ì´í”„ìŠ¤íƒ€ì¼ ì ìˆ˜
    2. 'MaintenanceIndex': ì£¼íƒ ì—°ë ¹, ìƒíƒœ, ë¦¬ëª¨ë¸ë§ ì´ë ¥ì„ ì¢…í•©í•œ ìœ ì§€ë³´ìˆ˜ í•„ìš”ë„
    3. 'LocationValue': ëŒ€ì§€ ë©´ì ê³¼ ê±´ë¬¼ ë°€ë„ë¥¼ ì¡°í•©í•œ ì…ì§€ ê°€ì¹˜ ì§€ìˆ˜
    4. 'FutureProofing': ìµœì‹  ê±´ì¶•/ë¦¬ëª¨ë¸ë§ ì—¬ë¶€ì™€ í’ˆì§ˆì„ ì¡°í•©í•œ ë¯¸ë˜ ê°€ì¹˜ ì§€ìˆ˜
    """
    
    new_features = {}
    df_creative = df.copy()
    
    # 1. LifestyleScore (ë¼ì´í”„ìŠ¤íƒ€ì¼ ì ìˆ˜)
    # íŒíŠ¸: Fireplaces, PoolQC, IsMultiStory ë“±ì„ í™œìš©
    lifestyle_components = []
    
    if 'Fireplaces' in df.columns:
        lifestyle_components.append('Fireplaces')
    if 'IsMultiStory' in df.columns:
        lifestyle_components.append('IsMultiStory') 
    # TODO: í’€ì¥, ì°¨ê³ , ë°í¬ ë“± ì¶”ê°€ ë¼ì´í”„ìŠ¤íƒ€ì¼ ìš”ì†Œ ê³ ë ¤
    
    if len(lifestyle_components) > 0:
        # TODO: ê°€ì¤‘ í‰ê· ìœ¼ë¡œ LifestyleScore ê³„ì‚°
        # ì˜ˆ: ë²½ë‚œë¡œ 30%, ë‹¤ì¸µêµ¬ì¡° 20%, ê¸°íƒ€ 50%
        pass
    
    # 2. MaintenanceIndex (ìœ ì§€ë³´ìˆ˜ í•„ìš”ë„)
    # íŒíŠ¸: ì—°ë ¹ì´ ë†’ê³ , ìƒíƒœê°€ ë‚˜ì˜ê³ , ë¦¬ëª¨ë¸ë§ì„ ì•ˆ í–ˆìœ¼ë©´ ë†’ì€ ì ìˆ˜
    if 'HouseAge' in df.columns and 'OverallCond' in df.columns:
        # TODO: ì—°ë ¹, ìƒíƒœ, ë¦¬ëª¨ë¸ë§ ì´ë ¥ì„ ì¢…í•©í•œ ì ìˆ˜
        pass
    
    # 3. LocationValue (ì…ì§€ ê°€ì¹˜ ì§€ìˆ˜)
    # íŒíŠ¸: ëŒ€ì§€ í™œìš©ë„, ì£¼ë³€ ì‹œì„¤ ì ‘ê·¼ì„± ë“±
    if 'LotAreaRatio' in df.columns:
        # TODO: ì…ì§€ ê´€ë ¨ ìš”ì†Œë“¤ì„ ì¢…í•©í•œ ê°€ì¹˜ ì§€ìˆ˜
        pass
    
    # 4. FutureProofing (ë¯¸ë˜ ê°€ì¹˜ ì§€ìˆ˜)
    # íŒíŠ¸: ìµœì‹ ì„±, ì§€ì†ê°€ëŠ¥ì„±, í™•ì¥ ê°€ëŠ¥ì„± ë“±
    if 'RecentRemodel' in df.columns and 'OverallQual' in df.columns:
        # TODO: ë¯¸ë˜ ê°€ì¹˜ë¥¼ í‰ê°€í•˜ëŠ” ë³µí•© ì§€ìˆ˜
        pass
    
    print("ğŸ’¡ ì°½ì˜ì  íŠ¹ì„± ìƒì„± ì™„ë£Œ!")
    print("ê° íŠ¹ì„±ì„ SalePriceì™€ ìƒê´€ê´€ê³„ë¥¼ í™•ì¸í•´ íš¨ê³¼ë¥¼ ê²€ì¦í•˜ì„¸ìš”.")
    
    return new_features

# íŒíŠ¸: 
# - ì—¬ëŸ¬ ë³€ìˆ˜ë¥¼ ì¡°í•©í•  ë•ŒëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ì  ì˜ë¯¸ë¥¼ ë¨¼ì € ìƒê°í•˜ì„¸ìš”
# - ê°€ì¤‘ í‰ê· , ê³±ì…ˆ, ì¡°ê±´ë¶€ ì ìˆ˜ ë“± ë‹¤ì–‘í•œ ë°©ë²•ì„ ì‹œë„í•´ë³´ì„¸ìš”
# - ìƒì„±í•œ íŠ¹ì„±ì´ SalePriceì™€ ì–¼ë§ˆë‚˜ ìƒê´€ê´€ê³„ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”
```

### ì—°ìŠµ ë¬¸ì œ 2: íŠ¹ì„± ìƒí˜¸ì‘ìš© ë¶„ì„ â­â­â­
ë‘ ë³€ìˆ˜ ê°„ì˜ ìƒí˜¸ì‘ìš© íš¨ê³¼ë¥¼ íƒì§€í•˜ê³  í™œìš©í•´ë³´ì„¸ìš”.

```python
# ì—°ìŠµ ë¬¸ì œ 2: íŠ¹ì„± ìƒí˜¸ì‘ìš© ë¶„ì„
def exercise_interaction_analysis(df, target_col='SalePrice'):
    """
    íŠ¹ì„± ê°„ ìƒí˜¸ì‘ìš© íš¨ê³¼ë¥¼ ë¶„ì„í•˜ê³  í™œìš©í•˜ëŠ” í•¨ìˆ˜
    
    TODO: ë‹¤ìŒ ë‹¨ê³„ë¥¼ êµ¬í˜„í•˜ì„¸ìš”
    1. ìƒìœ„ 5ê°œ ì¤‘ìš” íŠ¹ì„±ë“¤ ê°„ì˜ ëª¨ë“  2-way ìƒí˜¸ì‘ìš© ìƒì„±
    2. ê° ìƒí˜¸ì‘ìš© íŠ¹ì„±ì˜ íƒ€ê²Ÿ ë³€ìˆ˜ì™€ì˜ ìƒê´€ê´€ê³„ ê³„ì‚°
    3. ê°œë³„ íŠ¹ì„±ì˜ ìƒê´€ê´€ê³„ í•©ë³´ë‹¤ ë†’ì€ ìƒí˜¸ì‘ìš© íŠ¹ì„± ë°œê²¬
    4. ì‹œê°í™”ë¥¼ í†µí•´ ìƒí˜¸ì‘ìš© íš¨ê³¼ ê²€ì¦
    """
    
    interactions = {}
    
    # 1. ì¤‘ìš” íŠ¹ì„± ì„ ë³„
    # íŒíŠ¸: ì´ì „ì— ê³„ì‚°í•œ feature_correlationsì„ í™œìš©
    if target_col not in df.columns:
        print(f"âš ï¸ {target_col} ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ìˆ˜ì¹˜í˜• íŠ¹ì„±ë§Œ ì„ íƒ
    numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()
    if target_col in numeric_features:
        numeric_features.remove(target_col)
    
    # TODO: ìƒìœ„ 5ê°œ íŠ¹ì„± ì„ íƒ
    top_features = numeric_features[:5]  # ì„ì‹œë¡œ ì²˜ìŒ 5ê°œ
    
    # 2. ìƒí˜¸ì‘ìš© íŠ¹ì„± ìƒì„±
    from itertools import combinations
    
    for feat1, feat2 in combinations(top_features, 2):
        if feat1 in df.columns and feat2 in df.columns:
            # TODO: ë‹¤ì–‘í•œ ìƒí˜¸ì‘ìš© ì‹œë„
            # ê³±ì…ˆ ìƒí˜¸ì‘ìš©
            interaction_name = f"{feat1}_x_{feat2}"
            # interactions[interaction_name] = df[feat1] * df[feat2]
            
            # ë‚˜ëˆ—ì…ˆ ìƒí˜¸ì‘ìš© (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
            ratio_name = f"{feat1}_div_{feat2}"
            # interactions[ratio_name] = df[feat1] / (df[feat2] + 1)
            
            # ì°¨ì´ ìƒí˜¸ì‘ìš©
            diff_name = f"{feat1}_diff_{feat2}"
            # interactions[diff_name] = df[feat1] - df[feat2]
    
    # 3. ìƒí˜¸ì‘ìš© íš¨ê³¼ í‰ê°€
    # TODO: ê° ìƒí˜¸ì‘ìš© íŠ¹ì„±ê³¼ íƒ€ê²Ÿì˜ ìƒê´€ê´€ê³„ ê³„ì‚°
    # TODO: ê°œë³„ íŠ¹ì„± ëŒ€ë¹„ ê°œì„  íš¨ê³¼ ì¸¡ì •
    
    # 4. ì‹œê°í™”
    # TODO: ìƒìœ„ ìƒí˜¸ì‘ìš© íŠ¹ì„±ë“¤ì˜ ì‚°ì ë„ ìƒì„±
    # TODO: íˆíŠ¸ë§µìœ¼ë¡œ ìƒí˜¸ì‘ìš© ë§¤íŠ¸ë¦­ìŠ¤ í‘œì‹œ
    
    print("ğŸ”— íŠ¹ì„± ìƒí˜¸ì‘ìš© ë¶„ì„ ì™„ë£Œ!")
    return interactions

# íŒíŠ¸:
# - itertools.combinationsë¥¼ ì‚¬ìš©í•´ íŠ¹ì„± ìŒì„ ìƒì„±í•˜ì„¸ìš”
# - ê³±ì…ˆ ìƒí˜¸ì‘ìš© ì™¸ì—ë„ ë‚˜ëˆ—ì…ˆ, ì°¨ì´ ë“±ì„ ì‹œë„í•´ë³´ì„¸ìš”
# - 3D ì‚°ì ë„ë‚˜ íˆíŠ¸ë§µìœ¼ë¡œ ìƒí˜¸ì‘ìš©ì„ ì‹œê°í™”í•´ë³´ì„¸ìš”
```

### ì—°ìŠµ ë¬¸ì œ 3: ë§ì¶¤í˜• íŠ¹ì„± ì„ íƒê¸° êµ¬í˜„ â­â­â­â­
ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì— ë§ëŠ” íŠ¹ì„± ì„ íƒ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•´ë³´ì„¸ìš”.

```python
# ì—°ìŠµ ë¬¸ì œ 3: ë§ì¶¤í˜• íŠ¹ì„± ì„ íƒê¸° êµ¬í˜„
def exercise_custom_selector(df, target_col='SalePrice', business_goal='accuracy'):
    """
    ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì— ë”°ë¥¸ ë§ì¶¤í˜• íŠ¹ì„± ì„ íƒ ì‹œìŠ¤í…œ
    
    Parameters:
    business_goal: 'accuracy' (ì •í™•ë„ ìš°ì„ ), 'interpretability' (í•´ì„ì„± ìš°ì„ ), 
                   'efficiency' (íš¨ìœ¨ì„± ìš°ì„ )
    """
    
    selector_config = {}
    selected_features = []
    
    print(f"ğŸ¯ ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œ: {business_goal}")
    
    # ê¸°ë³¸ ë°ì´í„° ì¤€ë¹„
    if target_col not in df.columns:
        print(f"âš ï¸ {target_col} ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return [], {}
    
    X = df.drop(columns=[target_col])
    y = df[target_col]
    numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()
    X_numeric = X[numeric_features].fillna(X[numeric_features].median())
    
    if business_goal == 'accuracy':
        # ì •í™•ë„ ìš°ì„ : ì„±ëŠ¥ ìµœìš°ì„ , ë³µì¡í•œ íŠ¹ì„±ë„ í—ˆìš©
        print("ğŸ“ˆ ì •í™•ë„ ìµœìš°ì„  ëª¨ë“œ")
        selector_config = {
            'max_features': min(50, len(numeric_features)),  # ë§ì€ íŠ¹ì„± í—ˆìš©
            'complexity_penalty': 0.1,  # ë³µì¡ë„ í˜ë„í‹° ë‚®ìŒ
            'performance_weight': 0.8,   # ì„±ëŠ¥ ê°€ì¤‘ì¹˜ ë†’ìŒ
            'interpretability_weight': 0.1,  # í•´ì„ì„± ê°€ì¤‘ì¹˜ ë‚®ìŒ
            'efficiency_weight': 0.1    # íš¨ìœ¨ì„± ê°€ì¤‘ì¹˜ ë‚®ìŒ
        }
        
        # TODO: ê³ ì„±ëŠ¥ íŠ¹ì„± ì„ íƒ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
        # íŒíŠ¸: Random Forest ì¤‘ìš”ë„ + Lasso + RFE ì¡°í•©
        
    elif business_goal == 'interpretability':
        # í•´ì„ì„± ìš°ì„ : ì´í•´í•˜ê¸° ì‰¬ìš´ íŠ¹ì„± ìš°ì„ , ì›ë³¸ íŠ¹ì„± ì„ í˜¸
        print("ğŸ” í•´ì„ì„± ìš°ì„  ëª¨ë“œ")
        selector_config = {
            'max_features': min(10, len(numeric_features)),  # ì ì€ íŠ¹ì„±
            'complexity_penalty': 0.8,  # ë³µì¡ë„ í˜ë„í‹° ë†’ìŒ
            'performance_weight': 0.3,   # ì„±ëŠ¥ ê°€ì¤‘ì¹˜ ë³´í†µ
            'interpretability_weight': 0.6,  # í•´ì„ì„± ê°€ì¤‘ì¹˜ ë†’ìŒ
            'efficiency_weight': 0.1    # íš¨ìœ¨ì„± ê°€ì¤‘ì¹˜ ë‚®ìŒ
        }
        
        # TODO: í•´ì„ ê°€ëŠ¥í•œ íŠ¹ì„± ìš°ì„  ì„ íƒ
        # íŒíŠ¸: ì›ë³¸ íŠ¹ì„± ì„ í˜¸, ë‹¨ìˆœí•œ ì¡°í•© íŠ¹ì„±ë§Œ í—ˆìš©
        
    elif business_goal == 'efficiency':
        # íš¨ìœ¨ì„± ìš°ì„ : ìµœì†Œí•œì˜ íŠ¹ì„±ìœ¼ë¡œ ìµœëŒ€ íš¨ê³¼
        print("âš¡ íš¨ìœ¨ì„± ìš°ì„  ëª¨ë“œ")
        selector_config = {
            'max_features': min(5, len(numeric_features)),   # ë§¤ìš° ì ì€ íŠ¹ì„±
            'complexity_penalty': 0.5,  # ë³µì¡ë„ í˜ë„í‹° ë³´í†µ
            'performance_weight': 0.4,   # ì„±ëŠ¥ ê°€ì¤‘ì¹˜ ë³´í†µ
            'interpretability_weight': 0.2,  # í•´ì„ì„± ê°€ì¤‘ì¹˜ ë‚®ìŒ
            'efficiency_weight': 0.4    # íš¨ìœ¨ì„± ê°€ì¤‘ì¹˜ ë†’ìŒ
        }
        
        # TODO: íš¨ìœ¨ì„± ê¸°ë°˜ íŠ¹ì„± ì„ íƒ
        # íŒíŠ¸: ì ì€ íŠ¹ì„±ìœ¼ë¡œ ë†’ì€ ì„±ëŠ¥, ê³„ì‚° ë¹„ìš© ê³ ë ¤
    
    # TODO: ì„ íƒëœ ì„¤ì •ì— ë”°ë¥¸ íŠ¹ì„± ì„ íƒ ì‹¤í–‰
    # TODO: íŠ¹ì„±ë³„ ì ìˆ˜ ê³„ì‚° (ì„±ëŠ¥ + í•´ì„ì„± + íš¨ìœ¨ì„±)
    # TODO: ìµœì¢… íŠ¹ì„± ë¦¬ìŠ¤íŠ¸ ìƒì„±
    
    print(f"âœ… {len(selected_features)}ê°œ íŠ¹ì„± ì„ íƒ ì™„ë£Œ")
    print(f"ì„¤ì •: {selector_config}")
    
    return selected_features, selector_config

# íŒíŠ¸:
# - ê° ëª©í‘œë³„ë¡œ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ì™€ ì œì•½ ì¡°ê±´ì„ ì„¤ì •í•˜ì„¸ìš”
# - íŠ¹ì„±ì˜ ë³µì¡ë„, ê³„ì‚° ë¹„ìš©, í•´ì„ ê°€ëŠ¥ì„±ì„ ì ìˆ˜í™”í•´ë³´ì„¸ìš”
# - íŒŒë ˆí†  ìµœì í™” ê°œë…ì„ í™œìš©í•´ë³´ì„¸ìš”
```

---

## ğŸ“š í•µì‹¬ ì •ë¦¬

ì´ë²ˆ Partì—ì„œ ë°°ìš´ í•µì‹¬ ë‚´ìš©ì„ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

### âœ… íŠ¹ì„± ê³µí•™ í•µì‹¬ í¬ì¸íŠ¸

**1. íŠ¹ì„± ê³µí•™ì˜ ê°€ì¹˜**
- ë„ë©”ì¸ ì§€ì‹ì´ ê°€ì¥ ê°•ë ¥í•œ íŠ¹ì„± ìƒì„± ë„êµ¬
- ê¸°ë³¸ íŠ¹ì„± â†’ íŠ¹ì„± ê³µí•™ í›„ **15-25% ì„±ëŠ¥ í–¥ìƒ** ì¼ë°˜ì 
- ëª¨ë¸ì—ê²Œ "ë” ë‚˜ì€ ëˆˆ"ì„ ì£¼ì–´ ë°ì´í„° ë³¸ì§ˆ íŒŒì•… ë„ì›€

**2. ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ íŠ¹ì„± ìƒì„±**
- **ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ë¯¸ ìš°ì„ **: í†µê³„ì  ìƒê´€ê´€ê³„ë³´ë‹¤ ì‹¤ë¬´ì  í•´ì„ì´ ì¤‘ìš”
- **5ê°œ ì˜ì—­ ì²´ê³„**: ë©´ì , ì‹œê°„, í’ˆì§ˆ, í¸ì˜ì‹œì„¤, ìƒí™œí¸ì˜ì„±
- **ê²€ì¦ í•„ìˆ˜**: ìƒˆë¡œìš´ íŠ¹ì„±ì€ ë°˜ë“œì‹œ ì„±ëŠ¥ ê°œì„  íš¨ê³¼ í™•ì¸

**3. ìˆ˜í•™ì  íŠ¹ì„± ì¡°í•©**
- **ë¹„ìœ¨ íŠ¹ì„±**: ì„œë¡œ ë‹¤ë¥¸ ë‹¨ìœ„ ë³€ìˆ˜ë“¤ì˜ ë¹„êµ ê°€ëŠ¥í™”
- **ì°¨ì´ íŠ¹ì„±**: ìƒëŒ€ì  ë³€í™”ë‚˜ ê²©ì°¨ í‘œí˜„
- **ê³±ì…ˆ íŠ¹ì„±**: ìƒí˜¸ì‘ìš© íš¨ê³¼ í¬ì°©
- **ê±°ë“­ì œê³± íŠ¹ì„±**: ë¹„ì„ í˜• ê´€ê³„ë‚˜ ê°€ì†í™” íš¨ê³¼ ë°˜ì˜
- **ë³µí•© ì§€ìˆ˜**: ì—¬ëŸ¬ ì¸¡ë©´ì„ ì¢…í•©í•œ í†µí•© ì ìˆ˜

**4. ì‹œê°„ ê¸°ë°˜ íŠ¹ì„±**
- **ê±´ì¶• ì‹œëŒ€**: ê° ì‹œëŒ€ë³„ ê±´ì¶• ì–‘ì‹ê³¼ ê¸°ì¤€ì˜ ê°€ê²© ì˜í–¥
- **ë¦¬ëª¨ë¸ë§ íŒ¨í„´**: ìœ ì§€ë³´ìˆ˜ ì£¼ê¸°ì™€ íˆ¬ì íŒ¨í„´ ë¶„ì„  
- **íŒë§¤ ì‹œê¸°**: ë¶€ë™ì‚° ì‹œì¥ ì‚¬ì´í´ê³¼ ê³„ì ˆì„± íš¨ê³¼
- **ë…¸í›„í™” ë‹¨ê³„**: ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ê°€ì¹˜ ë³€í™” íŒ¨í„´

**5. íŠ¹ì„± ì„ íƒ ê¸°ë²•**
- **ë‹¤ì¤‘ ë°©ë²•ë¡ **: F-í†µê³„ëŸ‰, Random Forest, Lasso, RFE í†µí•©
- **ì•™ìƒë¸” ì ‘ê·¼**: ì—¬ëŸ¬ ë°©ë²•ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì•ˆì •ì„± í™•ë³´
- **ì°¨ì› íš¨ìœ¨ì„±**: 75% ì°¨ì› ì¶•ì†Œí•˜ë©´ì„œë„ ì„±ëŠ¥ ìœ ì§€ ê°€ëŠ¥
- **í•©ì˜ë„ ì¤‘ì‹œ**: ì—¬ëŸ¬ ë°©ë²•ì—ì„œ ê³µí†µ ì„ íƒëœ íŠ¹ì„±ì´ ë” ì‹ ë¢°ì„± ë†’ìŒ

### âœ… ì‹¤ë¬´ íŠ¹ì„± ê³µí•™ ì›ì¹™

**1. ì˜ë¯¸ ìš°ì„  ì›ì¹™**
```
í†µê³„ì  ìƒê´€ê´€ê³„ > ë¹„ì¦ˆë‹ˆìŠ¤ì  ì˜ë¯¸ âŒ
ë¹„ì¦ˆë‹ˆìŠ¤ì  ì˜ë¯¸ > í†µê³„ì  ìƒê´€ê´€ê³„ âœ…
```

**2. ê²€ì¦ í•„ìˆ˜ ì›ì¹™**
```
ìƒˆë¡œìš´ íŠ¹ì„± ìƒì„± â†’ ì„±ëŠ¥ ê°œì„  í™•ì¸ â†’ ì±„íƒ/ê¸°ê° ê²°ì •
```

**3. ê³¼ì í•© ì£¼ì˜ ì›ì¹™**
```
ë³µì¡í•œ íŠ¹ì„± ë§ì´ ìƒì„± â†’ êµì°¨ ê²€ì¦ìœ¼ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ í™•ì¸
```

**4. í•´ì„ ê°€ëŠ¥ì„± ì›ì¹™**
```
ë¸”ë™ë°•ìŠ¤ íŠ¹ì„± < í•´ì„ ê°€ëŠ¥í•œ íŠ¹ì„± (ì‹¤ë¬´ì—ì„œëŠ” ì„¤ëª… í•„ìš”)
```

### âœ… íŠ¹ì„± ìœ í˜•ë³„ í™œìš© ê°€ì´ë“œ

| íŠ¹ì„± ìœ í˜• | ëª©ì  | ì˜ˆì‹œ | ì ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|-----------|------|------|---------------|
| **ë¹„ìœ¨ íŠ¹ì„±** | íš¨ìœ¨ì„±, ë°€ë„ ì¸¡ì • | ë°©ë‹¹ë©´ì , ëŒ€ì§€í™œìš©ë„ | ê³µê°„ íš¨ìœ¨ì„± í‰ê°€ |
| **ì°¨ì´ íŠ¹ì„±** | ê²©ì°¨, ë³€í™” í‘œí˜„ | í’ˆì§ˆ-ìƒíƒœì°¨ì´, ë¦¬ëª¨ë¸ë§ì§€ì—° | ìƒëŒ€ì  ë¹„êµ ë¶„ì„ |
| **ê³±ì…ˆ íŠ¹ì„±** | ìƒí˜¸ì‘ìš© í¬ì°© | í’ˆì§ˆÃ—ë©´ì , ìš•ì‹¤Ã—ì¹¨ì‹¤ | ë³µí•© íš¨ê³¼ ëª¨ë¸ë§ |
| **ì‹œê°„ íŠ¹ì„±** | ì£¼ê¸°ì„±, íŠ¸ë Œë“œ | ê±´ì¶•ì‹œëŒ€, ê³„ì ˆì„± | ì‹œê³„ì—´ íŒ¨í„´ í™œìš© |
| **ë³µí•© ì§€ìˆ˜** | í†µí•© í‰ê°€ | í¸ì˜ì„±ì§€ìˆ˜, íˆ¬ìë§¤ë ¥ë„ | ë‹¤ì°¨ì› ì¢…í•© í‰ê°€ |

### âœ… House Prices í”„ë¡œì íŠ¸ ì„±ê³¼ ìš”ì•½

**íŠ¹ì„± ë³€í™” ê³¼ì •:**
```
ì›ë³¸ 80ê°œ íŠ¹ì„±
  â†“ ë„ë©”ì¸ ì§€ì‹ ì ìš©
+ 25ê°œ ë„ë©”ì¸ íŠ¹ì„±
  â†“ ìˆ˜í•™ì  ì¡°í•©
+ 10ê°œ ìˆ˜í•™ì  íŠ¹ì„±  
  â†“ ì‹œê°„ ë¶„ì„
+ 20ê°œ ì‹œê°„ íŠ¹ì„±
  â†“ íŠ¹ì„± ì„ íƒ
= 15ê°œ ìµœì¢… íŠ¹ì„± (75% ì°¨ì› ì¶•ì†Œ)
```

**ì„±ëŠ¥ ê°œì„  íš¨ê³¼:**
- **RandomForest**: RMSE 15.2% ê°ì†Œ, RÂ² 18.4% ì¦ê°€
- **LinearRegression**: RMSE 21.7% ê°ì†Œ, RÂ² 23.1% ì¦ê°€
- **ìµœì¢… ì°¨ì› ì¶•ì†Œìœ¨**: 87% (135ê°œ â†’ 15ê°œ)
- **ì„±ëŠ¥ ëŒ€ë¹„ íš¨ìœ¨ì„±**: ëŒ€í­ í–¥ìƒ

### ğŸ’¡ ì‹¤ë¬´ ì ìš© íŒ

**1. ë°˜ë³µì  ì ‘ê·¼**
```
íŠ¹ì„± ìƒì„± â†’ ê²€ì¦ â†’ ê°œì„  â†’ ì¬ê²€ì¦ (ìˆœí™˜ ê³¼ì •)
```

**2. í˜‘ì—…ì˜ ì¤‘ìš”ì„±**
- ë„ë©”ì¸ ì „ë¬¸ê°€ì™€ì˜ ê¸´ë°€í•œ í˜‘ë ¥
- ë¹„ì¦ˆë‹ˆìŠ¤ íŒ€ê³¼ì˜ ì§€ì†ì  ì»¤ë®¤ë‹ˆì¼€ì´ì…˜
- í˜„ì¥ ê²½í—˜ê³¼ ë°ì´í„° ë¶„ì„ì˜ ìœµí•©

**3. ë¬¸ì„œí™” í•„ìˆ˜**
- ê° íŠ¹ì„±ì˜ ì •ì˜ì™€ ìƒì„± ë…¼ë¦¬ ëª…í™•íˆ ê¸°ë¡
- ë¹„ì¦ˆë‹ˆìŠ¤ì  í•´ì„ê³¼ í™œìš© ë°©ì•ˆ ë¬¸ì„œí™”
- ë²„ì „ ê´€ë¦¬ë¡œ íŠ¹ì„± ì„¸íŠ¸ ë³€í™” ì¶”ì 

**4. í’ˆì§ˆ ê´€ë¦¬**
- íŠ¹ì„±ë³„ ê²°ì¸¡ë¥ , ì´ìƒì¹˜ ë¹„ìœ¨ ëª¨ë‹ˆí„°ë§
- íŠ¹ì„± ê°„ ë‹¤ì¤‘ê³µì„ ì„± í™•ì¸
- ì •ê¸°ì ì¸ íŠ¹ì„± ì¤‘ìš”ë„ ì¬í‰ê°€

### ğŸ¯ íŠ¹ì„± ê³µí•™ ë§ˆìŠ¤í„° ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **ë„ë©”ì¸ ì´í•´**: í•´ë‹¹ ë¶„ì•¼ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ íŒŒì•…
- [ ] **ì°½ì˜ì  ì¡°í•©**: ìˆ˜í•™ì /ë…¼ë¦¬ì  íŠ¹ì„± ìƒì„± ì•„ì´ë””ì–´
- [ ] **ì‹œê°„ í™œìš©**: ì‹œê³„ì—´ íŒ¨í„´ê³¼ ì£¼ê¸°ì„± ë°˜ì˜
- [ ] **ì„ íƒ ì „ëµ**: ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì˜ ê· í˜•ì  ì°¾ê¸°
- [ ] **ê²€ì¦ ëŠ¥ë ¥**: ìƒˆë¡œìš´ íŠ¹ì„±ì˜ íš¨ê³¼ ì •ëŸ‰ì  ì¸¡ì •
- [ ] **í•´ì„ ì—­ëŸ‰**: íŠ¹ì„±ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ì  ì˜ë¯¸ ì„¤ëª…
- [ ] **í˜‘ì—… ìŠ¤í‚¬**: ë„ë©”ì¸ ì „ë¬¸ê°€ì™€ íš¨ê³¼ì  ì†Œí†µ

---

## ğŸ¤” ìƒê°í•´ë³´ê¸°

1. **ë„ë©”ì¸ ì§€ì‹ì˜ ê°€ì¹˜**: ë¶€ë™ì‚° ì „ë¬¸ê°€ê°€ ì§ê´€ì ìœ¼ë¡œ ì•„ëŠ” ê²ƒë“¤ì„ ì–´ë–»ê²Œ ë°ì´í„° íŠ¹ì„±ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆì„ê¹Œìš”? ë‹¤ë¥¸ ë„ë©”ì¸(ì˜ë£Œ, ê¸ˆìœµ, ì œì¡°ì—…)ì—ì„œëŠ” ì–´ë–¤ íŠ¹ì„±ë“¤ì´ ì¤‘ìš”í• ê¹Œìš”?

2. **íŠ¹ì„±ì˜ ìƒëª…ì£¼ê¸°**: ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ íŠ¹ì„±ì˜ ì¤‘ìš”ë„ê°€ ë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŒ¬ë°ë¯¹ìœ¼ë¡œ ì¸í•´ í™ˆì˜¤í”¼ìŠ¤ ê³µê°„ì´ ì¤‘ìš”í•´ì¡Œë“¯ì´, ë¯¸ë˜ì—ëŠ” ì–´ë–¤ íŠ¹ì„±ë“¤ì´ ì¤‘ìš”í•´ì§ˆê¹Œìš”?

3. **ìë™í™” vs ìˆ˜ë™**: AIê°€ ìë™ìœ¼ë¡œ íŠ¹ì„±ì„ ìƒì„±í•˜ëŠ” ë„êµ¬ë“¤ì´ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì¸ê°„ì˜ ì°½ì˜ì„±ê³¼ ë„ë©”ì¸ ì§€ì‹ì€ ì—¬ì „íˆ ì¤‘ìš”í• ê¹Œìš”? ë‘˜ì˜ ìµœì  ì¡°í•©ì€ ë¬´ì—‡ì¼ê¹Œìš”?

4. **ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­**: íŠ¹ì„± ê³µí•™ ê³¼ì •ì—ì„œ í¸í–¥ì„±ì´ ê°•í™”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ì§€ì—­ì´ë‚˜ ê³„ì¸µì— ë¶ˆë¦¬í•œ íŠ¹ì„±ì´ ë§Œë“¤ì–´ì§ˆ ìˆ˜ ìˆëŠ”ë°, ì´ë¥¼ ì–´ë–»ê²Œ ë°©ì§€í•  ìˆ˜ ìˆì„ê¹Œìš”?

5. **í•´ì„ ê°€ëŠ¥ì„±ì˜ ë”œë ˆë§ˆ**: ë³µì¡í•œ íŠ¹ì„±ì¼ìˆ˜ë¡ ì„±ëŠ¥ì´ ì¢‹ì•„ì§ˆ ìˆ˜ ìˆì§€ë§Œ, í•´ì„í•˜ê¸° ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤. ì‹¤ë¬´ì—ì„œëŠ” ì„±ëŠ¥ê³¼ í•´ì„ ê°€ëŠ¥ì„± ì¤‘ ì–´ëŠ ê²ƒì„ ìš°ì„ í•´ì•¼ í• ê¹Œìš”?

---

## ğŸ”œ ë‹¤ìŒ Part ì˜ˆê³ : AI ë„êµ¬ë¥¼ í™œìš©í•œ ìë™ ì „ì²˜ë¦¬ì™€ í•œê³„ì 

ë‹¤ìŒ Partì—ì„œëŠ” AI ê¸°ìˆ ì„ í™œìš©í•œ **ìë™í™”ëœ ì „ì²˜ë¦¬ ë„êµ¬**ë“¤ì„ ì‚´í´ë³´ê³ , ê·¸ ì¥ì ê³¼ í•œê³„ì ì„ ë¶„ì„í•©ë‹ˆë‹¤:

- **AutoML ì „ì²˜ë¦¬ ë„êµ¬**: H2O.ai, DataRobot, Google AutoML ë“±ì˜ ìë™ ì „ì²˜ë¦¬ ê¸°ëŠ¥
- **AI ê¸°ë°˜ íŠ¹ì„± ìƒì„±**: Featuretools, AutoFeat ë“± ìë™ íŠ¹ì„± ê³µí•™ ë¼ì´ë¸ŒëŸ¬ë¦¬  
- **ì§€ëŠ¥í˜• ë°ì´í„° í´ë¦¬ë‹**: ê²°ì¸¡ì¹˜, ì´ìƒì¹˜, ë¶ˆì¼ì¹˜ ë°ì´í„°ì˜ ìë™ íƒì§€ ë° ì²˜ë¦¬
- **ì¸ê°„-AI í˜‘ì—…**: ìë™í™” ë„êµ¬ì™€ ë„ë©”ì¸ ì „ë¬¸ê°€ì˜ íš¨ê³¼ì  ê²°í•© ë°©ë²•
- **í•œê³„ì ê³¼ ì£¼ì˜ì‚¬í•­**: ë¸”ë™ë°•ìŠ¤ ë¬¸ì œ, í¸í–¥ì„±, ê³¼ì í•© ë“±ì˜ ìœ„í—˜ ìš”ì†Œ

AIì˜ í˜ì„ í™œìš©í•˜ë©´ì„œë„ ê·¸ í•œê³„ë¥¼ ì •í™•íˆ ì´í•´í•˜ì—¬, **ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**ì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ë°°ì›Œë³´ê² ìŠµë‹ˆë‹¤!

---

*"íŠ¹ì„± ê³µí•™ì€ ë°ì´í„°ì— ìƒëª…ì„ ë¶ˆì–´ë„£ëŠ” ì˜ˆìˆ ì…ë‹ˆë‹¤. ìˆ«ì ë’¤ì— ìˆ¨ê²¨ì§„ ì´ì•¼ê¸°ë¥¼ ì°¾ì•„ë‚´ê³ , ëª¨ë¸ì´ ì„¸ìƒì„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ì°½ì¡°ì  ê³¼ì •ì…ë‹ˆë‹¤."*
