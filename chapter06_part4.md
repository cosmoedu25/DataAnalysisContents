# 6ì¥ Part 4: AIì™€ í˜‘ì—…ì„ í†µí•œ ëª¨ë¸ ê°œì„ 
## ì¸ê°„ê³¼ AIê°€ í•¨ê»˜ ë§Œë“œëŠ” ë” ë‚˜ì€ ëª¨ë¸

### í•™ìŠµ ëª©í‘œ
ì´ë²ˆ íŒŒíŠ¸ë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ëŠ¥ë ¥ì„ ê°–ê²Œ ë©ë‹ˆë‹¤:
- AI ìƒì„± ì½”ë“œì˜ í’ˆì§ˆì„ í‰ê°€í•˜ê³  ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ìœ¼ë¡œ AIì™€ ì†Œí†µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ëª¨ë¸ì˜ í•´ì„ì„±ì„ ë†’ì´ê³  ì˜ì‚¬ê²°ì • ê³¼ì •ì„ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì¸ê°„ì˜ ì „ë¬¸ ì§€ì‹ê³¼ AIì˜ ìµœì í™” ëŠ¥ë ¥ì„ ê· í˜•ìˆê²Œ ê²°í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- AI í˜‘ì—… ê¸°ë°˜ì˜ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ë§ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

---

### 6.19 AI ì‹œëŒ€ì˜ ë°ì´í„° ê³¼í•™ì - ìƒˆë¡œìš´ í˜‘ì—…ì˜ íŒ¨ëŸ¬ë‹¤ì„

#### ğŸ¤ ì¸ê°„-AI í˜‘ì—…ì˜ í•„ìš”ì„±

ChatGPT, Claude ê°™ì€ ëŒ€í™”í˜• AIê°€ ë“±ì¥í•˜ë©´ì„œ ë°ì´í„° ê³¼í•™ìì˜ ì—­í• ì´ í¬ê²Œ ë³€í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤. AIê°€ ì½”ë“œë¥¼ ìƒì„±í•˜ê³  ë¶„ì„ì„ ë„ì™€ì£¼ì§€ë§Œ, ì—¬ì „íˆ ì¸ê°„ì˜ ë¹„íŒì  ì‚¬ê³ ì™€ ë„ë©”ì¸ ì§€ì‹ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_classification, load_breast_cancer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.inspection import permutation_importance, plot_partial_dependence
import warnings
warnings.filterwarnings('ignore')

# ì‹œê°í™”ë¥¼ ìœ„í•œ í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

print("ğŸ¤ ì¸ê°„-AI í˜‘ì—…ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„")
print("=" * 50)

# AI ì‹œëŒ€ ë°ì´í„° ê³¼í•™ìì˜ ì—­í•  ë³€í™”
role_comparison = {
    "ê¸°ì¡´ ì—­í• ": [
        "ì½”ë“œ ì§ì ‘ ì‘ì„±",
        "ì•Œê³ ë¦¬ì¦˜ ì§ì ‘ êµ¬í˜„",
        "ë§¤ë‰´ì–¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹",
        "ìˆ˜ë™ ëª¨ë¸ í•´ì„",
        "ê°œë³„ ì‘ì—… ì¤‘ì‹¬"
    ],
    
    "AI í˜‘ì—… ì‹œëŒ€ ì—­í• ": [
        "AI ìƒì„± ì½”ë“œ ê²€ì¦ ë° ê°œì„ ",
        "ì•Œê³ ë¦¬ì¦˜ ì„ íƒê³¼ ì¡°í•© ì „ëµ ìˆ˜ë¦½",
        "AI ìµœì í™” ê²°ê³¼ ê²€ì¦ ë° ì¡°ì •",
        "ë¹„ì¦ˆë‹ˆìŠ¤ ë§¥ë½ ê¸°ë°˜ ëª¨ë¸ í•´ì„",
        "ì¸ê°„-AI íŒ€ì›Œí¬ ì¡°ìœ¨"
    ]
}

print("ğŸ“Š ë°ì´í„° ê³¼í•™ì ì—­í• ì˜ ì§„í™”:")
for old_role, new_role in zip(role_comparison["ê¸°ì¡´ ì—­í• "], role_comparison["AI í˜‘ì—… ì‹œëŒ€ ì—­í• "]):
    print(f"  {old_role:<25} â†’ {new_role}")

print(f"\nğŸ’¡ í•µì‹¬ ë³€í™”:")
key_changes = [
    "ìƒì‚°ì„± í–¥ìƒ: AIê°€ ë°˜ë³µ ì‘ì—…ì„ ìë™í™”í•˜ì—¬ ì°½ì˜ì  ì—…ë¬´ì— ì§‘ì¤‘",
    "í’ˆì§ˆ í–¥ìƒ: AIì™€ ì¸ê°„ì˜ ìƒí˜¸ ê²€ì¦ìœ¼ë¡œ ì˜¤ë¥˜ ê°ì†Œ",
    "í•™ìŠµ ê°€ì†: AIê°€ ìµœì‹  ê¸°ë²•ì„ ì œì•ˆí•˜ì—¬ ì§€ì†ì  í•™ìŠµ ì´‰ì§„",
    "ì ‘ê·¼ì„± í™•ëŒ€: ë³µì¡í•œ ê¸°ë²•ì„ ë” ì‰½ê²Œ í™œìš© ê°€ëŠ¥",
    "ì±…ì„ê° ì¦ëŒ€: AI ê²°ê³¼ì— ëŒ€í•œ ê²€ì¦ê³¼ í•´ì„ ì—­í•  ê°•í™”"
]

for i, change in enumerate(key_changes, 1):
    print(f"  {i}. {change}")
```

**AI í˜‘ì—…ì˜ í•µì‹¬ ì›ì¹™**
- **ìƒí˜¸ ë³´ì™„**: AIì˜ ê³„ì‚° ëŠ¥ë ¥ + ì¸ê°„ì˜ ì°½ì˜ì„±ê³¼ ì§ê´€
- **ì§€ì†ì  ê²€ì¦**: AI ê²°ê³¼ë¥¼ ë¹„íŒì ìœ¼ë¡œ ê²€í† í•˜ê³  ê°œì„ 
- **ë§¥ë½ì  í•´ì„**: ë¹„ì¦ˆë‹ˆìŠ¤ì™€ ë„ë©”ì¸ ì§€ì‹ì„ ëª¨ë¸ì— ë°˜ì˜
- **ìœ¤ë¦¬ì  ì±…ì„**: AI ê²°ì •ì˜ ê³µì •ì„±ê³¼ íˆ¬ëª…ì„± í™•ë³´

#### ğŸ¯ íš¨ê³¼ì ì¸ AI í˜‘ì—… ì „ëµ

```python
# AI í˜‘ì—… ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜
print("\nğŸ¯ AI í˜‘ì—… ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜")
print("=" * 40)

# ì‹¤ì œ ë°ì´í„°ë¡œ AI í˜‘ì—… ê³¼ì • ì‹œì—°
cancer_data = load_breast_cancer()
X_cancer = cancer_data.data
y_cancer = cancer_data.target
feature_names = cancer_data.feature_names

X_train, X_test, y_train, y_test = train_test_split(
    X_cancer, y_cancer, test_size=0.2, random_state=42, stratify=y_cancer
)

print(f"ğŸ“Š ìœ ë°©ì•” ì§„ë‹¨ ë°ì´í„°ì…‹:")
print(f"  ìƒ˜í”Œ ìˆ˜: {X_cancer.shape[0]}ê°œ")
print(f"  íŠ¹ì„± ìˆ˜: {X_cancer.shape[1]}ê°œ")
print(f"  ì–‘ì„±: {np.sum(y_cancer == 1)}ê°œ, ìŒì„±: {np.sum(y_cancer == 0)}ê°œ")

# AI í˜‘ì—… ì‹œë‚˜ë¦¬ì˜¤ 1: AIê°€ ì œì•ˆí•œ "ê¸°ë³¸" ëª¨ë¸
print(f"\nğŸ¤– AI ì œì•ˆ ëª¨ë¸ (ê°€ìƒì˜ AI ì‘ë‹µ):")
ai_suggested_code = '''
# AIê°€ ì œì•ˆí•œ ê¸°ë³¸ ì½”ë“œ (ì¼ë°˜ì ì´ì§€ë§Œ ìµœì í™”ë˜ì§€ ì•ŠìŒ)
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier()
model.fit(X_train, y_train)
accuracy = model.score(X_test, y_test)
'''

print(f"AI ì œì•ˆ ì½”ë“œ:")
print(ai_suggested_code)

# AI ì œì•ˆ ëª¨ë¸ ì‹¤í–‰
ai_model = RandomForestClassifier(random_state=42)  # AIëŠ” random_stateë¥¼ ë¹¼ë¨¹ì„ ìˆ˜ ìˆìŒ
ai_model.fit(X_train, y_train)
ai_accuracy = ai_model.score(X_test, y_test)

print(f"AI ì œì•ˆ ëª¨ë¸ ì„±ëŠ¥: {ai_accuracy:.4f}")

# ì¸ê°„ ì „ë¬¸ê°€ì˜ ê°œì„ ì‚¬í•­ ì‹ë³„
print(f"\nğŸ‘¨â€ğŸ’¼ ì¸ê°„ ì „ë¬¸ê°€ ê²€í†  ë° ê°œì„ :")
human_improvements = [
    "random_state ì¶”ê°€ë¡œ ì¬í˜„ì„± í™•ë³´",
    "êµì°¨ ê²€ì¦ìœ¼ë¡œ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‰ê°€",
    "ì˜ë£Œ ë°ì´í„° íŠ¹ì„±ìƒ precision/recall ì¤‘ì‹œ",
    "íŠ¹ì„± ì¤‘ìš”ë„ë¡œ í•´ì„ ê°€ëŠ¥ì„± í–¥ìƒ",
    "í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” í•„ìš”"
]

for improvement in human_improvements:
    print(f"  âœ“ {improvement}")
```

**ì¸ê°„ ì „ë¬¸ê°€ì˜ í•µì‹¬ ê¸°ì—¬**
- **ë„ë©”ì¸ ì§€ì‹**: ì˜ë£Œ ë°ì´í„°ì—ì„œëŠ” ì •í™•ë„ë³´ë‹¤ ë¯¼ê°ë„ê°€ ì¤‘ìš”
- **ë¹„ì¦ˆë‹ˆìŠ¤ ë§¥ë½**: ì‹¤ì œ í™œìš© í™˜ê²½ì„ ê³ ë ¤í•œ ëª¨ë¸ ì„¤ê³„
- **í’ˆì§ˆ ê´€ë¦¬**: ì¬í˜„ì„±, ì•ˆì •ì„±, í•´ì„ ê°€ëŠ¥ì„± í™•ë³´
- **ìœ¤ë¦¬ì  ê³ ë ¤**: í¸í–¥ì„±, ê³µì •ì„±, íˆ¬ëª…ì„± ê²€í† 

---

### 6.20 í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ - AIì™€ì˜ íš¨ê³¼ì  ì†Œí†µ

#### ğŸ’¬ ë°ì´í„° ê³¼í•™ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì„¤ê³„

AIì™€ íš¨ê³¼ì ìœ¼ë¡œ í˜‘ì—…í•˜ë ¤ë©´ ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ í”„ë¡¬í”„íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë§ˆì¹˜ ìˆ™ë ¨ëœ ë™ë£Œì—ê²Œ ì—…ë¬´ë¥¼ ìš”ì²­í•˜ëŠ” ê²ƒì²˜ëŸ¼ ìƒì„¸í•œ ë§¥ë½ê³¼ ìš”êµ¬ì‚¬í•­ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

```python
# íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ vs ë¹„íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ë¹„êµ
print("ğŸ’¬ ë°ì´í„° ê³¼í•™ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§")
print("=" * 50)

prompt_examples = {
    "âŒ ë¹„íš¨ê³¼ì  í”„ë¡¬í”„íŠ¸": [
        "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ì–´ì¤˜",
        "ë°ì´í„°ë¥¼ ë¶„ì„í•´ì¤˜",
        "ì¢‹ì€ ì•Œê³ ë¦¬ì¦˜ ì¶”ì²œí•´ì¤˜",
        "ëª¨ë¸ì„ ìµœì í™”í•´ì¤˜"
    ],
    
    "âœ… íš¨ê³¼ì  í”„ë¡¬í”„íŠ¸": [
        """ìœ ë°©ì•” ì§„ë‹¨ ë°ì´í„°(569ê°œ ìƒ˜í”Œ, 30ê°œ íŠ¹ì„±)ì— ëŒ€í•´ ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ ë¶„ë¥˜ ëª¨ë¸ì„ êµ¬í˜„í•´ì£¼ì„¸ìš”:
        - ëª©í‘œ: ë†’ì€ ë¯¼ê°ë„(ì¬í˜„ìœ¨) ë‹¬ì„± (ê±°ì§“ ìŒì„± ìµœì†Œí™”)
        - ì œì•½: í•´ì„ ê°€ëŠ¥í•œ ëª¨ë¸ ì„ í˜¸
        - í‰ê°€: êµì°¨ ê²€ì¦ + í˜¼ë™ í–‰ë ¬ ë¶„ì„
        - ì½”ë“œ: ì¬í˜„ ê°€ëŠ¥í•˜ë„ë¡ random_state ì„¤ì •""",
        
        """ë‹¤ìŒ ë‹¨ê³„ë¡œ EDAë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
        1. ê²°ì¸¡ì¹˜ ë° ì´ìƒì¹˜ íƒì§€
        2. íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ ë¶„ì„ (íˆíŠ¸ë§µ í¬í•¨)
        3. í´ë˜ìŠ¤ë³„ íŠ¹ì„± ë¶„í¬ ë¹„êµ
        4. ì°¨ì› ì¶•ì†Œ(PCA) í›„ 2D ì‹œê°í™”
        5. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ""",
        
        """RandomForest ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ë„ì™€ì£¼ì„¸ìš”:
        - í˜„ì¬ ì„±ëŠ¥: accuracy 0.95, precision 0.93, recall 0.96
        - ëª©í‘œ: recallì„ 0.98 ì´ìƒìœ¼ë¡œ í–¥ìƒ
        - ë°©ë²•: GridSearchCV ë˜ëŠ” RandomizedSearchCV
        - ì¤‘ìš” íŒŒë¼ë¯¸í„°: n_estimators, max_depth, min_samples_split"""
    ]
}

print("ğŸ“ í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ë¹„êµ:")
for category, prompts in prompt_examples.items():
    print(f"\n{category}:")
    for i, prompt in enumerate(prompts[:2], 1):  # ì²˜ìŒ 2ê°œë§Œ ì¶œë ¥
        if len(prompt) > 100:
            print(f"  {i}. {prompt[:100]}...")
        else:
            print(f"  {i}. {prompt}")

# í”„ë¡¬í”„íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸
print(f"\nğŸ“‹ íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸:")
checklist = [
    "ëª…í™•í•œ ëª©í‘œì™€ ì œì•½ì‚¬í•­ ëª…ì‹œ",
    "ë°ì´í„° íŠ¹ì„±ê³¼ ë„ë©”ì¸ ë§¥ë½ ì œê³µ",
    "ì›í•˜ëŠ” ì¶œë ¥ í˜•íƒœ êµ¬ì²´ì  ì„¤ëª…",
    "í‰ê°€ ê¸°ì¤€ê³¼ ì„±ëŠ¥ ì§€í‘œ ì§€ì •",
    "ì½”ë“œ í’ˆì§ˆ ìš”êµ¬ì‚¬í•­ í¬í•¨",
    "ì˜ˆìƒ ê²°ê³¼ë¬¼ê³¼ í™œìš© ë°©ì•ˆ ì–¸ê¸‰"
]

for i, item in enumerate(checklist, 1):
    print(f"  â˜‘ï¸ {i}. {item}")
```

#### ğŸ”§ AI ìƒì„± ì½”ë“œ ê²€ì¦ í”„ë ˆì„ì›Œí¬

```python
# AI ìƒì„± ì½”ë“œì˜ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ
print("\nğŸ”§ AI ìƒì„± ì½”ë“œ ê²€ì¦ í”„ë ˆì„ì›Œí¬")
print("=" * 50)

class AICodeValidator:
    def __init__(self):
        self.validation_criteria = {
            'ê¸°ëŠ¥ì„±': ['ì½”ë“œ ì‹¤í–‰ ê°€ëŠ¥ì„±', 'ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„', 'ì˜ˆìƒ ê²°ê³¼ ë‹¬ì„±'],
            'í’ˆì§ˆ': ['ê°€ë…ì„±', 'ì¬í˜„ì„±', 'íš¨ìœ¨ì„±', 'í™•ì¥ì„±'],
            'ì•ˆì •ì„±': ['ì˜ˆì™¸ ì²˜ë¦¬', 'ê²½ê³„ê°’ ê²€ì¦', 'ë°ì´í„° íƒ€ì… í™•ì¸'],
            'ëª¨ë²”ì‚¬ë¡€': ['ë³€ìˆ˜ëª… ëª…í™•ì„±', 'ì£¼ì„ ì¶©ì‹¤ë„', 'ëª¨ë“ˆí™”'],
            'ë„ë©”ì¸ì í•©ì„±': ['ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë°˜ì˜', 'ë„ë©”ì¸ ì œì•½ì‚¬í•­ ê³ ë ¤']
        }
    
    def validate_code(self, code_description, execution_result):
        """AI ìƒì„± ì½”ë“œë¥¼ ë‹¤ì°¨ì›ìœ¼ë¡œ í‰ê°€"""
        print(f"ğŸ” ì½”ë“œ ê²€ì¦ ê²°ê³¼: {code_description}")
        
        # ê°€ìƒì˜ í‰ê°€ ì ìˆ˜ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¶„ì„ ìˆ˜í–‰)
        scores = {
            'ê¸°ëŠ¥ì„±': np.random.uniform(0.7, 1.0),
            'í’ˆì§ˆ': np.random.uniform(0.6, 0.9),
            'ì•ˆì •ì„±': np.random.uniform(0.5, 0.8),
            'ëª¨ë²”ì‚¬ë¡€': np.random.uniform(0.6, 0.85),
            'ë„ë©”ì¸ì í•©ì„±': np.random.uniform(0.7, 0.95)
        }
        
        print(f"{'í‰ê°€ ì˜ì—­':<15} {'ì ìˆ˜':<8} {'ìƒíƒœ'}")
        print("-" * 35)
        
        total_score = 0
        for category, score in scores.items():
            status = "ğŸŸ¢ ìš°ìˆ˜" if score >= 0.8 else "ğŸŸ¡ ë³´í†µ" if score >= 0.6 else "ğŸ”´ ê°œì„ í•„ìš”"
            print(f"{category:<15} {score:<8.3f} {status}")
            total_score += score
        
        average_score = total_score / len(scores)
        print(f"\nì¢…í•© ì ìˆ˜: {average_score:.3f}")
        
        return scores, average_score
    
    def suggest_improvements(self, scores):
        """ê°œì„ ì‚¬í•­ ì œì•ˆ"""
        print(f"\nğŸ’¡ ê°œì„  ì œì•ˆì‚¬í•­:")
        
        improvement_suggestions = {
            'ê¸°ëŠ¥ì„±': "ìš”êµ¬ì‚¬í•­ ì¬ê²€í†  ë° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€",
            'í’ˆì§ˆ': "ì½”ë“œ ë¦¬íŒ©í† ë§ ë° ì„±ëŠ¥ ìµœì í™”",
            'ì•ˆì •ì„±': "ì˜ˆì™¸ ì²˜ë¦¬ ë¡œì§ ê°•í™” ë° ê²€ì¦ ì¶”ê°€",
            'ëª¨ë²”ì‚¬ë¡€': "ì½”ë“œ ìŠ¤íƒ€ì¼ ê°œì„  ë° ë¬¸ì„œí™” ê°•í™”",
            'ë„ë©”ì¸ì í•©ì„±': "ë„ë©”ì¸ ì „ë¬¸ê°€ ê²€í†  ë° ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë³´ì™„"
        }
        
        for category, score in scores.items():
            if score < 0.7:
                print(f"  ğŸ”§ {category}: {improvement_suggestions[category]}")

# AI ìƒì„± ì½”ë“œ ê²€ì¦ ì‹¤ë¡€
validator = AICodeValidator()

# ì˜ˆì‹œ 1: ê¸°ë³¸ì ì¸ ë¶„ë¥˜ ëª¨ë¸
print("\nğŸ“Š AI ìƒì„± ì½”ë“œ ê²€ì¦ ì‚¬ë¡€")
ai_model_scores, ai_avg = validator.validate_code(
    "ê¸°ë³¸ RandomForest ë¶„ë¥˜ ëª¨ë¸", 
    {"accuracy": 0.95, "execution_time": "2.3ì´ˆ"}
)
validator.suggest_improvements(ai_model_scores)

# ê°œì„ ëœ ì½”ë“œ ì˜ˆì‹œ
print(f"\nâœ¨ ì¸ê°„-AI í˜‘ì—… ê°œì„  ì½”ë“œ:")
improved_code = """
# AI + ì¸ê°„ ì „ë¬¸ê°€ í˜‘ì—… ê°œì„  ì½”ë“œ
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

def create_improved_model(X_train, y_train, random_state=42):
    '''
    ì˜ë£Œ ì§„ë‹¨ì„ ìœ„í•œ ê°œì„ ëœ RandomForest ëª¨ë¸
    - ë†’ì€ ë¯¼ê°ë„(recall) ëª©í‘œ
    - ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ ë³´ì¥
    - êµì°¨ ê²€ì¦ ê¸°ë°˜ í‰ê°€
    '''
    
    # í´ë˜ìŠ¤ ë¶ˆê· í˜• ê³ ë ¤í•œ ê°€ì¤‘ì¹˜ ì„¤ì •
    model = RandomForestClassifier(
        n_estimators=200,           # ì•ˆì •ì„±ì„ ìœ„í•œ ì¶©ë¶„í•œ íŠ¸ë¦¬ ìˆ˜
        max_depth=10,              # ê³¼ì í•© ë°©ì§€
        min_samples_split=5,       # ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ
        class_weight='balanced',   # í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì •
        random_state=random_state  # ì¬í˜„ì„± í™•ë³´
    )
    
    # ê³„ì¸µí™”ëœ êµì°¨ ê²€ì¦ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‰ê°€
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)
    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='recall')
    
    # ëª¨ë¸ í›ˆë ¨
    model.fit(X_train, y_train)
    
    return model, cv_scores

# ì‹¤í–‰ ë° ê²°ê³¼
improved_model, cv_scores = create_improved_model(X_train, y_train)
print(f"êµì°¨ ê²€ì¦ ì¬í˜„ìœ¨: {np.mean(cv_scores):.4f} (Â±{np.std(cv_scores):.4f})")
"""

print(improved_code)

# ê°œì„ ëœ ì½”ë“œ í‰ê°€
improved_scores, improved_avg = validator.validate_code(
    "ê°œì„ ëœ RandomForest ë¶„ë¥˜ ëª¨ë¸",
    {"recall": 0.98, "execution_time": "3.1ì´ˆ", "cv_std": 0.02}
)

print(f"\nğŸ“ˆ ê°œì„  íš¨ê³¼:")
print(f"  ì¢…í•© ì ìˆ˜: {ai_avg:.3f} â†’ {improved_avg:.3f} (+{improved_avg-ai_avg:.3f})")
```

**AI ìƒì„± ì½”ë“œ ê²€ì¦ì˜ í•µì‹¬ ìš”ì†Œ**
- **ê¸°ëŠ¥ì  ì •í™•ì„±**: ì½”ë“œê°€ ì˜ë„í•œ ëŒ€ë¡œ ì‘ë™í•˜ëŠ”ê°€?
- **ì‹¤ë¬´ ì í•©ì„±**: ì‹¤ì œ ì—…ë¬´ í™˜ê²½ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œê°€?
- **ìœ ì§€ë³´ìˆ˜ì„±**: ì½”ë“œë¥¼ ì´í•´í•˜ê³  ìˆ˜ì •í•˜ê¸° ì‰¬ìš´ê°€?
- **í™•ì¥ ê°€ëŠ¥ì„±**: ìƒˆë¡œìš´ ìš”êµ¬ì‚¬í•­ì— ëŒ€ì‘í•  ìˆ˜ ìˆëŠ”ê°€?

---

### 6.21 ëª¨ë¸ í•´ì„ì„± í–¥ìƒ - AI ê²°ì • ê³¼ì •ì˜ íˆ¬ëª…ì„±

#### ğŸ” ë¸”ë™ë°•ìŠ¤ ëª¨ë¸ì„ íˆ¬ëª…í•˜ê²Œ ë§Œë“¤ê¸°

AIê°€ ë³µì¡í•œ ëª¨ë¸ì„ ì œì•ˆí•  ë•Œ, ê·¸ ê²°ì • ê³¼ì •ì„ ì´í•´í•˜ê³  ì„¤ëª…í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. íŠ¹íˆ ì˜ë£Œ, ê¸ˆìœµ ë“± ì¤‘ìš”í•œ ì˜ì‚¬ê²°ì • ì˜ì—­ì—ì„œëŠ” í•´ì„ ê°€ëŠ¥ì„±ì´ í•„ìˆ˜ì…ë‹ˆë‹¤.

```python
# ëª¨ë¸ í•´ì„ì„± ë„êµ¬ í™œìš©
print("ğŸ” ëª¨ë¸ í•´ì„ì„± í–¥ìƒ ê¸°ë²•")
print("=" * 40)

# í•´ì„ ê°€ëŠ¥í•œ ëª¨ë¸ êµ¬ì¶•
interpretable_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=8,
    min_samples_split=5,
    class_weight='balanced',
    random_state=42
)

interpretable_model.fit(X_train, y_train)

# 1. íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
feature_importance = interpretable_model.feature_importances_
importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': feature_importance
}).sort_values('importance', ascending=False)

print("ğŸ“Š íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ (ìƒìœ„ 10ê°œ):")
print(importance_df.head(10).to_string(index=False))

# íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”
plt.figure(figsize=(12, 8))
top_features = importance_df.head(15)

plt.subplot(2, 2, 1)
plt.barh(range(len(top_features)), top_features['importance'])
plt.yticks(range(len(top_features)), top_features['feature'])
plt.xlabel('ì¤‘ìš”ë„')
plt.title('ìƒìœ„ 15ê°œ íŠ¹ì„± ì¤‘ìš”ë„')
plt.gca().invert_yaxis()

# 2. ìˆœì—´ ì¤‘ìš”ë„ (Permutation Importance)
print(f"\nğŸ”„ ìˆœì—´ ì¤‘ìš”ë„ ë¶„ì„ (ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¸¡ì •):")

perm_importance = permutation_importance(
    interpretable_model, X_test, y_test, 
    n_repeats=10, random_state=42, scoring='accuracy'
)

perm_df = pd.DataFrame({
    'feature': feature_names,
    'importance_mean': perm_importance.importances_mean,
    'importance_std': perm_importance.importances_std
}).sort_values('importance_mean', ascending=False)

print("ìˆœì—´ ì¤‘ìš”ë„ (ìƒìœ„ 10ê°œ):")
print(perm_df.head(10)[['feature', 'importance_mean', 'importance_std']].to_string(index=False))

# ìˆœì—´ ì¤‘ìš”ë„ ì‹œê°í™”
plt.subplot(2, 2, 2)
top_perm = perm_df.head(10)
plt.barh(range(len(top_perm)), top_perm['importance_mean'])
plt.xerr = top_perm['importance_std']
plt.yticks(range(len(top_perm)), top_perm['feature'])
plt.xlabel('ìˆœì—´ ì¤‘ìš”ë„')
plt.title('ìˆœì—´ ì¤‘ìš”ë„ (ìƒìœ„ 10ê°œ)')
plt.gca().invert_yaxis()

# 3. ë¶€ë¶„ ì˜ì¡´ì„± í”Œë¡¯ (Partial Dependence Plot)
from sklearn.inspection import PartialDependenceDisplay

# ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±ë“¤ì˜ ë¶€ë¶„ ì˜ì¡´ì„± ë¶„ì„
top_feature_indices = [
    list(feature_names).index(top_features.iloc[0]['feature']),
    list(feature_names).index(top_features.iloc[1]['feature'])
]

plt.subplot(2, 2, 3)
PartialDependenceDisplay.from_estimator(
    interpretable_model, X_train, 
    features=[top_feature_indices[0]], 
    ax=plt.gca()
)
plt.title(f'{top_features.iloc[0]["feature"]} ë¶€ë¶„ ì˜ì¡´ì„±')

plt.subplot(2, 2, 4)
PartialDependenceDisplay.from_estimator(
    interpretable_model, X_train, 
    features=[top_feature_indices[1]], 
    ax=plt.gca()
)
plt.title(f'{top_features.iloc[1]["feature"]} ë¶€ë¶„ ì˜ì¡´ì„±')

plt.tight_layout()
plt.show()

# 4. SHAP (SHapley Additive exPlanations) ë¶„ì„ (ê°œë… ì„¤ëª…)
print(f"\nğŸ¯ SHAP ë¶„ì„ (ì„¤ì¹˜ í•„ìš”: pip install shap):")
print(f"SHAPëŠ” ê²Œì„ ì´ë¡ ì˜ ìƒ¤í”Œë¦¬ ê°’ì„ í™œìš©í•˜ì—¬ ê° íŠ¹ì„±ì´ ì˜ˆì¸¡ì— ê¸°ì—¬í•˜ëŠ” ì •ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.")

shap_explanation = """
SHAPì˜ í•µì‹¬ ê°œë…:
1. ê³µì •í•œ ê¸°ì—¬ë„ ê³„ì‚°: ê° íŠ¹ì„±ì´ ì˜ˆì¸¡ì— ì–¼ë§ˆë‚˜ ê¸°ì—¬í–ˆëŠ”ì§€ ê³µì •í•˜ê²Œ ì¸¡ì •
2. ì§€ì—­ì  í•´ì„: ê°œë³„ ì˜ˆì¸¡ì— ëŒ€í•œ ì„¤ëª… ì œê³µ
3. ì „ì—­ì  í•´ì„: ì „ì²´ ëª¨ë¸ì˜ í–‰ë™ íŒ¨í„´ ì´í•´
4. ì‹œê°í™”: ì›Œí„°í´ ì°¨íŠ¸, í¬ìŠ¤ í”Œë¡¯ ë“± ì§ê´€ì ì¸ ì‹œê°í™”

í™œìš© ì˜ˆì‹œ:
- íŠ¹ì • í™˜ìê°€ ì™œ 'ì•…ì„±'ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆëŠ”ì§€ ì„¤ëª…
- ì˜ë£Œì§„ì—ê²Œ ì§„ë‹¨ ê·¼ê±° ì œì‹œ
- ëª¨ë¸ì˜ í¸í–¥ì„± ê²€ì¦
"""

print(shap_explanation)
```

**ëª¨ë¸ í•´ì„ì„±ì˜ ì¤‘ìš”ì„±**
- **ì‹ ë¢°ì„± êµ¬ì¶•**: ì˜ì‚¬ê²°ì •ìê°€ ëª¨ë¸ì„ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê·¼ê±° ì œê³µ
- **ê·œì œ ì¤€ìˆ˜**: GDPR ë“± AI íˆ¬ëª…ì„± ìš”êµ¬ì‚¬í•­ ì¶©ì¡±
- **í¸í–¥ì„± ê²€ì¦**: ëª¨ë¸ì´ ê³µì •í•œ ê²°ì •ì„ ë‚´ë¦¬ëŠ”ì§€ í™•ì¸
- **ë„ë©”ì¸ ì§€ì‹ ê²€ì¦**: ëª¨ë¸ì˜ í•™ìŠµ íŒ¨í„´ì´ ì „ë¬¸ ì§€ì‹ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸

#### ğŸ“ˆ í•´ì„ ê°€ëŠ¥í•œ AI í˜‘ì—… ì›Œí¬í”Œë¡œìš°

```python
# í•´ì„ ê°€ëŠ¥í•œ AI í˜‘ì—… í”„ë¡œì„¸ìŠ¤
print("\nğŸ“ˆ í•´ì„ ê°€ëŠ¥í•œ AI í˜‘ì—… ì›Œí¬í”Œë¡œìš°")
print("=" * 50)

class InterpretableAIWorkflow:
    def __init__(self, model, X_train, y_train, X_test, y_test, feature_names):
        self.model = model
        self.X_train = X_train
        self.y_train = y_train
        self.X_test = X_test
        self.y_test = y_test
        self.feature_names = feature_names
        self.insights = {}
        
    def step1_basic_performance(self):
        """1ë‹¨ê³„: ê¸°ë³¸ ì„±ëŠ¥ í‰ê°€"""
        print("1ï¸âƒ£ ê¸°ë³¸ ì„±ëŠ¥ í‰ê°€")
        train_score = self.model.score(self.X_train, self.y_train)
        test_score = self.model.score(self.X_test, self.y_test)
        
        y_pred = self.model.predict(self.X_test)
        
        print(f"   í›ˆë ¨ ì •í™•ë„: {train_score:.4f}")
        print(f"   í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_score:.4f}")
        print(f"   ê³¼ì í•© ì •ë„: {train_score - test_score:.4f}")
        
        # í˜¼ë™ í–‰ë ¬
        cm = confusion_matrix(self.y_test, y_pred)
        tn, fp, fn, tp = cm.ravel()
        
        sensitivity = tp / (tp + fn)  # ë¯¼ê°ë„ (ì¬í˜„ìœ¨)
        specificity = tn / (tn + fp)  # íŠ¹ì´ë„
        
        print(f"   ë¯¼ê°ë„ (Sensitivity): {sensitivity:.4f}")
        print(f"   íŠ¹ì´ë„ (Specificity): {specificity:.4f}")
        
        self.insights['performance'] = {
            'test_accuracy': test_score,
            'sensitivity': sensitivity,
            'specificity': specificity
        }
        
    def step2_feature_analysis(self):
        """2ë‹¨ê³„: íŠ¹ì„± ë¶„ì„"""
        print(f"\n2ï¸âƒ£ íŠ¹ì„± ë¶„ì„ ë° ë„ë©”ì¸ ì§€ì‹ ê²€ì¦")
        
        # íŠ¹ì„± ì¤‘ìš”ë„
        importance = self.model.feature_importances_
        top_features = sorted(zip(self.feature_names, importance), 
                            key=lambda x: x[1], reverse=True)[:5]
        
        print(f"   ìƒìœ„ 5ê°œ ì¤‘ìš” íŠ¹ì„±:")
        for i, (feature, imp) in enumerate(top_features, 1):
            print(f"     {i}. {feature}: {imp:.4f}")
        
        # ë„ë©”ì¸ ì§€ì‹ê³¼ ë¹„êµ
        medical_knowledge = {
            'worst perimeter': 'ì¢…ì–‘ ê²½ê³„ ê¸¸ì´ - ì•…ì„±ì¼ìˆ˜ë¡ ë¶ˆê·œì¹™',
            'worst area': 'ì¢…ì–‘ ë©´ì  - í¬ê¸°ì™€ ì•…ì„±ë„ ê´€ë ¨',
            'worst radius': 'ì¢…ì–‘ ë°˜ì§€ë¦„ - í¬ê¸° ì§€í‘œ',
            'worst concave points': 'ì˜¤ëª©í•œ ë¶€ë¶„ - ì•…ì„± íŠ¹ì§•',
            'mean concave points': 'í‰ê·  ì˜¤ëª©í•œ ë¶€ë¶„'
        }
        
        print(f"\n   ë„ë©”ì¸ ì§€ì‹ ê²€ì¦:")
        for feature, imp in top_features:
            if feature in medical_knowledge:
                print(f"     âœ“ {feature}: {medical_knowledge[feature]}")
            else:
                print(f"     ? {feature}: ë„ë©”ì¸ ì „ë¬¸ê°€ ê²€í†  í•„ìš”")
        
        self.insights['top_features'] = top_features
        
    def step3_decision_boundary_analysis(self):
        """3ë‹¨ê³„: ì˜ì‚¬ê²°ì • ê²½ê³„ ë¶„ì„"""
        print(f"\n3ï¸âƒ£ ì˜ì‚¬ê²°ì • ê²½ê³„ ë¶„ì„")
        
        # í™•ë¥  ì˜ˆì¸¡ìœ¼ë¡œ ì‹ ë¢°ë„ ë¶„ì„
        y_proba = self.model.predict_proba(self.X_test)
        confidence_scores = np.max(y_proba, axis=1)
        
        # ì‹ ë¢°ë„ë³„ ë¶„í¬
        low_confidence = np.sum(confidence_scores < 0.7)
        medium_confidence = np.sum((confidence_scores >= 0.7) & (confidence_scores < 0.9))
        high_confidence = np.sum(confidence_scores >= 0.9)
        
        total = len(confidence_scores)
        print(f"   ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„í¬:")
        print(f"     ë†’ìŒ (â‰¥0.9): {high_confidence}ê°œ ({high_confidence/total*100:.1f}%)")
        print(f"     ë³´í†µ (0.7-0.9): {medium_confidence}ê°œ ({medium_confidence/total*100:.1f}%)")
        print(f"     ë‚®ìŒ (<0.7): {low_confidence}ê°œ ({low_confidence/total*100:.1f}%)")
        
        if low_confidence > total * 0.1:
            print(f"   âš ï¸ ì£¼ì˜: ì‹ ë¢°ë„ê°€ ë‚®ì€ ì˜ˆì¸¡ì´ {low_confidence/total*100:.1f}%")
            print(f"     â†’ ì¶”ê°€ ê²€ì¦ì´ë‚˜ ë” ë§ì€ ë°ì´í„° í•„ìš”")
        
        self.insights['confidence'] = {
            'high': high_confidence/total,
            'medium': medium_confidence/total,
            'low': low_confidence/total
        }
    
    def step4_business_recommendations(self):
        """4ë‹¨ê³„: ë¹„ì¦ˆë‹ˆìŠ¤ ê¶Œê³ ì‚¬í•­"""
        print(f"\n4ï¸âƒ£ ë¹„ì¦ˆë‹ˆìŠ¤ ê¶Œê³ ì‚¬í•­")
        
        performance = self.insights['performance']
        confidence = self.insights['confidence']
        
        recommendations = []
        
        # ë¯¼ê°ë„ ê¸°ë°˜ ê¶Œê³ 
        if performance['sensitivity'] >= 0.95:
            recommendations.append("âœ… ë†’ì€ ë¯¼ê°ë„ë¡œ ì•…ì„± ì¢…ì–‘ ë†“ì¹  ìœ„í—˜ ë‚®ìŒ")
        elif performance['sensitivity'] >= 0.90:
            recommendations.append("âš ï¸ ë¯¼ê°ë„ ë³´í†µ - ì„ê³„ê°’ ì¡°ì • ê³ ë ¤")
        else:
            recommendations.append("ğŸš¨ ë¯¼ê°ë„ ë‚®ìŒ - ëª¨ë¸ ê°œì„  í•„ìš”")
        
        # íŠ¹ì´ë„ ê¸°ë°˜ ê¶Œê³ 
        if performance['specificity'] >= 0.90:
            recommendations.append("âœ… ë†’ì€ íŠ¹ì´ë„ë¡œ ë¶ˆí•„ìš”í•œ ìƒê²€ ìµœì†Œí™”")
        else:
            recommendations.append("âš ï¸ íŠ¹ì´ë„ ê°œì„ ìœ¼ë¡œ ê±°ì§“ ì–‘ì„± ê°ì†Œ í•„ìš”")
        
        # ì‹ ë¢°ë„ ê¸°ë°˜ ê¶Œê³ 
        if confidence['low'] > 0.15:
            recommendations.append("ğŸ” ì‹ ë¢°ë„ ë‚®ì€ ì¼€ì´ìŠ¤ëŠ” ì „ë¬¸ì˜ ì¬ê²€í† ")
        
        print(f"   ê¶Œê³ ì‚¬í•­:")
        for i, rec in enumerate(recommendations, 1):
            print(f"     {i}. {rec}")
        
        # ë°°í¬ ì¤€ë¹„ë„ í‰ê°€
        deployment_score = (
            performance['test_accuracy'] * 0.3 +
            performance['sensitivity'] * 0.4 +
            performance['specificity'] * 0.2 +
            (1 - confidence['low']) * 0.1
        )
        
        print(f"\n   ë°°í¬ ì¤€ë¹„ë„: {deployment_score:.3f}")
        if deployment_score >= 0.9:
            print(f"     ğŸŸ¢ ë°°í¬ ê¶Œì¥")
        elif deployment_score >= 0.8:
            print(f"     ğŸŸ¡ ì œí•œì  ë°°í¬ (ì „ë¬¸ê°€ ê²€í†  í•„ìˆ˜)")
        else:
            print(f"     ğŸ”´ ì¶”ê°€ ê°œì„  í•„ìš”")

# í•´ì„ ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
workflow = InterpretableAIWorkflow(
    interpretable_model, X_train, y_train, X_test, y_test, feature_names
)

workflow.step1_basic_performance()
workflow.step2_feature_analysis()
workflow.step3_decision_boundary_analysis()
workflow.step4_business_recommendations()
```

**í•´ì„ ê°€ëŠ¥í•œ AIì˜ í•µì‹¬ ê°€ì¹˜**
- **íˆ¬ëª…ì„±**: ê²°ì • ê³¼ì •ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…
- **ì‹ ë¢°ì„±**: ì˜ˆì¸¡ì˜ ì‹ ë¢°ë„ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ì œì‹œ
- **ì‹¤ìš©ì„±**: ì‹¤ì œ ì—…ë¬´ì— í™œìš© ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì œê³µ
- **ì±…ì„ì„±**: AI ê²°ì •ì— ëŒ€í•œ ì¸ê°„ì˜ ì±…ì„ ìˆëŠ” ê°ë…

---

### 6.22 ì¸ê°„-AI í˜‘ì—… ëª¨ë¸ì˜ í’ˆì§ˆ ê´€ë¦¬

#### ğŸ›¡ï¸ í˜‘ì—… ëª¨ë¸ì˜ ì•ˆì •ì„± ê²€ì¦

AIì™€ í˜‘ì—…í•´ì„œ ë§Œë“  ëª¨ë¸ì´ ì‹¤ì œ í™˜ê²½ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ ê²€ì¦í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

```python
# ëª¨ë¸ ì•ˆì •ì„± ë° ê²¬ê³ ì„± í…ŒìŠ¤íŠ¸
print("ğŸ›¡ï¸ í˜‘ì—… ëª¨ë¸ì˜ ì•ˆì •ì„± ê²€ì¦")
print("=" * 50)

class ModelRobustnessValidator:
    def __init__(self, model, X_test, y_test, feature_names):
        self.model = model
        self.X_test = X_test
        self.y_test = y_test
        self.feature_names = feature_names
        
    def test_data_drift(self, X_new=None):
        """ë°ì´í„° ë“œë¦¬í”„íŠ¸ ì‹œë®¬ë ˆì´ì…˜"""
        print("1ï¸âƒ£ ë°ì´í„° ë“œë¦¬í”„íŠ¸ ë‚´ì„± í…ŒìŠ¤íŠ¸")
        
        if X_new is None:
            # ê°€ìƒì˜ ë“œë¦¬í”„íŠ¸ ì‹œë®¬ë ˆì´ì…˜ (ë…¸ì´ì¦ˆ ì¶”ê°€)
            noise_levels = [0.0, 0.1, 0.2, 0.3]
            baseline_score = self.model.score(self.X_test, self.y_test)
            
            print(f"   ê¸°ì¤€ ì„±ëŠ¥: {baseline_score:.4f}")
            print(f"   ë…¸ì´ì¦ˆ ìˆ˜ì¤€ë³„ ì„±ëŠ¥ ë³€í™”:")
            
            for noise in noise_levels[1:]:
                # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€
                X_noisy = self.X_test + np.random.normal(0, noise * np.std(self.X_test, axis=0), self.X_test.shape)
                noisy_score = self.model.score(X_noisy, self.y_test)
                performance_drop = baseline_score - noisy_score
                
                status = "ğŸŸ¢" if performance_drop < 0.05 else "ğŸŸ¡" if performance_drop < 0.1 else "ğŸ”´"
                print(f"     ë…¸ì´ì¦ˆ {noise*100:2.0f}%: {noisy_score:.4f} ({performance_drop:+.4f}) {status}")
        
    def test_feature_corruption(self):
        """íŠ¹ì„± ëˆ„ë½/ì†ìƒ í…ŒìŠ¤íŠ¸"""
        print(f"\n2ï¸âƒ£ íŠ¹ì„± ëˆ„ë½ ë‚´ì„± í…ŒìŠ¤íŠ¸")
        
        baseline_score = self.model.score(self.X_test, self.y_test)
        feature_importance = self.model.feature_importances_
        
        # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬ëœ íŠ¹ì„± ì¸ë±ìŠ¤
        sorted_indices = np.argsort(feature_importance)[::-1]
        
        print(f"   ê¸°ì¤€ ì„±ëŠ¥: {baseline_score:.4f}")
        print(f"   íŠ¹ì„± ì œê±° ì‹œ ì„±ëŠ¥ ë³€í™”:")
        
        for i in range(min(5, len(sorted_indices))):
            # ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±ë¶€í„° í•˜ë‚˜ì”© ì œê±°
            indices_to_remove = sorted_indices[:i+1]
            X_corrupted = self.X_test.copy()
            X_corrupted[:, indices_to_remove] = 0  # íŠ¹ì„±ì„ 0ìœ¼ë¡œ ì„¤ì •
            
            corrupted_score = self.model.score(X_corrupted, self.y_test)
            performance_drop = baseline_score - corrupted_score
            
            removed_features = [self.feature_names[idx] for idx in indices_to_remove]
            status = "ğŸŸ¢" if performance_drop < 0.1 else "ğŸŸ¡" if performance_drop < 0.2 else "ğŸ”´"
            
            print(f"     ìƒìœ„ {i+1}ê°œ ì œê±°: {corrupted_score:.4f} ({performance_drop:+.4f}) {status}")
            if i == 0:
                print(f"       ì œê±°ëœ íŠ¹ì„±: {removed_features[0]}")
    
    def test_prediction_consistency(self):
        """ì˜ˆì¸¡ ì¼ê´€ì„± í…ŒìŠ¤íŠ¸"""
        print(f"\n3ï¸âƒ£ ì˜ˆì¸¡ ì¼ê´€ì„± í…ŒìŠ¤íŠ¸")
        
        # ë™ì¼í•œ ì…ë ¥ì— ëŒ€í•œ ì—¬ëŸ¬ ë²ˆì˜ ì˜ˆì¸¡ (ëœë¤ ì‹œë“œê°€ ë‹¤ë¥¸ ê²½ìš°)
        sample_size = min(100, len(self.X_test))
        X_sample = self.X_test[:sample_size]
        
        predictions_list = []
        for seed in range(10):
            # ëª¨ë¸ì´ RandomForestì¸ ê²½ìš° ìƒˆë¡œìš´ ì‹œë“œë¡œ ì¬í›ˆë ¨
            test_model = RandomForestClassifier(
                n_estimators=100, max_depth=8, min_samples_split=5,
                class_weight='balanced', random_state=seed
            )
            test_model.fit(self.X_test, self.y_test)  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©
            predictions_list.append(test_model.predict(X_sample))
        
        # ì˜ˆì¸¡ ì¼ê´€ì„± ê³„ì‚°
        predictions_array = np.array(predictions_list)
        consistency_scores = []
        
        for i in range(sample_size):
            sample_predictions = predictions_array[:, i]
            # ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ì˜ˆì¸¡ì˜ ë¹„ìœ¨
            unique, counts = np.unique(sample_predictions, return_counts=True)
            max_agreement = np.max(counts) / len(sample_predictions)
            consistency_scores.append(max_agreement)
        
        avg_consistency = np.mean(consistency_scores)
        low_consistency_ratio = np.mean(np.array(consistency_scores) < 0.7)
        
        print(f"   í‰ê·  ì˜ˆì¸¡ ì¼ê´€ì„±: {avg_consistency:.4f}")
        print(f"   ì¼ê´€ì„± ë‚®ì€ ìƒ˜í”Œ: {low_consistency_ratio*100:.1f}%")
        
        if avg_consistency >= 0.9:
            print(f"   ğŸŸ¢ ë†’ì€ ì¼ê´€ì„± - ì•ˆì •ì ì¸ ëª¨ë¸")
        elif avg_consistency >= 0.8:
            print(f"   ğŸŸ¡ ë³´í†µ ì¼ê´€ì„± - ì¼ë¶€ ë¶ˆì•ˆì •ì„±")
        else:
            print(f"   ğŸ”´ ë‚®ì€ ì¼ê´€ì„± - ëª¨ë¸ ì•ˆì •ì„± ê°œì„  í•„ìš”")
    
    def generate_robustness_report(self):
        """ì¢…í•© ê²¬ê³ ì„± ë³´ê³ ì„œ"""
        print(f"\nğŸ“‹ ëª¨ë¸ ê²¬ê³ ì„± ì¢…í•© í‰ê°€")
        print("-" * 40)
        
        robustness_aspects = [
            "ë°ì´í„° í’ˆì§ˆ ë³€í™” ëŒ€ì‘ëŠ¥ë ¥",
            "í•µì‹¬ íŠ¹ì„± ëˆ„ë½ ì‹œ ë³µì›ë ¥", 
            "ì˜ˆì¸¡ ê²°ê³¼ì˜ ì¼ê´€ì„±",
            "ë„ë©”ì¸ ì§€ì‹ê³¼ì˜ ì¼ì¹˜ì„±",
            "í•´ì„ ê°€ëŠ¥ì„±ê³¼ íˆ¬ëª…ì„±"
        ]
        
        # ê°€ìƒì˜ í‰ê°€ ì ìˆ˜
        scores = np.random.uniform(0.7, 0.95, len(robustness_aspects))
        
        print(f"{'í‰ê°€ í•­ëª©':<25} {'ì ìˆ˜':<8} {'ë“±ê¸‰'}")
        print("-" * 45)
        
        total_score = 0
        for aspect, score in zip(robustness_aspects, scores):
            grade = "A" if score >= 0.9 else "B" if score >= 0.8 else "C"
            print(f"{aspect:<25} {score:<8.3f} {grade}")
            total_score += score
        
        avg_score = total_score / len(scores)
        overall_grade = "A" if avg_score >= 0.9 else "B" if avg_score >= 0.8 else "C"
        
        print(f"\nì¢…í•© í‰ê°€: {avg_score:.3f} (ë“±ê¸‰: {overall_grade})")
        
        if overall_grade == "A":
            print("ğŸŸ¢ ë°°í¬ ê¶Œì¥ - í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì•ˆì •ì  ì‚¬ìš© ê°€ëŠ¥")
        elif overall_grade == "B": 
            print("ğŸŸ¡ ì¡°ê±´ë¶€ ë°°í¬ - ëª¨ë‹ˆí„°ë§ê³¼ í•¨ê»˜ ì œí•œì  ì‚¬ìš©")
        else:
            print("ğŸ”´ ê°œì„  í•„ìš” - ì¶”ê°€ ê²€ì¦ ë° ëª¨ë¸ ê°œì„  í›„ ì¬í‰ê°€")

# ê²¬ê³ ì„± ê²€ì¦ ì‹¤í–‰
robustness_validator = ModelRobustnessValidator(
    interpretable_model, X_test, y_test, feature_names
)

robustness_validator.test_data_drift()
robustness_validator.test_feature_corruption()
robustness_validator.test_prediction_consistency()
robustness_validator.generate_robustness_report()
```

**ëª¨ë¸ ê²¬ê³ ì„±ì˜ í•µì‹¬ ìš”ì†Œ**
- **ë°ì´í„° ë‚´ì„±**: ì…ë ¥ ë°ì´í„° í’ˆì§ˆ ë³€í™”ì— ëŒ€í•œ ì•ˆì •ì„±
- **íŠ¹ì„± ë³µì›ë ¥**: ì¼ë¶€ íŠ¹ì„± ëˆ„ë½ ì‹œì—ë„ í•©ë¦¬ì  ì„±ëŠ¥ ìœ ì§€
- **ì˜ˆì¸¡ ì¼ê´€ì„±**: ë™ì¼ ì¡°ê±´ì—ì„œ ì¼ê´€ëœ ê²°ê³¼ ìƒì„±
- **í•´ì„ ì•ˆì •ì„±**: í•´ì„ ê²°ê³¼ê°€ ì¼ê´€ë˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆìŒ

---

### 6.23 ì‹¤ìŠµ í”„ë¡œì íŠ¸: ì§€ëŠ¥ì  í˜‘ì—… ëª¨ë¸ë§ ì‹œìŠ¤í…œ

ì´ì œ ëª¨ë“  ê°œë…ì„ í†µí•©í•˜ì—¬ AIì™€ í˜‘ì—…í•˜ëŠ” ì™„ì „í•œ ëª¨ë¸ë§ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•´ë³´ê² ìŠµë‹ˆë‹¤.

```python
# ì¢…í•© AI í˜‘ì—… ëª¨ë¸ë§ ì‹œìŠ¤í…œ
print("ğŸš€ ì§€ëŠ¥ì  í˜‘ì—… ëª¨ë¸ë§ ì‹œìŠ¤í…œ êµ¬ì¶•")
print("=" * 60)

class IntelligentCollaborativeML:
    def __init__(self, problem_type="classification"):
        self.problem_type = problem_type
        self.models = {}
        self.evaluations = {}
        self.ai_suggestions = {}
        self.human_improvements = {}
        self.final_model = None
        
    def simulate_ai_suggestions(self, X, y):
        """AIê°€ ì œì•ˆí•˜ëŠ” ì´ˆê¸° ëª¨ë¸ë“¤ ì‹œë®¬ë ˆì´ì…˜"""
        print("ğŸ¤– AI ì œì•ˆ ëª¨ë¸ ìƒì„± ì¤‘...")
        
        # AIê°€ ì œì•ˆí•  ë§Œí•œ ë‹¤ì–‘í•œ ëª¨ë¸ë“¤
        ai_models = {
            'AI_Basic_RF': RandomForestClassifier(random_state=42),
            'AI_Balanced_RF': RandomForestClassifier(class_weight='balanced', random_state=42),
            'AI_Boosting': GradientBoostingClassifier(random_state=42)
        }
        
        suggestions = {}
        for name, model in ai_models.items():
            model.fit(X, y)
            cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
            
            suggestions[name] = {
                'model': model,
                'cv_mean': np.mean(cv_scores),
                'cv_std': np.std(cv_scores),
                'rationale': self._get_ai_rationale(name)
            }
        
        self.ai_suggestions = suggestions
        
        print("AI ì œì•ˆ ëª¨ë¸ ìš”ì•½:")
        for name, info in suggestions.items():
            print(f"  {name}: CV={info['cv_mean']:.4f}Â±{info['cv_std']:.4f}")
            print(f"    ê·¼ê±°: {info['rationale']}")
        
        return suggestions
    
    def _get_ai_rationale(self, model_name):
        """AI ëª¨ë¸ ì œì•ˆ ê·¼ê±° ì‹œë®¬ë ˆì´ì…˜"""
        rationales = {
            'AI_Basic_RF': "ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ì— ì í•©",
            'AI_Balanced_RF': "í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ì‹¤ìš©ì  ì ‘ê·¼",
            'AI_Boosting': "ìˆœì°¨ì  í•™ìŠµìœ¼ë¡œ ë†’ì€ ì„±ëŠ¥ ê¸°ëŒ€"
        }
        return rationales.get(model_name, "ì¼ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ì•Œê³ ë¦¬ì¦˜")
    
    def apply_human_expertise(self, X, y, domain_knowledge):
        """ì¸ê°„ ì „ë¬¸ê°€ì˜ ì§€ì‹ì„ ë°˜ì˜í•œ ëª¨ë¸ ê°œì„ """
        print(f"\nğŸ‘¨â€ğŸ’¼ ì¸ê°„ ì „ë¬¸ê°€ ê°œì„  ì ìš©...")
        
        # ì¸ê°„ ì „ë¬¸ê°€ê°€ ê°œì„ í•œ ëª¨ë¸ë“¤
        expert_models = {}
        
        # 1. ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ íŠ¹ì„± ì„ íƒ
        if 'important_features' in domain_knowledge:
            important_indices = domain_knowledge['important_features']
            X_selected = X[:, important_indices]
            
            expert_models['Expert_Feature_Selected'] = {
                'model': RandomForestClassifier(
                    n_estimators=200, max_depth=10, min_samples_split=5,
                    class_weight='balanced', random_state=42
                ),
                'X': X_selected,
                'rationale': "ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ í•µì‹¬ íŠ¹ì„± ì„ íƒ"
            }
        
        # 2. ì˜ë£Œ íŠ¹í™” ìµœì í™” (ë¯¼ê°ë„ ìš°ì„ )
        expert_models['Expert_Medical_Optimized'] = {
            'model': RandomForestClassifier(
                n_estimators=300, max_depth=12, min_samples_split=3,
                min_samples_leaf=1, class_weight={0: 1, 1: 3},  # ì•…ì„±(1)ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
                random_state=42
            ),
            'X': X,
            'rationale': "ì˜ë£Œ ì§„ë‹¨ íŠ¹ì„± ë°˜ì˜ - ê±°ì§“ ìŒì„± ìµœì†Œí™” ìš°ì„ "
        }
        
        # 3. í•´ì„ì„± ì¤‘ì‹œ ëª¨ë¸
        expert_models['Expert_Interpretable'] = {
            'model': RandomForestClassifier(
                n_estimators=100, max_depth=6, min_samples_split=10,
                class_weight='balanced', random_state=42
            ),
            'X': X,
            'rationale': "í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì„±ëŠ¥ì˜ ê· í˜•"
        }
        
        # ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€
        expert_evaluations = {}
        for name, config in expert_models.items():
            model = config['model']
            X_data = config['X']
            
            model.fit(X_data, y)
            cv_scores = cross_val_score(model, X_data, y, cv=5, scoring='recall')  # ë¯¼ê°ë„ ì¤‘ì‹œ
            
            expert_evaluations[name] = {
                'model': model,
                'X_data': X_data,
                'cv_mean': np.mean(cv_scores),
                'cv_std': np.std(cv_scores),
                'rationale': config['rationale']
            }
        
        self.human_improvements = expert_evaluations
        
        print("ì¸ê°„ ì „ë¬¸ê°€ ê°œì„  ëª¨ë¸ ìš”ì•½:")
        for name, info in expert_evaluations.items():
            print(f"  {name}: Recall={info['cv_mean']:.4f}Â±{info['cv_std']:.4f}")
            print(f"    ê·¼ê±°: {info['rationale']}")
        
        return expert_evaluations
    
    def collaborative_model_selection(self):
        """AIì™€ ì¸ê°„ì˜ í˜‘ì—…ìœ¼ë¡œ ìµœì¢… ëª¨ë¸ ì„ íƒ"""
        print(f"\nğŸ¤ í˜‘ì—… ê¸°ë°˜ ìµœì¢… ëª¨ë¸ ì„ íƒ")
        
        # ëª¨ë“  í›„ë³´ ëª¨ë¸ í†µí•©
        all_candidates = {}
        all_candidates.update(self.ai_suggestions)
        all_candidates.update(self.human_improvements)
        
        # ë‹¤ì¤‘ ê¸°ì¤€ í‰ê°€
        evaluation_criteria = {
            'performance': 0.4,    # ì„±ëŠ¥ (40%)
            'interpretability': 0.3,  # í•´ì„ì„± (30%)
            'robustness': 0.2,     # ê²¬ê³ ì„± (20%)
            'efficiency': 0.1      # íš¨ìœ¨ì„± (10%)
        }
        
        print(f"ë‹¤ì¤‘ ê¸°ì¤€ í‰ê°€ (ê°€ì¤‘ì¹˜):")
        for criterion, weight in evaluation_criteria.items():
            print(f"  {criterion}: {weight*100:.0f}%")
        
        # ê° ëª¨ë¸ì˜ ì¢…í•© ì ìˆ˜ ê³„ì‚°
        final_scores = {}
        for name, info in all_candidates.items():
            # ì„±ëŠ¥ ì ìˆ˜ (êµì°¨ ê²€ì¦ ê²°ê³¼)
            performance_score = info['cv_mean']
            
            # í•´ì„ì„± ì ìˆ˜ (ë‹¨ìˆœí•œ ëª¨ë¸ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            if 'Interpretable' in name or 'Feature_Selected' in name:
                interpretability_score = 0.9
            elif 'Basic' in name:
                interpretability_score = 0.8
            else:
                interpretability_score = 0.7
            
            # ê²¬ê³ ì„± ì ìˆ˜ (í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            robustness_score = 1 - info['cv_std']
            
            # íš¨ìœ¨ì„± ì ìˆ˜ (ëª¨ë¸ ë³µì¡ë„ ê¸°ë°˜)
            if 'Basic' in name:
                efficiency_score = 0.9
            elif 'Boosting' in name:
                efficiency_score = 0.6
            else:
                efficiency_score = 0.8
            
            # ì¢…í•© ì ìˆ˜ ê³„ì‚°
            total_score = (
                performance_score * evaluation_criteria['performance'] +
                interpretability_score * evaluation_criteria['interpretability'] +
                robustness_score * evaluation_criteria['robustness'] +
                efficiency_score * evaluation_criteria['efficiency']
            )
            
            final_scores[name] = {
                'total_score': total_score,
                'performance': performance_score,
                'interpretability': interpretability_score,
                'robustness': robustness_score,
                'efficiency': efficiency_score
            }
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼:")
        print(f"{'ëª¨ë¸ëª…':<25} {'ì¢…í•©ì ìˆ˜':<10} {'ì„±ëŠ¥':<8} {'í•´ì„ì„±':<8} {'ê²¬ê³ ì„±':<8} {'íš¨ìœ¨ì„±'}")
        print("-" * 80)
        
        sorted_models = sorted(final_scores.items(), key=lambda x: x[1]['total_score'], reverse=True)
        
        for name, scores in sorted_models:
            print(f"{name:<25} {scores['total_score']:<10.4f} {scores['performance']:<8.4f} "
                  f"{scores['interpretability']:<8.4f} {scores['robustness']:<8.4f} {scores['efficiency']:<8.4f}")
        
        # ìµœê³  ì ìˆ˜ ëª¨ë¸ ì„ íƒ
        best_model_name = sorted_models[0][0]
        self.final_model = {
            'name': best_model_name,
            'model': all_candidates[best_model_name]['model'],
            'scores': final_scores[best_model_name]
        }
        
        print(f"\nğŸ† ì„ íƒëœ ìµœì¢… ëª¨ë¸: {best_model_name}")
        print(f"   ì¢…í•© ì ìˆ˜: {final_scores[best_model_name]['total_score']:.4f}")
        
        return self.final_model
    
    def generate_deployment_guide(self):
        """ë°°í¬ ê°€ì´ë“œ ìƒì„±"""
        print(f"\nğŸ“‹ ë°°í¬ ê°€ì´ë“œ ë° ëª¨ë‹ˆí„°ë§ ê³„íš")
        print("-" * 50)
        
        guide = {
            'ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸': [
                "âœ“ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ ì™„ë£Œ",
                "âœ“ í•´ì„ì„± ê²€ì¦ ì™„ë£Œ", 
                "âœ“ ê²¬ê³ ì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ",
                "âœ“ ë„ë©”ì¸ ì „ë¬¸ê°€ ìŠ¹ì¸",
                "âœ“ ìœ¤ë¦¬ì  ê²€í†  ì™„ë£Œ"
            ],
            
            'ëª¨ë‹ˆí„°ë§ ì§€í‘œ': [
                "ì˜ˆì¸¡ ì •í™•ë„ (ì£¼ê°„ ë‹¨ìœ„)",
                "ë¯¼ê°ë„/íŠ¹ì´ë„ ì¶”ì´",
                "ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„í¬",
                "ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€",
                "ì‚¬ìš©ì í”¼ë“œë°± ì ìˆ˜"
            ],
            
            'ì¬í›ˆë ¨ ì¡°ê±´': [
                "ì„±ëŠ¥ ì§€í‘œ 5% ì´ìƒ ì €í•˜",
                "ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€",
                "ìƒˆë¡œìš´ ì„ìƒ ê°€ì´ë“œë¼ì¸ ë°˜ì˜",
                "ë¶„ê¸°ë³„ ì •ê¸° ì—…ë°ì´íŠ¸"
            ],
            
            'ì˜ˆì™¸ ìƒí™© ëŒ€ì‘': [
                "ì‹ ë¢°ë„ ë‚®ì€ ì˜ˆì¸¡ ì‹œ ì „ë¬¸ì˜ ê²€í† ",
                "ì‹œìŠ¤í…œ ì¥ì•  ì‹œ ë°±ì—… ëª¨ë¸ í™œìš©",
                "ìƒˆë¡œìš´ ë°ì´í„° íŒ¨í„´ ë°œê²¬ ì‹œ ì¦‰ì‹œ ê²€í† "
            ]
        }
        
        for section, items in guide.items():
            print(f"\n{section}:")
            for item in items:
                print(f"  â€¢ {item}")
        
        return guide

# ì§€ëŠ¥ì  í˜‘ì—… ì‹œìŠ¤í…œ ì‹¤í–‰
collaborative_system = IntelligentCollaborativeML()

# ë„ë©”ì¸ ì§€ì‹ ì •ì˜ (ì˜ë£Œ ì „ë¬¸ê°€ ì…ë ¥)
medical_domain_knowledge = {
    'important_features': [0, 1, 2, 20, 21, 22],  # ì˜ˆì‹œ: í¬ê¸° ê´€ë ¨ íŠ¹ì„±ë“¤
    'class_priority': 'sensitivity',  # ë¯¼ê°ë„ ìš°ì„ 
    'interpretability_required': True
}

# 1. AI ì œì•ˆ ëª¨ë¸ ìƒì„±
ai_suggestions = collaborative_system.simulate_ai_suggestions(X_train, y_train)

# 2. ì¸ê°„ ì „ë¬¸ê°€ ê°œì„  ì ìš©  
human_improvements = collaborative_system.apply_human_expertise(
    X_train, y_train, medical_domain_knowledge
)

# 3. í˜‘ì—… ê¸°ë°˜ ìµœì¢… ëª¨ë¸ ì„ íƒ
final_model = collaborative_system.collaborative_model_selection()

# 4. ë°°í¬ ê°€ì´ë“œ ìƒì„±
deployment_guide = collaborative_system.generate_deployment_guide()

print(f"\nğŸ‰ ì¸ê°„-AI í˜‘ì—… ëª¨ë¸ë§ ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ!")
print(f"ìµœì¢… ì„ íƒ ëª¨ë¸: {final_model['name']}")
print(f"ì¢…í•© ì„±ëŠ¥ ì ìˆ˜: {final_model['scores']['total_score']:.4f}")
```

**í˜‘ì—… ëª¨ë¸ë§ ì‹œìŠ¤í…œì˜ í•µì‹¬ ê°€ì¹˜**
- **ë‹¤ì–‘í•œ ê´€ì  ìœµí•©**: AIì˜ ë°ì´í„° ì¤‘ì‹¬ + ì¸ê°„ì˜ ì§ê´€ê³¼ ê²½í—˜
- **ê· í˜• ì¡íŒ í‰ê°€**: ì„±ëŠ¥ë¿ë§Œ ì•„ë‹ˆë¼ í•´ì„ì„±, ê²¬ê³ ì„±, íš¨ìœ¨ì„± ì¢…í•© ê³ ë ¤  
- **ì‹¤ë¬´ ì ìš©ì„±**: ë°°í¬ì™€ ìš´ì˜ì„ ê³ ë ¤í•œ ì‹¤ìš©ì  ì ‘ê·¼
- **ì§€ì†ì  ê°œì„ **: ëª¨ë‹ˆí„°ë§ê³¼ í”¼ë“œë°±ì„ í†µí•œ ì ì§„ì  ë°œì „

---

### ğŸ’ª ì§ì ‘ í•´ë³´ê¸° - ì—°ìŠµ ë¬¸ì œ

#### ğŸ¯ ì—°ìŠµ ë¬¸ì œ 1: AI ì½”ë“œ í’ˆì§ˆ í‰ê°€ê¸° êµ¬í˜„
AIê°€ ìƒì„±í•œ ì½”ë“œì˜ í’ˆì§ˆì„ ìë™ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ì‹œìŠ¤í…œì„ ë§Œë“¤ì–´ë³´ì„¸ìš”.

```python
# TODO: ì½”ë“œë¥¼ ì™„ì„±í•˜ì„¸ìš”
class AICodeQualityEvaluator:
    def __init__(self):
        # TODO: ì´ˆê¸°í™”
        pass
    
    def evaluate_functionality(self, code_string):
        """ê¸°ëŠ¥ì„± í‰ê°€: ì½”ë“œê°€ ì‹¤í–‰ë˜ê³  ì˜ˆìƒ ê²°ê³¼ë¥¼ ì‚°ì¶œí•˜ëŠ”ê°€?"""
        # TODO: êµ¬í˜„
        # íŒíŠ¸: exec() í•¨ìˆ˜ë¡œ ì½”ë“œ ì‹¤í–‰, try-exceptë¡œ ì˜¤ë¥˜ í¬ì°©
        pass
    
    def evaluate_best_practices(self, code_string):
        """ëª¨ë²”ì‚¬ë¡€ í‰ê°€: ë³€ìˆ˜ëª…, ì£¼ì„, êµ¬ì¡°í™” ë“±"""
        # TODO: êµ¬í˜„  
        # íŒíŠ¸: ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ íŒ¨í„´ ê²€ìƒ‰, ì½”ë“œ ë¼ì¸ ìˆ˜ ê³„ì‚°
        pass
    
    def evaluate_domain_relevance(self, code_string, domain="medical"):
        """ë„ë©”ì¸ ì í•©ì„± í‰ê°€: ì˜ë£Œ ë„ë©”ì¸ì— ì ì ˆí•œ ì ‘ê·¼ì¸ê°€?"""
        # TODO: êµ¬í˜„
        # íŒíŠ¸: í‚¤ì›Œë“œ ê²€ìƒ‰, í‰ê°€ ì§€í‘œ í™•ì¸ (precision vs recall ë“±)
        pass
    
    def generate_improvement_suggestions(self, evaluation_results):
        """ê°œì„ ì‚¬í•­ ì œì•ˆ"""
        # TODO: êµ¬í˜„
        pass

# í…ŒìŠ¤íŠ¸í•  AI ìƒì„± ì½”ë“œ ì˜ˆì‹œë“¤
ai_codes = [
    "model = RandomForestClassifier()\nmodel.fit(X, y)",
    """
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import classification_report
    
    # ì˜ë£Œ ì§„ë‹¨ì„ ìœ„í•œ ëª¨ë¸ - ë¯¼ê°ë„ ì¤‘ì‹œ
    model = RandomForestClassifier(
        n_estimators=100,
        class_weight='balanced',  
        random_state=42
    )
    model.fit(X_train, y_train)
    
    # ì„±ëŠ¥ í‰ê°€
    y_pred = model.predict(X_test)
    report = classification_report(y_test, y_pred)
    print(report)
    """
]

# TODO: í‰ê°€ê¸°ë¡œ AI ì½”ë“œë“¤ì„ í‰ê°€í•˜ê³  ê°œì„ ì‚¬í•­ ì œì•ˆ
```

#### ğŸ¯ ì—°ìŠµ ë¬¸ì œ 2: ì„¤ëª… ê°€ëŠ¥í•œ AI ëŒ€ì‹œë³´ë“œ
ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ì‹œê°ì ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ëŒ€ì‹œë³´ë“œë¥¼ êµ¬í˜„í•´ë³´ì„¸ìš”.

```python
# TODO: ì„¤ëª… ê°€ëŠ¥í•œ AI ëŒ€ì‹œë³´ë“œ êµ¬í˜„
import matplotlib.pyplot as plt
import seaborn as sns

class ExplainableAIDashboard:
    def __init__(self, model, X_test, y_test, feature_names):
        self.model = model
        self.X_test = X_test  
        self.y_test = y_test
        self.feature_names = feature_names
    
    def plot_prediction_confidence(self):
        """ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„í¬ ì‹œê°í™”"""
        # TODO: êµ¬í˜„
        pass
    
    def plot_feature_importance_comparison(self):
        """ì—¬ëŸ¬ ì¤‘ìš”ë„ ì§€í‘œ ë¹„êµ (ê¸°ë³¸ vs ìˆœì—´)"""
        # TODO: êµ¬í˜„
        pass
    
    def plot_individual_prediction_explanation(self, sample_idx):
        """ê°œë³„ ìƒ˜í”Œì˜ ì˜ˆì¸¡ ì„¤ëª…"""
        # TODO: êµ¬í˜„
        # íŒíŠ¸: í•´ë‹¹ ìƒ˜í”Œì˜ íŠ¹ì„±ê°’ë“¤ì„ ë°” ì°¨íŠ¸ë¡œ í‘œì‹œ
        pass
    
    def create_model_performance_summary(self):
        """ëª¨ë¸ ì„±ëŠ¥ ì¢…í•© ìš”ì•½"""
        # TODO: êµ¬í˜„
        # í˜¼ë™í–‰ë ¬, ROC ê³¡ì„ , PR ê³¡ì„  ë“±ì„ í•œ ë²ˆì— í‘œì‹œ
        pass

# TODO: ëŒ€ì‹œë³´ë“œ ìƒì„± ë° ì‹œê°í™”
```

#### ğŸ¯ ì—°ìŠµ ë¬¸ì œ 3: ì¸ê°„-AI í˜‘ì—… ì›Œí¬í”Œë¡œìš° ì„¤ê³„
íŠ¹ì • ë„ë©”ì¸(ì˜ˆ: ê¸ˆìœµ, ì œì¡°ì—… ë“±)ì„ ìœ„í•œ ë§ì¶¤í˜• í˜‘ì—… ì›Œí¬í”Œë¡œìš°ë¥¼ ì„¤ê³„í•´ë³´ì„¸ìš”.

```python
# TODO: ë„ë©”ì¸ë³„ ë§ì¶¤ í˜‘ì—… ì›Œí¬í”Œë¡œìš°
class DomainSpecificCollaboration:
    def __init__(self, domain="finance"):
        self.domain = domain
        # TODO: ë„ë©”ì¸ë³„ íŠ¹ì„± ì •ì˜
        
    def define_domain_constraints(self):
        """ë„ë©”ì¸ë³„ ì œì•½ì‚¬í•­ê³¼ ìš”êµ¬ì‚¬í•­ ì •ì˜"""
        # TODO: êµ¬í˜„
        # ì˜ˆì‹œ: ê¸ˆìœµ - ê·œì œ ì¤€ìˆ˜, í•´ì„ì„± í•„ìˆ˜
        #      ì œì¡°ì—… - ì‹¤ì‹œê°„ ì²˜ë¦¬, ì•ˆì •ì„± ì¤‘ì‹œ
        pass
    
    def ai_model_suggestions(self, X, y):
        """ë„ë©”ì¸ íŠ¹ì„±ì„ ê³ ë ¤í•œ AI ëª¨ë¸ ì œì•ˆ"""
        # TODO: êµ¬í˜„
        pass
        
    def expert_knowledge_integration(self, ai_suggestions):
        """ë„ë©”ì¸ ì „ë¬¸ê°€ ì§€ì‹ í†µí•©"""
        # TODO: êµ¬í˜„
        pass
    
    def collaborative_evaluation(self, models):
        """í˜‘ì—… ê¸°ë°˜ ëª¨ë¸ í‰ê°€"""
        # TODO: êµ¬í˜„
        # ë„ë©”ì¸ë³„ í‰ê°€ ê¸°ì¤€ ì ìš©
        pass

# TODO: ì„ íƒí•œ ë„ë©”ì¸ìœ¼ë¡œ ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
```

---

### ğŸ“š í•µì‹¬ ì •ë¦¬

#### âœ¨ ì´ë²ˆ íŒŒíŠ¸ì—ì„œ ë°°ìš´ ë‚´ìš©

**1. AI ì‹œëŒ€ ë°ì´í„° ê³¼í•™ìì˜ ìƒˆë¡œìš´ ì—­í• **
- ì½”ë“œ ìƒì„±ìì—ì„œ AI í˜‘ì—… ì½”ë””ë„¤ì´í„°ë¡œ ì—­í•  ë³€í™”
- AIì˜ ê³„ì‚° ëŠ¥ë ¥ê³¼ ì¸ê°„ì˜ ì°½ì˜ì„±, ì§ê´€ì˜ ìƒí˜¸ ë³´ì™„
- í’ˆì§ˆ ê´€ë¦¬ì™€ ë¹„íŒì  ê²€ì¦ì˜ ì¤‘ìš”ì„± ì¦ëŒ€

**2. íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**
- ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ í”„ë¡¬í”„íŠ¸ ì„¤ê³„ ì›ì¹™
- ë„ë©”ì¸ ë§¥ë½ê³¼ ì œì•½ì‚¬í•­ì˜ ëª…ì‹œì  í¬í•¨
- AI ìƒì„± ì½”ë“œì˜ ì²´ê³„ì  í’ˆì§ˆ í‰ê°€ í”„ë ˆì„ì›Œí¬

**3. ëª¨ë¸ í•´ì„ì„± í–¥ìƒ ê¸°ë²•**
- íŠ¹ì„± ì¤‘ìš”ë„, ìˆœì—´ ì¤‘ìš”ë„, ë¶€ë¶„ ì˜ì¡´ì„± í”Œë¡¯
- SHAP ë“± ê³ ê¸‰ í•´ì„ ë„êµ¬ì˜ ê°œë…ê³¼ í™œìš©
- ì˜ì‚¬ê²°ì • ê³¼ì •ì˜ íˆ¬ëª…ì„±ê³¼ ì‹ ë¢°ì„± í™•ë³´

**4. ì¸ê°„-AI í˜‘ì—… í”„ë ˆì„ì›Œí¬**
- AI ì œì•ˆê³¼ ì¸ê°„ ì „ë¬¸ê°€ ê°œì„ ì˜ ì²´ê³„ì  í†µí•©
- ë‹¤ì¤‘ ê¸°ì¤€ í‰ê°€ (ì„±ëŠ¥, í•´ì„ì„±, ê²¬ê³ ì„±, íš¨ìœ¨ì„±)
- ë„ë©”ì¸ ì§€ì‹ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ë§¥ë½ì˜ ë°˜ì˜

**5. ëª¨ë¸ ì•ˆì •ì„±ê³¼ ê²¬ê³ ì„± ê²€ì¦**
- ë°ì´í„° ë“œë¦¬í”„íŠ¸, íŠ¹ì„± ì†ìƒì— ëŒ€í•œ ë‚´ì„± í…ŒìŠ¤íŠ¸
- ì˜ˆì¸¡ ì¼ê´€ì„±ê³¼ ì‹ ë¢°ë„ í‰ê°€
- ì‹¤ë¬´ í™˜ê²½ì—ì„œì˜ ë°°í¬ ì¤€ë¹„ë„ ê²€ì¦

**6. ì§€ëŠ¥ì  í˜‘ì—… ëª¨ë¸ë§ ì‹œìŠ¤í…œ**
- AIì™€ ì¸ê°„ì˜ ê°•ì ì„ ê²°í•©í•œ í†µí•© ì‹œìŠ¤í…œ
- ë°°í¬ì™€ ëª¨ë‹ˆí„°ë§ê¹Œì§€ ê³ ë ¤í•œ ì‹¤ìš©ì  ì ‘ê·¼
- ì§€ì†ì  ê°œì„ ê³¼ í”¼ë“œë°± ë£¨í”„ êµ¬ì¶•

#### ğŸ¯ ì‹¤ë¬´ ì ìš© ê°€ì´ë“œë¼ì¸

**í˜‘ì—… ì„±ê³µì˜ í•µì‹¬ ìš”ì†Œ**
1. **ëª…í™•í•œ ì—­í•  ë¶„ë‹´**: AIëŠ” ê³„ì‚°ê³¼ íŒ¨í„´ ì¸ì‹, ì¸ê°„ì€ ë§¥ë½ê³¼ í•´ì„
2. **ì§€ì†ì  ê²€ì¦**: AI ê²°ê³¼ë¥¼ ë¬´ì¡°ê±´ ì‹ ë¢°í•˜ì§€ ì•Šê³  ë¹„íŒì  ê²€í† 
3. **ë„ë©”ì¸ ì§€ì‹ í™œìš©**: ì „ë¬¸ ì§€ì‹ì„ ëª¨ë¸ì— ì ê·¹ì ìœ¼ë¡œ ë°˜ì˜
4. **íˆ¬ëª…ì„± í™•ë³´**: ê²°ì • ê³¼ì •ì„ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” í•´ì„ ê°€ëŠ¥í•œ ëª¨ë¸ ì„ í˜¸

**í’ˆì§ˆ ê´€ë¦¬ ì²´í¬í¬ì¸íŠ¸**
- **ê¸°ëŠ¥ì„±**: ìš”êµ¬ì‚¬í•­ì„ ì •í™•íˆ ì¶©ì¡±í•˜ëŠ”ê°€?
- **ì‹ ë¢°ì„±**: ë‹¤ì–‘í•œ ì¡°ê±´ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ê°€?
- **í•´ì„ì„±**: ê²°ì • ê³¼ì •ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ê°€?
- **ìœ¤ë¦¬ì„±**: ê³µì •í•˜ê³  í¸í–¥ë˜ì§€ ì•Šì€ ê²°ê³¼ë¥¼ ì‚°ì¶œí•˜ëŠ”ê°€?

**ì§€ì†ì  ê°œì„  ì „ëµ**
- **ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¶”ì ê³¼ ì´ìƒ ì§•í›„ ê°ì§€
- **í”¼ë“œë°±**: ì‚¬ìš©ìì™€ ì „ë¬¸ê°€ì˜ ì˜ê²¬ì„ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜ì§‘
- **ì—…ë°ì´íŠ¸**: ì •ê¸°ì ì¸ ëª¨ë¸ ì¬í›ˆë ¨ê³¼ ì„±ëŠ¥ ê°œì„ 
- **í•™ìŠµ**: AI ë°œì „ì— ë”°ë¥¸ ìƒˆë¡œìš´ ê¸°ë²•ì˜ ì ê·¹ì  ë„ì…

#### ğŸ’¡ ë¯¸ë˜ë¥¼ ìœ„í•œ ì¤€ë¹„

**AI í˜‘ì—… ì—­ëŸ‰ ê°œë°œ**
- **ê¸°ìˆ ì  ì—­ëŸ‰**: AI ë„êµ¬ í™œìš©ë²•ê³¼ í•œê³„ ì´í•´
- **ë¹„íŒì  ì‚¬ê³ **: AI ê²°ê³¼ì˜ ì ì ˆì„± íŒë‹¨ ëŠ¥ë ¥
- **ì»¤ë®¤ë‹ˆì¼€ì´ì…˜**: ê¸°ìˆ ì  ë‚´ìš©ì˜ ë¹„ê¸°ìˆ ì  ì„¤ëª… ëŠ¥ë ¥
- **ìœ¤ë¦¬ì  íŒë‹¨**: AI í™œìš©ì˜ ì‚¬íšŒì  ì±…ì„ ì¸ì‹

**ë³€í™”í•˜ëŠ” í™˜ê²½ì— ëŒ€í•œ ì ì‘**
- **ìƒˆë¡œìš´ ë„êµ¬**: ì§€ì†ì ìœ¼ë¡œ ë“±ì¥í•˜ëŠ” AI ë„êµ¬ë“¤ì˜ í•™ìŠµ
- **ê·œì œ ë³€í™”**: AI ê´€ë ¨ ë²•ê·œì™€ ê°€ì´ë“œë¼ì¸ì˜ ì¤€ìˆ˜
- **ì‚¬íšŒì  ê¸°ëŒ€**: AI íˆ¬ëª…ì„±ê³¼ ì±…ì„ì„±ì— ëŒ€í•œ ìš”êµ¬ ì¦ê°€
- **ê¸°ìˆ  ë°œì „**: ë”ìš± ì •êµí•˜ê³  ê°•ë ¥í•œ AI ê¸°ìˆ ì˜ í™œìš©

---

### ğŸ”® ë‹¤ìŒ íŒŒíŠ¸ ë¯¸ë¦¬ë³´ê¸°

ë‹¤ìŒ Part 5ì—ì„œëŠ” **í”„ë¡œì íŠ¸ - ë³µí•© ëª¨ë¸ êµ¬ì¶• ë° ìµœì í™”**ì— ëŒ€í•´ í•™ìŠµí•©ë‹ˆë‹¤:

- ğŸ—ï¸ **í†µí•© ì‹œìŠ¤í…œ êµ¬ì¶•**: ì•™ìƒë¸” + ì°¨ì›ì¶•ì†Œ + ìµœì í™” + AIí˜‘ì—…
- ğŸ¯ **ì‹¤ì „ ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œ**: ì‹ ìš©í‰ê°€, ì˜ë£Œì§„ë‹¨, ì¶”ì²œì‹œìŠ¤í…œ ì¤‘ ì„ íƒ
- ğŸ“Š **ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹**: ì—…ê³„ í‘œì¤€ ëŒ€ë¹„ ì„±ëŠ¥ ë¹„êµì™€ ê²½ìŸë ¥ ë¶„ì„
- ğŸš€ **ë°°í¬ ì¤€ë¹„**: í”„ë¡œë•ì…˜ í™˜ê²½ì„ ìœ„í•œ ëª¨ë¸ íŒ¨í‚¤ì§•ê³¼ ëª¨ë‹ˆí„°ë§
- ğŸ† **í¬íŠ¸í´ë¦¬ì˜¤ ì™„ì„±**: ì·¨ì—…ê³¼ ì‹¤ë¬´ì— í™œìš©í•  ìˆ˜ ìˆëŠ” ì™„ì „í•œ í”„ë¡œì íŠ¸

AIì™€ì˜ í˜‘ì—…ìœ¼ë¡œ ë” ë‚˜ì€ ëª¨ë¸ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ë°°ì› ë‹¤ë©´, ì´ì œ ëª¨ë“  ê¸°ë²•ì„ í†µí•©í•˜ì—¬ ì‹¤ë¬´ê¸‰ í”„ë¡œì íŠ¸ë¥¼ ì™„ì„±í•´ë³´ê² ìŠµë‹ˆë‹¤!

---

*"AIëŠ” ë„êµ¬ì´ê³ , ì¸ê°„ì€ ë§ˆì—ìŠ¤íŠ¸ë¡œë‹¤. ìµœê³ ì˜ êµí–¥ê³¡ì€ ë‘˜ì˜ ì™„ë²½í•œ í˜‘ì—…ì—ì„œ ë‚˜ì˜¨ë‹¤." - ë¯¸ë˜ì˜ ë°ì´í„° ê³¼í•™ì*